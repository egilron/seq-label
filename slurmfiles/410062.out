Starting job 410062 on gpu-7 at Thu Jan 18 11:08:06 CET 2024

/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_27.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_27.json
01170939_tsa-bin_NorBERT_3_large_27.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_25.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_25.json
01170939_tsa-bin_NB-BERT_base_25.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_03.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_03.json
01170939_tsa-bin_NorBERT_2_03.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_37.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_37.json
01170939_tsa-bin_NorBERT_1_37.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_08.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_08.json
01170939_tsa-bin_NorBERT_3_base_08.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_30.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_30.json
01170939_tsa-bin_NorBERT_1_30.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_16.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_16.json
01170939_tsa-bin_NorBERT_1_16.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_00.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_00.json
01170939_tsa-bin_NorBERT_3_small_00.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_06.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_06.json
01170939_tsa-bin_NorBERT_3_large_06.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_01.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_01.json
01170939_tsa-bin_NorBERT_3_base_01.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_35.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_35.json
01170939_tsa-bin_NorBERT_3_small_35.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_12.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_12.json
01170939_tsa-bin_NB-BERT_large_12.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_40.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_40.json
01170939_tsa-bin_NB-BERT_large_40.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_23.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_23.json
01170939_tsa-bin_NorBERT_1_23.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_36.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_36.json
01170939_tsa-bin_NorBERT_3_base_36.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_18.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_18.json
01170939_tsa-bin_NB-BERT_base_18.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_04.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_04.json
01170939_tsa-bin_NB-BERT_base_04.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_24.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_24.json
01170939_tsa-bin_NorBERT_2_24.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_26.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_26.json
01170939_tsa-bin_NB-BERT_large_26.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_11.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_11.json
01170939_tsa-bin_NB-BERT_base_11.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_31.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_31.json
01170939_tsa-bin_NorBERT_2_31.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_41.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_41.json
01170939_tsa-bin_NorBERT_3_large_41.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_29.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_29.json
01170939_tsa-bin_NorBERT_3_base_29.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_05.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_05.json
01170939_tsa-bin_NB-BERT_large_05.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_14.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_14.json
01170939_tsa-bin_NorBERT_3_small_14.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_15.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_15.json
01170939_tsa-bin_NorBERT_3_base_15.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_07.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_07.json
01170939_tsa-bin_NorBERT_3_small_07.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_02.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_02.json
01170939_tsa-bin_NorBERT_1_02.json seems to be completed. Exiting
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_34.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_34.json
01170939_tsa-bin_NorBERT_3_large Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 5611.30 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:01, 6505.67 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6525.60 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6638.13 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6726.64 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 6871.60 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 7046.81 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6189.81 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6501.84 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7209.16 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6790.68 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 5651.63 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 5750.25 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Checkpoint destination directory /cluster/work/projects/ec30/egilron/tsa-hf/01170939_tsa-bin_NorBERT_3_large/checkpoint-135 already exists and is non-empty.Saving will proceed but saved results may be invalid.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
01170939_tsa-bin_NorBERT_3_large Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.3849, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': 0.19679734110832214, 'eval_precision': 0.23122765196662692, 'eval_recall': 0.22120866590649943, 'eval_f1': 0.2261072261072261, 'eval_accuracy': 0.9402455029722844, 'eval_runtime': 5.9452, 'eval_samples_per_second': 257.52, 'eval_steps_per_second': 32.295, 'epoch': 1.0}
{'loss': 0.1895, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': 0.1920808106660843, 'eval_precision': 0.48545176110260335, 'eval_recall': 0.3614595210946408, 'eval_f1': 0.4143790849673202, 'eval_accuracy': 0.937543426233305, 'eval_runtime': 5.8343, 'eval_samples_per_second': 262.412, 'eval_steps_per_second': 32.909, 'epoch': 2.0}
{'loss': 0.1087, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': 0.19301174581050873, 'eval_precision': 0.44510035419126326, 'eval_recall': 0.4298745724059293, 'eval_f1': 0.43735498839907194, 'eval_accuracy': 0.9488149463444762, 'eval_runtime': 5.8246, 'eval_samples_per_second': 262.85, 'eval_steps_per_second': 32.964, 'epoch': 3.0}
{'loss': 0.0597, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.20538313686847687, 'eval_precision': 0.4727822580645161, 'eval_recall': 0.5347776510832383, 'eval_f1': 0.5018726591760299, 'eval_accuracy': 0.9494325638848143, 'eval_runtime': 5.8331, 'eval_samples_per_second': 262.469, 'eval_steps_per_second': 32.916, 'epoch': 4.0}
{'loss': 0.034, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.2023894339799881, 'eval_precision': 0.49187432286023836, 'eval_recall': 0.5176738882554162, 'eval_f1': 0.5044444444444445, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 5.8439, 'eval_samples_per_second': 261.982, 'eval_steps_per_second': 32.855, 'epoch': 5.0}
{'loss': 0.0174, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.24169686436653137, 'eval_precision': 0.4670981661272923, 'eval_recall': 0.49372862029646525, 'eval_f1': 0.48004434589800443, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 5.8207, 'eval_samples_per_second': 263.027, 'eval_steps_per_second': 32.986, 'epoch': 6.0}
{'loss': 0.01, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': 0.26273399591445923, 'eval_precision': 0.5032397408207343, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.516916250693289, 'eval_accuracy': 0.95167142746854, 'eval_runtime': 5.8205, 'eval_samples_per_second': 263.034, 'eval_steps_per_second': 32.987, 'epoch': 7.0}
{'loss': 0.0063, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': 0.2700825333595276, 'eval_precision': 0.4971815107102593, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.4999999999999999, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 5.8235, 'eval_samples_per_second': 262.902, 'eval_steps_per_second': 32.97, 'epoch': 8.0}
{'loss': 0.0042, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': 0.2859261929988861, 'eval_precision': 0.5176767676767676, 'eval_recall': 0.467502850627138, 'eval_f1': 0.4913121629718394, 'eval_accuracy': 0.9515942252759978, 'eval_runtime': 5.9068, 'eval_samples_per_second': 259.194, 'eval_steps_per_second': 32.505, 'epoch': 9.0}
{'loss': 0.0031, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.3242522180080414, 'eval_precision': 0.4627606752730884, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.49469214437367304, 'eval_accuracy': 0.9480815255153247, 'eval_runtime': 5.8355, 'eval_samples_per_second': 262.359, 'eval_steps_per_second': 32.902, 'epoch': 10.0}
{'loss': 0.0032, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': 0.2884940207004547, 'eval_precision': 0.4677584442169908, 'eval_recall': 0.5210946408209807, 'eval_f1': 0.4929881337648328, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 5.8376, 'eval_samples_per_second': 262.266, 'eval_steps_per_second': 32.89, 'epoch': 11.0}
{'loss': 0.002, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': 0.3133881688117981, 'eval_precision': 0.5180180180180181, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5212464589235128, 'eval_accuracy': 0.9506677989654906, 'eval_runtime': 5.8282, 'eval_samples_per_second': 262.687, 'eval_steps_per_second': 32.943, 'epoch': 12.0}
{'loss': 0.0017, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': 0.31300172209739685, 'eval_precision': 0.5056306306306306, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5087818696883852, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 5.8399, 'eval_samples_per_second': 262.162, 'eval_steps_per_second': 32.877, 'epoch': 13.0}
{'loss': 0.0007, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': 0.3429499566555023, 'eval_precision': 0.5022371364653244, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5070581592320723, 'eval_accuracy': 0.950204585810237, 'eval_runtime': 5.8252, 'eval_samples_per_second': 262.822, 'eval_steps_per_second': 32.96, 'epoch': 14.0}
{'loss': 0.0006, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': 0.34904080629348755, 'eval_precision': 0.5111856823266219, 'eval_recall': 0.5210946408209807, 'eval_f1': 0.5160926030491247, 'eval_accuracy': 0.950783602254304, 'eval_runtime': 5.8313, 'eval_samples_per_second': 262.547, 'eval_steps_per_second': 32.925, 'epoch': 15.0}
{'loss': 0.0006, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.34996846318244934, 'eval_precision': 0.5, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5125069483046136, 'eval_accuracy': 0.9505905967729483, 'eval_runtime': 5.8325, 'eval_samples_per_second': 262.495, 'eval_steps_per_second': 32.919, 'epoch': 16.0}
{'loss': 0.0004, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': 0.3709042966365814, 'eval_precision': 0.525934861278649, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.5111371629542789, 'eval_accuracy': 0.951053809928202, 'eval_runtime': 5.8256, 'eval_samples_per_second': 262.804, 'eval_steps_per_second': 32.958, 'epoch': 17.0}
{'loss': 0.0004, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': 0.360144704580307, 'eval_precision': 0.5280373831775701, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.5216387766878245, 'eval_accuracy': 0.9519030340461669, 'eval_runtime': 5.821, 'eval_samples_per_second': 263.011, 'eval_steps_per_second': 32.984, 'epoch': 18.0}
{'loss': 0.0004, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': 0.3680007755756378, 'eval_precision': 0.4788306451612903, 'eval_recall': 0.5416191562143672, 'eval_f1': 0.5082932049224184, 'eval_accuracy': 0.9493553616922721, 'eval_runtime': 5.8219, 'eval_samples_per_second': 262.972, 'eval_steps_per_second': 32.979, 'epoch': 19.0}
{'loss': 0.0003, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': 0.3693675398826599, 'eval_precision': 0.5159010600706714, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.5075318655851682, 'eval_accuracy': 0.9512854165058288, 'eval_runtime': 5.8091, 'eval_samples_per_second': 263.552, 'eval_steps_per_second': 33.052, 'epoch': 20.0}
{'loss': 0.0002, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': 0.3659268021583557, 'eval_precision': 0.49411764705882355, 'eval_recall': 0.5267958950969214, 'eval_f1': 0.5099337748344371, 'eval_accuracy': 0.9501659847139658, 'eval_runtime': 5.8233, 'eval_samples_per_second': 262.91, 'eval_steps_per_second': 32.971, 'epoch': 21.0}
{'loss': 0.0003, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.37161412835121155, 'eval_precision': 0.5256257449344458, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.513986013986014, 'eval_accuracy': 0.9514398208909133, 'eval_runtime': 5.8232, 'eval_samples_per_second': 262.913, 'eval_steps_per_second': 32.971, 'epoch': 22.0}
{'loss': 0.0002, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': 0.3721295893192291, 'eval_precision': 0.5230224321133412, 'eval_recall': 0.5051311288483467, 'eval_f1': 0.5139211136890951, 'eval_accuracy': 0.9514784219871845, 'eval_runtime': 5.862, 'eval_samples_per_second': 261.175, 'eval_steps_per_second': 32.753, 'epoch': 23.0}
{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.37318313121795654, 'eval_precision': 0.5230769230769231, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.5133565621370499, 'eval_accuracy': 0.9515556241797267, 'eval_runtime': 5.9938, 'eval_samples_per_second': 255.43, 'eval_steps_per_second': 32.033, 'epoch': 24.0}
{'train_runtime': 2475.5862, 'train_samples_per_second': 83.704, 'train_steps_per_second': 1.309, 'train_loss': 0.03453326718479303, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0345
  train_runtime            = 0:41:15.58
  train_samples            =       8634
  train_samples_per_second =     83.704
  train_steps_per_second   =      1.309
[{'loss': 0.3849, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.19679734110832214, 'eval_precision': 0.23122765196662692, 'eval_recall': 0.22120866590649943, 'eval_f1': 0.2261072261072261, 'eval_accuracy': 0.9402455029722844, 'eval_runtime': 5.9452, 'eval_samples_per_second': 257.52, 'eval_steps_per_second': 32.295, 'epoch': 1.0, 'step': 135}, {'loss': 0.1895, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.1920808106660843, 'eval_precision': 0.48545176110260335, 'eval_recall': 0.3614595210946408, 'eval_f1': 0.4143790849673202, 'eval_accuracy': 0.937543426233305, 'eval_runtime': 5.8343, 'eval_samples_per_second': 262.412, 'eval_steps_per_second': 32.909, 'epoch': 2.0, 'step': 270}, {'loss': 0.1087, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.19301174581050873, 'eval_precision': 0.44510035419126326, 'eval_recall': 0.4298745724059293, 'eval_f1': 0.43735498839907194, 'eval_accuracy': 0.9488149463444762, 'eval_runtime': 5.8246, 'eval_samples_per_second': 262.85, 'eval_steps_per_second': 32.964, 'epoch': 3.0, 'step': 405}, {'loss': 0.0597, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.20538313686847687, 'eval_precision': 0.4727822580645161, 'eval_recall': 0.5347776510832383, 'eval_f1': 0.5018726591760299, 'eval_accuracy': 0.9494325638848143, 'eval_runtime': 5.8331, 'eval_samples_per_second': 262.469, 'eval_steps_per_second': 32.916, 'epoch': 4.0, 'step': 540}, {'loss': 0.034, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.2023894339799881, 'eval_precision': 0.49187432286023836, 'eval_recall': 0.5176738882554162, 'eval_f1': 0.5044444444444445, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 5.8439, 'eval_samples_per_second': 261.982, 'eval_steps_per_second': 32.855, 'epoch': 5.0, 'step': 675}, {'loss': 0.0174, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.24169686436653137, 'eval_precision': 0.4670981661272923, 'eval_recall': 0.49372862029646525, 'eval_f1': 0.48004434589800443, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 5.8207, 'eval_samples_per_second': 263.027, 'eval_steps_per_second': 32.986, 'epoch': 6.0, 'step': 810}, {'loss': 0.01, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.26273399591445923, 'eval_precision': 0.5032397408207343, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.516916250693289, 'eval_accuracy': 0.95167142746854, 'eval_runtime': 5.8205, 'eval_samples_per_second': 263.034, 'eval_steps_per_second': 32.987, 'epoch': 7.0, 'step': 945}, {'loss': 0.0063, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.2700825333595276, 'eval_precision': 0.4971815107102593, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.4999999999999999, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 5.8235, 'eval_samples_per_second': 262.902, 'eval_steps_per_second': 32.97, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0042, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.2859261929988861, 'eval_precision': 0.5176767676767676, 'eval_recall': 0.467502850627138, 'eval_f1': 0.4913121629718394, 'eval_accuracy': 0.9515942252759978, 'eval_runtime': 5.9068, 'eval_samples_per_second': 259.194, 'eval_steps_per_second': 32.505, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0031, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.3242522180080414, 'eval_precision': 0.4627606752730884, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.49469214437367304, 'eval_accuracy': 0.9480815255153247, 'eval_runtime': 5.8355, 'eval_samples_per_second': 262.359, 'eval_steps_per_second': 32.902, 'epoch': 10.0, 'step': 1350}, {'loss': 0.0032, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.2884940207004547, 'eval_precision': 0.4677584442169908, 'eval_recall': 0.5210946408209807, 'eval_f1': 0.4929881337648328, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 5.8376, 'eval_samples_per_second': 262.266, 'eval_steps_per_second': 32.89, 'epoch': 11.0, 'step': 1485}, {'loss': 0.002, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.3133881688117981, 'eval_precision': 0.5180180180180181, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5212464589235128, 'eval_accuracy': 0.9506677989654906, 'eval_runtime': 5.8282, 'eval_samples_per_second': 262.687, 'eval_steps_per_second': 32.943, 'epoch': 12.0, 'step': 1620}, {'loss': 0.0017, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.31300172209739685, 'eval_precision': 0.5056306306306306, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5087818696883852, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 5.8399, 'eval_samples_per_second': 262.162, 'eval_steps_per_second': 32.877, 'epoch': 13.0, 'step': 1755}, {'loss': 0.0007, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.3429499566555023, 'eval_precision': 0.5022371364653244, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5070581592320723, 'eval_accuracy': 0.950204585810237, 'eval_runtime': 5.8252, 'eval_samples_per_second': 262.822, 'eval_steps_per_second': 32.96, 'epoch': 14.0, 'step': 1890}, {'loss': 0.0006, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.34904080629348755, 'eval_precision': 0.5111856823266219, 'eval_recall': 0.5210946408209807, 'eval_f1': 0.5160926030491247, 'eval_accuracy': 0.950783602254304, 'eval_runtime': 5.8313, 'eval_samples_per_second': 262.547, 'eval_steps_per_second': 32.925, 'epoch': 15.0, 'step': 2025}, {'loss': 0.0006, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.34996846318244934, 'eval_precision': 0.5, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5125069483046136, 'eval_accuracy': 0.9505905967729483, 'eval_runtime': 5.8325, 'eval_samples_per_second': 262.495, 'eval_steps_per_second': 32.919, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0004, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.3709042966365814, 'eval_precision': 0.525934861278649, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.5111371629542789, 'eval_accuracy': 0.951053809928202, 'eval_runtime': 5.8256, 'eval_samples_per_second': 262.804, 'eval_steps_per_second': 32.958, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0004, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.360144704580307, 'eval_precision': 0.5280373831775701, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.5216387766878245, 'eval_accuracy': 0.9519030340461669, 'eval_runtime': 5.821, 'eval_samples_per_second': 263.011, 'eval_steps_per_second': 32.984, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0004, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.3680007755756378, 'eval_precision': 0.4788306451612903, 'eval_recall': 0.5416191562143672, 'eval_f1': 0.5082932049224184, 'eval_accuracy': 0.9493553616922721, 'eval_runtime': 5.8219, 'eval_samples_per_second': 262.972, 'eval_steps_per_second': 32.979, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0003, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.3693675398826599, 'eval_precision': 0.5159010600706714, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.5075318655851682, 'eval_accuracy': 0.9512854165058288, 'eval_runtime': 5.8091, 'eval_samples_per_second': 263.552, 'eval_steps_per_second': 33.052, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0002, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.3659268021583557, 'eval_precision': 0.49411764705882355, 'eval_recall': 0.5267958950969214, 'eval_f1': 0.5099337748344371, 'eval_accuracy': 0.9501659847139658, 'eval_runtime': 5.8233, 'eval_samples_per_second': 262.91, 'eval_steps_per_second': 32.971, 'epoch': 21.0, 'step': 2835}, {'loss': 0.0003, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.37161412835121155, 'eval_precision': 0.5256257449344458, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.513986013986014, 'eval_accuracy': 0.9514398208909133, 'eval_runtime': 5.8232, 'eval_samples_per_second': 262.913, 'eval_steps_per_second': 32.971, 'epoch': 22.0, 'step': 2970}, {'loss': 0.0002, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.3721295893192291, 'eval_precision': 0.5230224321133412, 'eval_recall': 0.5051311288483467, 'eval_f1': 0.5139211136890951, 'eval_accuracy': 0.9514784219871845, 'eval_runtime': 5.862, 'eval_samples_per_second': 261.175, 'eval_steps_per_second': 32.753, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.37318313121795654, 'eval_precision': 0.5230769230769231, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.5133565621370499, 'eval_accuracy': 0.9515556241797267, 'eval_runtime': 5.9938, 'eval_samples_per_second': 255.43, 'eval_steps_per_second': 32.033, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 2475.5862, 'train_samples_per_second': 83.704, 'train_steps_per_second': 1.309, 'total_flos': 2.705738887944774e+16, 'train_loss': 0.03453326718479303, 'epoch': 24.0, 'step': 3240}]

Evaluation, ltg/norbert3-large
***** predict metrics *****
  predict_accuracy           =     0.9413
  predict_f1                 =     0.4097
  predict_loss               =     0.1993
  predict_precision          =      0.506
  predict_recall             =     0.3442
  predict_runtime            = 0:00:04.87
  predict_samples_per_second =    260.748
  predict_steps_per_second   =     32.593
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_34.json completed. F1: 0.4097165991902834
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_13.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_13.json
01170939_tsa-bin_NorBERT_3_large Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6678.57 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 7115.83 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6882.05 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6863.60 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6915.50 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7005.21 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:00<00:00, 7161.34 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6264.59 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6691.32 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7196.41 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6834.05 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6930.52 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6763.64 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
01170939_tsa-bin_NorBERT_3_large Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.0, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9019, 'eval_samples_per_second': 259.406, 'eval_steps_per_second': 32.532, 'epoch': 1.0}
{'loss': 0.0, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8572, 'eval_samples_per_second': 261.388, 'eval_steps_per_second': 32.78, 'epoch': 2.0}
{'loss': 0.0, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8456, 'eval_samples_per_second': 261.905, 'eval_steps_per_second': 32.845, 'epoch': 3.0}
{'loss': 0.0, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8409, 'eval_samples_per_second': 262.117, 'eval_steps_per_second': 32.872, 'epoch': 4.0}
{'loss': 0.0, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9136, 'eval_samples_per_second': 258.893, 'eval_steps_per_second': 32.467, 'epoch': 5.0}
{'loss': 0.0, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8594, 'eval_samples_per_second': 261.292, 'eval_steps_per_second': 32.768, 'epoch': 6.0}
{'loss': 0.0, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9134, 'eval_samples_per_second': 258.903, 'eval_steps_per_second': 32.469, 'epoch': 7.0}
{'loss': 0.0, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8399, 'eval_samples_per_second': 262.161, 'eval_steps_per_second': 32.877, 'epoch': 8.0}
{'loss': 0.0, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8541, 'eval_samples_per_second': 261.527, 'eval_steps_per_second': 32.798, 'epoch': 9.0}
{'loss': 0.0, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8396, 'eval_samples_per_second': 262.177, 'eval_steps_per_second': 32.879, 'epoch': 10.0}
{'loss': 0.0, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9211, 'eval_samples_per_second': 258.569, 'eval_steps_per_second': 32.427, 'epoch': 11.0}
{'loss': 0.0, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8419, 'eval_samples_per_second': 262.074, 'eval_steps_per_second': 32.866, 'epoch': 12.0}
{'loss': 0.0, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9087, 'eval_samples_per_second': 259.11, 'eval_steps_per_second': 32.495, 'epoch': 13.0}
{'loss': 0.0, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8638, 'eval_samples_per_second': 261.094, 'eval_steps_per_second': 32.743, 'epoch': 14.0}
{'loss': 0.0, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8501, 'eval_samples_per_second': 261.704, 'eval_steps_per_second': 32.82, 'epoch': 15.0}
{'loss': 0.0, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8703, 'eval_samples_per_second': 260.804, 'eval_steps_per_second': 32.707, 'epoch': 16.0}
{'loss': 0.0, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8657, 'eval_samples_per_second': 261.008, 'eval_steps_per_second': 32.733, 'epoch': 17.0}
{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8451, 'eval_samples_per_second': 261.929, 'eval_steps_per_second': 32.848, 'epoch': 18.0}
{'loss': 0.0, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8559, 'eval_samples_per_second': 261.446, 'eval_steps_per_second': 32.787, 'epoch': 19.0}
{'loss': 0.0, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 6.2006, 'eval_samples_per_second': 246.91, 'eval_steps_per_second': 30.965, 'epoch': 20.0}
{'loss': 0.0, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8627, 'eval_samples_per_second': 261.144, 'eval_steps_per_second': 32.75, 'epoch': 21.0}
{'loss': 0.0, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8604, 'eval_samples_per_second': 261.246, 'eval_steps_per_second': 32.762, 'epoch': 22.0}
{'loss': 0.0, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8376, 'eval_samples_per_second': 262.266, 'eval_steps_per_second': 32.89, 'epoch': 23.0}
{'loss': 0.0, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 6.0154, 'eval_samples_per_second': 254.515, 'eval_steps_per_second': 31.918, 'epoch': 24.0}
{'train_runtime': 2428.7284, 'train_samples_per_second': 85.319, 'train_steps_per_second': 2.134, 'train_loss': 0.0, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =        0.0
  train_runtime            = 0:40:28.72
  train_samples            =       8634
  train_samples_per_second =     85.319
  train_steps_per_second   =      2.134
[{'loss': 0.0, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 216}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9019, 'eval_samples_per_second': 259.406, 'eval_steps_per_second': 32.532, 'epoch': 1.0, 'step': 216}, {'loss': 0.0, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 432}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8572, 'eval_samples_per_second': 261.388, 'eval_steps_per_second': 32.78, 'epoch': 2.0, 'step': 432}, {'loss': 0.0, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 648}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8456, 'eval_samples_per_second': 261.905, 'eval_steps_per_second': 32.845, 'epoch': 3.0, 'step': 648}, {'loss': 0.0, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 864}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8409, 'eval_samples_per_second': 262.117, 'eval_steps_per_second': 32.872, 'epoch': 4.0, 'step': 864}, {'loss': 0.0, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 1080}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9136, 'eval_samples_per_second': 258.893, 'eval_steps_per_second': 32.467, 'epoch': 5.0, 'step': 1080}, {'loss': 0.0, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 1296}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8594, 'eval_samples_per_second': 261.292, 'eval_steps_per_second': 32.768, 'epoch': 6.0, 'step': 1296}, {'loss': 0.0, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 1512}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9134, 'eval_samples_per_second': 258.903, 'eval_steps_per_second': 32.469, 'epoch': 7.0, 'step': 1512}, {'loss': 0.0, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1728}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8399, 'eval_samples_per_second': 262.161, 'eval_steps_per_second': 32.877, 'epoch': 8.0, 'step': 1728}, {'loss': 0.0, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1944}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8541, 'eval_samples_per_second': 261.527, 'eval_steps_per_second': 32.798, 'epoch': 9.0, 'step': 1944}, {'loss': 0.0, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 2160}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8396, 'eval_samples_per_second': 262.177, 'eval_steps_per_second': 32.879, 'epoch': 10.0, 'step': 2160}, {'loss': 0.0, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 2376}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9211, 'eval_samples_per_second': 258.569, 'eval_steps_per_second': 32.427, 'epoch': 11.0, 'step': 2376}, {'loss': 0.0, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 2592}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8419, 'eval_samples_per_second': 262.074, 'eval_steps_per_second': 32.866, 'epoch': 12.0, 'step': 2592}, {'loss': 0.0, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 2808}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.9087, 'eval_samples_per_second': 259.11, 'eval_steps_per_second': 32.495, 'epoch': 13.0, 'step': 2808}, {'loss': 0.0, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 3024}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8638, 'eval_samples_per_second': 261.094, 'eval_steps_per_second': 32.743, 'epoch': 14.0, 'step': 3024}, {'loss': 0.0, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 3240}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8501, 'eval_samples_per_second': 261.704, 'eval_steps_per_second': 32.82, 'epoch': 15.0, 'step': 3240}, {'loss': 0.0, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 3456}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8703, 'eval_samples_per_second': 260.804, 'eval_steps_per_second': 32.707, 'epoch': 16.0, 'step': 3456}, {'loss': 0.0, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 3672}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8657, 'eval_samples_per_second': 261.008, 'eval_steps_per_second': 32.733, 'epoch': 17.0, 'step': 3672}, {'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 3888}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8451, 'eval_samples_per_second': 261.929, 'eval_steps_per_second': 32.848, 'epoch': 18.0, 'step': 3888}, {'loss': 0.0, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 4104}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8559, 'eval_samples_per_second': 261.446, 'eval_steps_per_second': 32.787, 'epoch': 19.0, 'step': 4104}, {'loss': 0.0, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 4320}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 6.2006, 'eval_samples_per_second': 246.91, 'eval_steps_per_second': 30.965, 'epoch': 20.0, 'step': 4320}, {'loss': 0.0, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 4536}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8627, 'eval_samples_per_second': 261.144, 'eval_steps_per_second': 32.75, 'epoch': 21.0, 'step': 4536}, {'loss': 0.0, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 4752}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8604, 'eval_samples_per_second': 261.246, 'eval_steps_per_second': 32.762, 'epoch': 22.0, 'step': 4752}, {'loss': 0.0, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 4968}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 5.8376, 'eval_samples_per_second': 262.266, 'eval_steps_per_second': 32.89, 'epoch': 23.0, 'step': 4968}, {'loss': 0.0, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 5184}, {'eval_loss': nan, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 6.0154, 'eval_samples_per_second': 254.515, 'eval_steps_per_second': 31.918, 'epoch': 24.0, 'step': 5184}, {'train_runtime': 2428.7284, 'train_samples_per_second': 85.319, 'train_steps_per_second': 2.134, 'total_flos': 2.4800280552929028e+16, 'train_loss': 0.0, 'epoch': 24.0, 'step': 5184}]

Evaluation, ltg/norbert3-large
***** predict metrics *****
  predict_accuracy           =     0.9327
  predict_f1                 =        0.0
  predict_loss               =        nan
  predict_precision          =        0.0
  predict_recall             =        0.0
  predict_runtime            = 0:00:04.89
  predict_samples_per_second =     259.69
  predict_steps_per_second   =     32.461
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_13.json completed. F1: 0.0
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_09.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at ltg/norbert and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_09.json
01170939_tsa-bin_NorBERT_1 Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 5267.68 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:01, 6472.51 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6685.72 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6914.78 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 7070.29 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7245.92 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6414.96 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6793.65 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6776.49 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7593.55 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 7211.63 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7367.94 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 7172.25 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
01170939_tsa-bin_NorBERT_1 Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2837, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': 0.21498994529247284, 'eval_precision': 0.4099616858237548, 'eval_recall': 0.12200684150513112, 'eval_f1': 0.18804920913884007, 'eval_accuracy': 0.9374276229444917, 'eval_runtime': 2.3103, 'eval_samples_per_second': 662.676, 'eval_steps_per_second': 83.105, 'epoch': 1.0}
{'loss': 0.2052, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': 0.19285044074058533, 'eval_precision': 0.47911547911547914, 'eval_recall': 0.22234891676168758, 'eval_f1': 0.3037383177570094, 'eval_accuracy': 0.9436037983478731, 'eval_runtime': 2.284, 'eval_samples_per_second': 670.328, 'eval_steps_per_second': 84.065, 'epoch': 2.0}
{'loss': 0.1618, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': 0.1882469803094864, 'eval_precision': 0.3722060252672498, 'eval_recall': 0.43671607753705816, 'eval_f1': 0.40188877229800635, 'eval_accuracy': 0.9357677758048328, 'eval_runtime': 2.2828, 'eval_samples_per_second': 670.658, 'eval_steps_per_second': 84.106, 'epoch': 3.0}
{'loss': 0.1292, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.19925622642040253, 'eval_precision': 0.33779904306220093, 'eval_recall': 0.40250855188141393, 'eval_f1': 0.3673257023933403, 'eval_accuracy': 0.9358449779973751, 'eval_runtime': 2.301, 'eval_samples_per_second': 665.359, 'eval_steps_per_second': 83.442, 'epoch': 4.0}
{'loss': 0.1071, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.20539842545986176, 'eval_precision': 0.3891625615763547, 'eval_recall': 0.3603192702394527, 'eval_f1': 0.37418590882178804, 'eval_accuracy': 0.9410947270902493, 'eval_runtime': 2.3402, 'eval_samples_per_second': 654.209, 'eval_steps_per_second': 82.043, 'epoch': 5.0}
{'loss': 0.0887, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.2106718271970749, 'eval_precision': 0.41133004926108374, 'eval_recall': 0.3808437856328392, 'eval_f1': 0.39550029603315573, 'eval_accuracy': 0.9409017216088937, 'eval_runtime': 2.2842, 'eval_samples_per_second': 670.253, 'eval_steps_per_second': 84.055, 'epoch': 6.0}
{'loss': 0.0834, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': 0.22852253913879395, 'eval_precision': 0.3762597984322508, 'eval_recall': 0.3831242873432155, 'eval_f1': 0.37966101694915255, 'eval_accuracy': 0.9378908360997452, 'eval_runtime': 2.2814, 'eval_samples_per_second': 671.065, 'eval_steps_per_second': 84.157, 'epoch': 7.0}
{'loss': 0.0708, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': 0.24255859851837158, 'eval_precision': 0.3549000951474786, 'eval_recall': 0.42531356898517675, 'eval_f1': 0.3869294605809128, 'eval_accuracy': 0.937813633907203, 'eval_runtime': 2.2884, 'eval_samples_per_second': 669.027, 'eval_steps_per_second': 83.902, 'epoch': 8.0}
{'loss': 0.0635, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': 0.239655002951622, 'eval_precision': 0.3612512613521695, 'eval_recall': 0.40820980615735464, 'eval_f1': 0.38329764453961457, 'eval_accuracy': 0.937234617463136, 'eval_runtime': 2.287, 'eval_samples_per_second': 669.439, 'eval_steps_per_second': 83.953, 'epoch': 9.0}
{'loss': 0.0549, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.25531184673309326, 'eval_precision': 0.391304347826087, 'eval_recall': 0.30786773090079816, 'eval_f1': 0.3446075303126994, 'eval_accuracy': 0.941828147919401, 'eval_runtime': 2.2909, 'eval_samples_per_second': 668.286, 'eval_steps_per_second': 83.809, 'epoch': 10.0}
{'loss': 0.0537, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': 0.2544967234134674, 'eval_precision': 0.41252955082742315, 'eval_recall': 0.3979475484606613, 'eval_f1': 0.4051073708647707, 'eval_accuracy': 0.9417123446305875, 'eval_runtime': 2.3652, 'eval_samples_per_second': 647.294, 'eval_steps_per_second': 81.176, 'epoch': 11.0}
{'loss': 0.0487, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': 0.27949318289756775, 'eval_precision': 0.3848009650180941, 'eval_recall': 0.3637400228050171, 'eval_f1': 0.3739742086752638, 'eval_accuracy': 0.9405543117424535, 'eval_runtime': 2.2836, 'eval_samples_per_second': 670.446, 'eval_steps_per_second': 84.079, 'epoch': 12.0}
{'loss': 0.044, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': 0.2968433201313019, 'eval_precision': 0.3830227743271222, 'eval_recall': 0.4218928164196123, 'eval_f1': 0.4015192620727075, 'eval_accuracy': 0.9371188141743225, 'eval_runtime': 2.2907, 'eval_samples_per_second': 668.357, 'eval_steps_per_second': 83.818, 'epoch': 13.0}
{'loss': 0.0413, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': 0.2970845401287079, 'eval_precision': 0.43375174337517436, 'eval_recall': 0.35461801596351195, 'eval_f1': 0.3902132998745295, 'eval_accuracy': 0.9437968038292287, 'eval_runtime': 2.2808, 'eval_samples_per_second': 671.255, 'eval_steps_per_second': 84.181, 'epoch': 14.0}
{'loss': 0.0363, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': 0.29578307271003723, 'eval_precision': 0.36153846153846153, 'eval_recall': 0.3751425313568985, 'eval_f1': 0.3682148852825965, 'eval_accuracy': 0.937813633907203, 'eval_runtime': 2.282, 'eval_samples_per_second': 670.901, 'eval_steps_per_second': 84.137, 'epoch': 15.0}
{'loss': 0.0313, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.3132881224155426, 'eval_precision': 0.4057971014492754, 'eval_recall': 0.3831242873432155, 'eval_f1': 0.39413489736070384, 'eval_accuracy': 0.9407473172238091, 'eval_runtime': 2.2882, 'eval_samples_per_second': 669.098, 'eval_steps_per_second': 83.91, 'epoch': 16.0}
{'loss': 0.028, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': 0.3034823536872864, 'eval_precision': 0.41947115384615385, 'eval_recall': 0.3979475484606613, 'eval_f1': 0.40842598010532477, 'eval_accuracy': 0.9429089786149927, 'eval_runtime': 2.2811, 'eval_samples_per_second': 671.169, 'eval_steps_per_second': 84.17, 'epoch': 17.0}
{'loss': 0.0247, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': 0.30538836121559143, 'eval_precision': 0.3639921722113503, 'eval_recall': 0.4241733181299886, 'eval_f1': 0.39178515007898895, 'eval_accuracy': 0.9368100054041535, 'eval_runtime': 2.3802, 'eval_samples_per_second': 643.225, 'eval_steps_per_second': 80.666, 'epoch': 18.0}
{'loss': 0.0194, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': 0.3353293836116791, 'eval_precision': 0.4031710079275198, 'eval_recall': 0.40592930444697833, 'eval_f1': 0.40454545454545454, 'eval_accuracy': 0.9403613062610978, 'eval_runtime': 2.2999, 'eval_samples_per_second': 665.679, 'eval_steps_per_second': 83.482, 'epoch': 19.0}
{'loss': 0.0169, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': 0.3387598693370819, 'eval_precision': 0.3854692230070636, 'eval_recall': 0.43557582668187, 'eval_f1': 0.4089935760171306, 'eval_accuracy': 0.9388172624102524, 'eval_runtime': 2.3548, 'eval_samples_per_second': 650.17, 'eval_steps_per_second': 81.537, 'epoch': 20.0}
{'loss': 0.0139, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': 0.33999013900756836, 'eval_precision': 0.42054958183990443, 'eval_recall': 0.4013683010262258, 'eval_f1': 0.41073512252042005, 'eval_accuracy': 0.9417509457268587, 'eval_runtime': 2.2744, 'eval_samples_per_second': 673.142, 'eval_steps_per_second': 84.418, 'epoch': 21.0}
{'loss': 0.0122, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.35015401244163513, 'eval_precision': 0.40114285714285713, 'eval_recall': 0.40022805017103763, 'eval_f1': 0.4006849315068493, 'eval_accuracy': 0.940399907357369, 'eval_runtime': 2.2731, 'eval_samples_per_second': 673.518, 'eval_steps_per_second': 84.465, 'epoch': 22.0}
{'loss': 0.0101, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': 0.3552108407020569, 'eval_precision': 0.4116279069767442, 'eval_recall': 0.40364880273660203, 'eval_f1': 0.40759930915371323, 'eval_accuracy': 0.941287732571605, 'eval_runtime': 2.2878, 'eval_samples_per_second': 669.19, 'eval_steps_per_second': 83.922, 'epoch': 23.0}
{'loss': 0.009, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.35767993330955505, 'eval_precision': 0.4022857142857143, 'eval_recall': 0.4013683010262258, 'eval_f1': 0.40182648401826493, 'eval_accuracy': 0.9406701150312669, 'eval_runtime': 2.2761, 'eval_samples_per_second': 672.635, 'eval_steps_per_second': 84.354, 'epoch': 24.0}
{'train_runtime': 789.7267, 'train_samples_per_second': 262.39, 'train_steps_per_second': 6.564, 'train_loss': 0.06824991428925667, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0682
  train_runtime            = 0:13:09.72
  train_samples            =       8634
  train_samples_per_second =     262.39
  train_steps_per_second   =      6.564
[{'loss': 0.2837, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.21498994529247284, 'eval_precision': 0.4099616858237548, 'eval_recall': 0.12200684150513112, 'eval_f1': 0.18804920913884007, 'eval_accuracy': 0.9374276229444917, 'eval_runtime': 2.3103, 'eval_samples_per_second': 662.676, 'eval_steps_per_second': 83.105, 'epoch': 1.0, 'step': 216}, {'loss': 0.2052, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 432}, {'eval_loss': 0.19285044074058533, 'eval_precision': 0.47911547911547914, 'eval_recall': 0.22234891676168758, 'eval_f1': 0.3037383177570094, 'eval_accuracy': 0.9436037983478731, 'eval_runtime': 2.284, 'eval_samples_per_second': 670.328, 'eval_steps_per_second': 84.065, 'epoch': 2.0, 'step': 432}, {'loss': 0.1618, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 648}, {'eval_loss': 0.1882469803094864, 'eval_precision': 0.3722060252672498, 'eval_recall': 0.43671607753705816, 'eval_f1': 0.40188877229800635, 'eval_accuracy': 0.9357677758048328, 'eval_runtime': 2.2828, 'eval_samples_per_second': 670.658, 'eval_steps_per_second': 84.106, 'epoch': 3.0, 'step': 648}, {'loss': 0.1292, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 864}, {'eval_loss': 0.19925622642040253, 'eval_precision': 0.33779904306220093, 'eval_recall': 0.40250855188141393, 'eval_f1': 0.3673257023933403, 'eval_accuracy': 0.9358449779973751, 'eval_runtime': 2.301, 'eval_samples_per_second': 665.359, 'eval_steps_per_second': 83.442, 'epoch': 4.0, 'step': 864}, {'loss': 0.1071, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 1080}, {'eval_loss': 0.20539842545986176, 'eval_precision': 0.3891625615763547, 'eval_recall': 0.3603192702394527, 'eval_f1': 0.37418590882178804, 'eval_accuracy': 0.9410947270902493, 'eval_runtime': 2.3402, 'eval_samples_per_second': 654.209, 'eval_steps_per_second': 82.043, 'epoch': 5.0, 'step': 1080}, {'loss': 0.0887, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 1296}, {'eval_loss': 0.2106718271970749, 'eval_precision': 0.41133004926108374, 'eval_recall': 0.3808437856328392, 'eval_f1': 0.39550029603315573, 'eval_accuracy': 0.9409017216088937, 'eval_runtime': 2.2842, 'eval_samples_per_second': 670.253, 'eval_steps_per_second': 84.055, 'epoch': 6.0, 'step': 1296}, {'loss': 0.0834, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 1512}, {'eval_loss': 0.22852253913879395, 'eval_precision': 0.3762597984322508, 'eval_recall': 0.3831242873432155, 'eval_f1': 0.37966101694915255, 'eval_accuracy': 0.9378908360997452, 'eval_runtime': 2.2814, 'eval_samples_per_second': 671.065, 'eval_steps_per_second': 84.157, 'epoch': 7.0, 'step': 1512}, {'loss': 0.0708, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1728}, {'eval_loss': 0.24255859851837158, 'eval_precision': 0.3549000951474786, 'eval_recall': 0.42531356898517675, 'eval_f1': 0.3869294605809128, 'eval_accuracy': 0.937813633907203, 'eval_runtime': 2.2884, 'eval_samples_per_second': 669.027, 'eval_steps_per_second': 83.902, 'epoch': 8.0, 'step': 1728}, {'loss': 0.0635, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1944}, {'eval_loss': 0.239655002951622, 'eval_precision': 0.3612512613521695, 'eval_recall': 0.40820980615735464, 'eval_f1': 0.38329764453961457, 'eval_accuracy': 0.937234617463136, 'eval_runtime': 2.287, 'eval_samples_per_second': 669.439, 'eval_steps_per_second': 83.953, 'epoch': 9.0, 'step': 1944}, {'loss': 0.0549, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 2160}, {'eval_loss': 0.25531184673309326, 'eval_precision': 0.391304347826087, 'eval_recall': 0.30786773090079816, 'eval_f1': 0.3446075303126994, 'eval_accuracy': 0.941828147919401, 'eval_runtime': 2.2909, 'eval_samples_per_second': 668.286, 'eval_steps_per_second': 83.809, 'epoch': 10.0, 'step': 2160}, {'loss': 0.0537, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 2376}, {'eval_loss': 0.2544967234134674, 'eval_precision': 0.41252955082742315, 'eval_recall': 0.3979475484606613, 'eval_f1': 0.4051073708647707, 'eval_accuracy': 0.9417123446305875, 'eval_runtime': 2.3652, 'eval_samples_per_second': 647.294, 'eval_steps_per_second': 81.176, 'epoch': 11.0, 'step': 2376}, {'loss': 0.0487, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 2592}, {'eval_loss': 0.27949318289756775, 'eval_precision': 0.3848009650180941, 'eval_recall': 0.3637400228050171, 'eval_f1': 0.3739742086752638, 'eval_accuracy': 0.9405543117424535, 'eval_runtime': 2.2836, 'eval_samples_per_second': 670.446, 'eval_steps_per_second': 84.079, 'epoch': 12.0, 'step': 2592}, {'loss': 0.044, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 2808}, {'eval_loss': 0.2968433201313019, 'eval_precision': 0.3830227743271222, 'eval_recall': 0.4218928164196123, 'eval_f1': 0.4015192620727075, 'eval_accuracy': 0.9371188141743225, 'eval_runtime': 2.2907, 'eval_samples_per_second': 668.357, 'eval_steps_per_second': 83.818, 'epoch': 13.0, 'step': 2808}, {'loss': 0.0413, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 3024}, {'eval_loss': 0.2970845401287079, 'eval_precision': 0.43375174337517436, 'eval_recall': 0.35461801596351195, 'eval_f1': 0.3902132998745295, 'eval_accuracy': 0.9437968038292287, 'eval_runtime': 2.2808, 'eval_samples_per_second': 671.255, 'eval_steps_per_second': 84.181, 'epoch': 14.0, 'step': 3024}, {'loss': 0.0363, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 3240}, {'eval_loss': 0.29578307271003723, 'eval_precision': 0.36153846153846153, 'eval_recall': 0.3751425313568985, 'eval_f1': 0.3682148852825965, 'eval_accuracy': 0.937813633907203, 'eval_runtime': 2.282, 'eval_samples_per_second': 670.901, 'eval_steps_per_second': 84.137, 'epoch': 15.0, 'step': 3240}, {'loss': 0.0313, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 3456}, {'eval_loss': 0.3132881224155426, 'eval_precision': 0.4057971014492754, 'eval_recall': 0.3831242873432155, 'eval_f1': 0.39413489736070384, 'eval_accuracy': 0.9407473172238091, 'eval_runtime': 2.2882, 'eval_samples_per_second': 669.098, 'eval_steps_per_second': 83.91, 'epoch': 16.0, 'step': 3456}, {'loss': 0.028, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 3672}, {'eval_loss': 0.3034823536872864, 'eval_precision': 0.41947115384615385, 'eval_recall': 0.3979475484606613, 'eval_f1': 0.40842598010532477, 'eval_accuracy': 0.9429089786149927, 'eval_runtime': 2.2811, 'eval_samples_per_second': 671.169, 'eval_steps_per_second': 84.17, 'epoch': 17.0, 'step': 3672}, {'loss': 0.0247, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 3888}, {'eval_loss': 0.30538836121559143, 'eval_precision': 0.3639921722113503, 'eval_recall': 0.4241733181299886, 'eval_f1': 0.39178515007898895, 'eval_accuracy': 0.9368100054041535, 'eval_runtime': 2.3802, 'eval_samples_per_second': 643.225, 'eval_steps_per_second': 80.666, 'epoch': 18.0, 'step': 3888}, {'loss': 0.0194, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 4104}, {'eval_loss': 0.3353293836116791, 'eval_precision': 0.4031710079275198, 'eval_recall': 0.40592930444697833, 'eval_f1': 0.40454545454545454, 'eval_accuracy': 0.9403613062610978, 'eval_runtime': 2.2999, 'eval_samples_per_second': 665.679, 'eval_steps_per_second': 83.482, 'epoch': 19.0, 'step': 4104}, {'loss': 0.0169, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 4320}, {'eval_loss': 0.3387598693370819, 'eval_precision': 0.3854692230070636, 'eval_recall': 0.43557582668187, 'eval_f1': 0.4089935760171306, 'eval_accuracy': 0.9388172624102524, 'eval_runtime': 2.3548, 'eval_samples_per_second': 650.17, 'eval_steps_per_second': 81.537, 'epoch': 20.0, 'step': 4320}, {'loss': 0.0139, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 4536}, {'eval_loss': 0.33999013900756836, 'eval_precision': 0.42054958183990443, 'eval_recall': 0.4013683010262258, 'eval_f1': 0.41073512252042005, 'eval_accuracy': 0.9417509457268587, 'eval_runtime': 2.2744, 'eval_samples_per_second': 673.142, 'eval_steps_per_second': 84.418, 'epoch': 21.0, 'step': 4536}, {'loss': 0.0122, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 4752}, {'eval_loss': 0.35015401244163513, 'eval_precision': 0.40114285714285713, 'eval_recall': 0.40022805017103763, 'eval_f1': 0.4006849315068493, 'eval_accuracy': 0.940399907357369, 'eval_runtime': 2.2731, 'eval_samples_per_second': 673.518, 'eval_steps_per_second': 84.465, 'epoch': 22.0, 'step': 4752}, {'loss': 0.0101, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 4968}, {'eval_loss': 0.3552108407020569, 'eval_precision': 0.4116279069767442, 'eval_recall': 0.40364880273660203, 'eval_f1': 0.40759930915371323, 'eval_accuracy': 0.941287732571605, 'eval_runtime': 2.2878, 'eval_samples_per_second': 669.19, 'eval_steps_per_second': 83.922, 'epoch': 23.0, 'step': 4968}, {'loss': 0.009, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 5184}, {'eval_loss': 0.35767993330955505, 'eval_precision': 0.4022857142857143, 'eval_recall': 0.4013683010262258, 'eval_f1': 0.40182648401826493, 'eval_accuracy': 0.9406701150312669, 'eval_runtime': 2.2761, 'eval_samples_per_second': 672.635, 'eval_steps_per_second': 84.354, 'epoch': 24.0, 'step': 5184}, {'train_runtime': 789.7267, 'train_samples_per_second': 262.39, 'train_steps_per_second': 6.564, 'total_flos': 7390962891524160.0, 'train_loss': 0.06824991428925667, 'epoch': 24.0, 'step': 5184}]

Evaluation, ltg/norbert
***** predict metrics *****
  predict_accuracy           =     0.9333
  predict_f1                 =     0.3559
  predict_loss               =     0.1934
  predict_precision          =     0.3298
  predict_recall             =     0.3864
  predict_runtime            = 0:00:01.91
  predict_samples_per_second =    664.641
  predict_steps_per_second   =      83.08
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_1_09.json completed. F1: 0.3558897243107769
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_17.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at ltg/norbert2 and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_17.json
01170939_tsa-bin_NorBERT_2 Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6042.41 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 7019.87 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 7025.33 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 7172.68 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 7282.34 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7443.53 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6554.80 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6944.51 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 7014.44 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7795.25 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 7379.29 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7481.96 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 7253.52 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
01170939_tsa-bin_NorBERT_2 Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2152, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0}
{'eval_loss': 0.16151946783065796, 'eval_precision': 0.4254215304798962, 'eval_recall': 0.37400228050171036, 'eval_f1': 0.39805825242718446, 'eval_accuracy': 0.9444144213695669, 'eval_runtime': 2.3398, 'eval_samples_per_second': 654.332, 'eval_steps_per_second': 82.059, 'epoch': 1.0}
{'loss': 0.1144, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0}
{'eval_loss': 0.16848087310791016, 'eval_precision': 0.46102150537634407, 'eval_recall': 0.39110604332953247, 'eval_f1': 0.4231955582973473, 'eval_accuracy': 0.9462286728943102, 'eval_runtime': 2.2515, 'eval_samples_per_second': 679.988, 'eval_steps_per_second': 85.276, 'epoch': 2.0}
{'loss': 0.0549, 'learning_rate': 8.75e-05, 'epoch': 3.0}
{'eval_loss': 0.24351675808429718, 'eval_precision': 0.36442687747035574, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.4304388422035481, 'eval_accuracy': 0.9321392727553462, 'eval_runtime': 2.2447, 'eval_samples_per_second': 682.055, 'eval_steps_per_second': 85.535, 'epoch': 3.0}
{'loss': 0.0328, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0}
{'eval_loss': 0.26873183250427246, 'eval_precision': 0.391651865008881, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.4403394907638542, 'eval_accuracy': 0.9379294371960164, 'eval_runtime': 2.2472, 'eval_samples_per_second': 681.289, 'eval_steps_per_second': 85.439, 'epoch': 4.0}
{'loss': 0.0201, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0}
{'eval_loss': 0.2813171446323395, 'eval_precision': 0.4262734584450402, 'eval_recall': 0.36259977194982895, 'eval_f1': 0.39186691312384475, 'eval_accuracy': 0.9439126071180421, 'eval_runtime': 2.2385, 'eval_samples_per_second': 683.951, 'eval_steps_per_second': 85.773, 'epoch': 5.0}
{'loss': 0.012, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.3406717777252197, 'eval_precision': 0.4599728629579376, 'eval_recall': 0.3865450399087799, 'eval_f1': 0.42007434944237915, 'eval_accuracy': 0.9435265961553309, 'eval_runtime': 2.2397, 'eval_samples_per_second': 683.574, 'eval_steps_per_second': 85.726, 'epoch': 6.0}
{'loss': 0.0097, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0}
{'eval_loss': 0.315421998500824, 'eval_precision': 0.41754385964912283, 'eval_recall': 0.4070695553021665, 'eval_f1': 0.41224018475750573, 'eval_accuracy': 0.9424071643634679, 'eval_runtime': 2.252, 'eval_samples_per_second': 679.842, 'eval_steps_per_second': 85.258, 'epoch': 7.0}
{'loss': 0.0086, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0}
{'eval_loss': 0.3534276783466339, 'eval_precision': 0.36065573770491804, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.41964711492608486, 'eval_accuracy': 0.9307110321933143, 'eval_runtime': 2.2527, 'eval_samples_per_second': 679.62, 'eval_steps_per_second': 85.23, 'epoch': 8.0}
{'loss': 0.0058, 'learning_rate': 6.25e-05, 'epoch': 9.0}
{'eval_loss': 0.39056479930877686, 'eval_precision': 0.36654135338345867, 'eval_recall': 0.44469783352337516, 'eval_f1': 0.401854714064915, 'eval_accuracy': 0.9347255462055122, 'eval_runtime': 2.3273, 'eval_samples_per_second': 657.847, 'eval_steps_per_second': 82.499, 'epoch': 9.0}
{'loss': 0.0049, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0}
{'eval_loss': 0.3744071424007416, 'eval_precision': 0.4222222222222222, 'eval_recall': 0.41163055872291904, 'eval_f1': 0.4168591224018476, 'eval_accuracy': 0.9408245194163515, 'eval_runtime': 2.2489, 'eval_samples_per_second': 680.771, 'eval_steps_per_second': 85.374, 'epoch': 10.0}
{'loss': 0.0036, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0}
{'eval_loss': 0.39632031321525574, 'eval_precision': 0.40489432703003336, 'eval_recall': 0.4150513112884835, 'eval_f1': 0.40990990990990994, 'eval_accuracy': 0.9404771095499113, 'eval_runtime': 2.2853, 'eval_samples_per_second': 669.94, 'eval_steps_per_second': 84.016, 'epoch': 11.0}
{'loss': 0.0024, 'learning_rate': 5e-05, 'epoch': 12.0}
{'eval_loss': 0.41462016105651855, 'eval_precision': 0.4324970131421744, 'eval_recall': 0.4127708095781072, 'eval_f1': 0.4224037339556593, 'eval_accuracy': 0.9408245194163515, 'eval_runtime': 2.2502, 'eval_samples_per_second': 680.398, 'eval_steps_per_second': 85.328, 'epoch': 12.0}
{'loss': 0.0021, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0}
{'eval_loss': 0.4230839014053345, 'eval_precision': 0.41088580576307365, 'eval_recall': 0.43899657924743446, 'eval_f1': 0.4244762954796031, 'eval_accuracy': 0.9397822898170308, 'eval_runtime': 2.2446, 'eval_samples_per_second': 682.083, 'eval_steps_per_second': 85.539, 'epoch': 13.0}
{'loss': 0.0028, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0}
{'eval_loss': 0.4021161198616028, 'eval_precision': 0.3983739837398374, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.42127888232133265, 'eval_accuracy': 0.9395120821431329, 'eval_runtime': 2.2445, 'eval_samples_per_second': 682.1, 'eval_steps_per_second': 85.541, 'epoch': 14.0}
{'loss': 0.0017, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0}
{'eval_loss': 0.42582154273986816, 'eval_precision': 0.4108170310701956, 'eval_recall': 0.4070695553021665, 'eval_f1': 0.40893470790378006, 'eval_accuracy': 0.9396278854319463, 'eval_runtime': 2.2474, 'eval_samples_per_second': 681.232, 'eval_steps_per_second': 85.432, 'epoch': 15.0}
{'loss': 0.0011, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0}
{'eval_loss': 0.43860486149787903, 'eval_precision': 0.4117647058823529, 'eval_recall': 0.4070695553021665, 'eval_f1': 0.40940366972477066, 'eval_accuracy': 0.9412491314753338, 'eval_runtime': 2.2472, 'eval_samples_per_second': 681.302, 'eval_steps_per_second': 85.441, 'epoch': 16.0}
{'loss': 0.001, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0}
{'eval_loss': 0.4116874039173126, 'eval_precision': 0.43270300333704115, 'eval_recall': 0.443557582668187, 'eval_f1': 0.4380630630630631, 'eval_accuracy': 0.940399907357369, 'eval_runtime': 2.3312, 'eval_samples_per_second': 656.743, 'eval_steps_per_second': 82.361, 'epoch': 17.0}
{'loss': 0.0005, 'learning_rate': 2.5e-05, 'epoch': 18.0}
{'eval_loss': 0.44774672389030457, 'eval_precision': 0.4434673366834171, 'eval_recall': 0.40250855188141393, 'eval_f1': 0.42199641362821283, 'eval_accuracy': 0.9431405851926195, 'eval_runtime': 2.2437, 'eval_samples_per_second': 682.367, 'eval_steps_per_second': 85.574, 'epoch': 18.0}
{'loss': 0.0005, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0}
{'eval_loss': 0.4584161937236786, 'eval_precision': 0.4308571428571429, 'eval_recall': 0.4298745724059293, 'eval_f1': 0.43036529680365293, 'eval_accuracy': 0.9414807380529607, 'eval_runtime': 2.2621, 'eval_samples_per_second': 676.815, 'eval_steps_per_second': 84.878, 'epoch': 19.0}
{'loss': 0.0003, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0}
{'eval_loss': 0.4658433496952057, 'eval_precision': 0.4420289855072464, 'eval_recall': 0.41733181299885974, 'eval_f1': 0.429325513196481, 'eval_accuracy': 0.9430247819038061, 'eval_runtime': 2.2499, 'eval_samples_per_second': 680.487, 'eval_steps_per_second': 85.339, 'epoch': 20.0}
{'loss': 0.0001, 'learning_rate': 1.25e-05, 'epoch': 21.0}
{'eval_loss': 0.48517775535583496, 'eval_precision': 0.4308390022675737, 'eval_recall': 0.43329532497149376, 'eval_f1': 0.43206367254121664, 'eval_accuracy': 0.941828147919401, 'eval_runtime': 2.2457, 'eval_samples_per_second': 681.735, 'eval_steps_per_second': 85.495, 'epoch': 21.0}
{'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0}
{'eval_loss': 0.48329174518585205, 'eval_precision': 0.44155844155844154, 'eval_recall': 0.4264538198403649, 'eval_f1': 0.4338747099767982, 'eval_accuracy': 0.9432563884814329, 'eval_runtime': 2.2505, 'eval_samples_per_second': 680.29, 'eval_steps_per_second': 85.314, 'epoch': 22.0}
{'loss': 0.0002, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0}
{'eval_loss': 0.4822247624397278, 'eval_precision': 0.4413472706155633, 'eval_recall': 0.43329532497149376, 'eval_f1': 0.4372842347525892, 'eval_accuracy': 0.9429089786149927, 'eval_runtime': 2.2416, 'eval_samples_per_second': 682.985, 'eval_steps_per_second': 85.652, 'epoch': 23.0}
{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.48350074887275696, 'eval_precision': 0.4375, 'eval_recall': 0.43101482326111745, 'eval_f1': 0.43423319931074095, 'eval_accuracy': 0.9428317764224504, 'eval_runtime': 2.2413, 'eval_samples_per_second': 683.075, 'eval_steps_per_second': 85.663, 'epoch': 24.0}
{'train_runtime': 755.5995, 'train_samples_per_second': 274.241, 'train_steps_per_second': 6.861, 'train_loss': 0.020612411285077945, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0206
  train_runtime            = 0:12:35.59
  train_samples            =       8634
  train_samples_per_second =    274.241
  train_steps_per_second   =      6.861
[{'loss': 0.2152, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.16151946783065796, 'eval_precision': 0.4254215304798962, 'eval_recall': 0.37400228050171036, 'eval_f1': 0.39805825242718446, 'eval_accuracy': 0.9444144213695669, 'eval_runtime': 2.3398, 'eval_samples_per_second': 654.332, 'eval_steps_per_second': 82.059, 'epoch': 1.0, 'step': 216}, {'loss': 0.1144, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0, 'step': 432}, {'eval_loss': 0.16848087310791016, 'eval_precision': 0.46102150537634407, 'eval_recall': 0.39110604332953247, 'eval_f1': 0.4231955582973473, 'eval_accuracy': 0.9462286728943102, 'eval_runtime': 2.2515, 'eval_samples_per_second': 679.988, 'eval_steps_per_second': 85.276, 'epoch': 2.0, 'step': 432}, {'loss': 0.0549, 'learning_rate': 8.75e-05, 'epoch': 3.0, 'step': 648}, {'eval_loss': 0.24351675808429718, 'eval_precision': 0.36442687747035574, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.4304388422035481, 'eval_accuracy': 0.9321392727553462, 'eval_runtime': 2.2447, 'eval_samples_per_second': 682.055, 'eval_steps_per_second': 85.535, 'epoch': 3.0, 'step': 648}, {'loss': 0.0328, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0, 'step': 864}, {'eval_loss': 0.26873183250427246, 'eval_precision': 0.391651865008881, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.4403394907638542, 'eval_accuracy': 0.9379294371960164, 'eval_runtime': 2.2472, 'eval_samples_per_second': 681.289, 'eval_steps_per_second': 85.439, 'epoch': 4.0, 'step': 864}, {'loss': 0.0201, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0, 'step': 1080}, {'eval_loss': 0.2813171446323395, 'eval_precision': 0.4262734584450402, 'eval_recall': 0.36259977194982895, 'eval_f1': 0.39186691312384475, 'eval_accuracy': 0.9439126071180421, 'eval_runtime': 2.2385, 'eval_samples_per_second': 683.951, 'eval_steps_per_second': 85.773, 'epoch': 5.0, 'step': 1080}, {'loss': 0.012, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0, 'step': 1296}, {'eval_loss': 0.3406717777252197, 'eval_precision': 0.4599728629579376, 'eval_recall': 0.3865450399087799, 'eval_f1': 0.42007434944237915, 'eval_accuracy': 0.9435265961553309, 'eval_runtime': 2.2397, 'eval_samples_per_second': 683.574, 'eval_steps_per_second': 85.726, 'epoch': 6.0, 'step': 1296}, {'loss': 0.0097, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0, 'step': 1512}, {'eval_loss': 0.315421998500824, 'eval_precision': 0.41754385964912283, 'eval_recall': 0.4070695553021665, 'eval_f1': 0.41224018475750573, 'eval_accuracy': 0.9424071643634679, 'eval_runtime': 2.252, 'eval_samples_per_second': 679.842, 'eval_steps_per_second': 85.258, 'epoch': 7.0, 'step': 1512}, {'loss': 0.0086, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0, 'step': 1728}, {'eval_loss': 0.3534276783466339, 'eval_precision': 0.36065573770491804, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.41964711492608486, 'eval_accuracy': 0.9307110321933143, 'eval_runtime': 2.2527, 'eval_samples_per_second': 679.62, 'eval_steps_per_second': 85.23, 'epoch': 8.0, 'step': 1728}, {'loss': 0.0058, 'learning_rate': 6.25e-05, 'epoch': 9.0, 'step': 1944}, {'eval_loss': 0.39056479930877686, 'eval_precision': 0.36654135338345867, 'eval_recall': 0.44469783352337516, 'eval_f1': 0.401854714064915, 'eval_accuracy': 0.9347255462055122, 'eval_runtime': 2.3273, 'eval_samples_per_second': 657.847, 'eval_steps_per_second': 82.499, 'epoch': 9.0, 'step': 1944}, {'loss': 0.0049, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0, 'step': 2160}, {'eval_loss': 0.3744071424007416, 'eval_precision': 0.4222222222222222, 'eval_recall': 0.41163055872291904, 'eval_f1': 0.4168591224018476, 'eval_accuracy': 0.9408245194163515, 'eval_runtime': 2.2489, 'eval_samples_per_second': 680.771, 'eval_steps_per_second': 85.374, 'epoch': 10.0, 'step': 2160}, {'loss': 0.0036, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0, 'step': 2376}, {'eval_loss': 0.39632031321525574, 'eval_precision': 0.40489432703003336, 'eval_recall': 0.4150513112884835, 'eval_f1': 0.40990990990990994, 'eval_accuracy': 0.9404771095499113, 'eval_runtime': 2.2853, 'eval_samples_per_second': 669.94, 'eval_steps_per_second': 84.016, 'epoch': 11.0, 'step': 2376}, {'loss': 0.0024, 'learning_rate': 5e-05, 'epoch': 12.0, 'step': 2592}, {'eval_loss': 0.41462016105651855, 'eval_precision': 0.4324970131421744, 'eval_recall': 0.4127708095781072, 'eval_f1': 0.4224037339556593, 'eval_accuracy': 0.9408245194163515, 'eval_runtime': 2.2502, 'eval_samples_per_second': 680.398, 'eval_steps_per_second': 85.328, 'epoch': 12.0, 'step': 2592}, {'loss': 0.0021, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0, 'step': 2808}, {'eval_loss': 0.4230839014053345, 'eval_precision': 0.41088580576307365, 'eval_recall': 0.43899657924743446, 'eval_f1': 0.4244762954796031, 'eval_accuracy': 0.9397822898170308, 'eval_runtime': 2.2446, 'eval_samples_per_second': 682.083, 'eval_steps_per_second': 85.539, 'epoch': 13.0, 'step': 2808}, {'loss': 0.0028, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0, 'step': 3024}, {'eval_loss': 0.4021161198616028, 'eval_precision': 0.3983739837398374, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.42127888232133265, 'eval_accuracy': 0.9395120821431329, 'eval_runtime': 2.2445, 'eval_samples_per_second': 682.1, 'eval_steps_per_second': 85.541, 'epoch': 14.0, 'step': 3024}, {'loss': 0.0017, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0, 'step': 3240}, {'eval_loss': 0.42582154273986816, 'eval_precision': 0.4108170310701956, 'eval_recall': 0.4070695553021665, 'eval_f1': 0.40893470790378006, 'eval_accuracy': 0.9396278854319463, 'eval_runtime': 2.2474, 'eval_samples_per_second': 681.232, 'eval_steps_per_second': 85.432, 'epoch': 15.0, 'step': 3240}, {'loss': 0.0011, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0, 'step': 3456}, {'eval_loss': 0.43860486149787903, 'eval_precision': 0.4117647058823529, 'eval_recall': 0.4070695553021665, 'eval_f1': 0.40940366972477066, 'eval_accuracy': 0.9412491314753338, 'eval_runtime': 2.2472, 'eval_samples_per_second': 681.302, 'eval_steps_per_second': 85.441, 'epoch': 16.0, 'step': 3456}, {'loss': 0.001, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0, 'step': 3672}, {'eval_loss': 0.4116874039173126, 'eval_precision': 0.43270300333704115, 'eval_recall': 0.443557582668187, 'eval_f1': 0.4380630630630631, 'eval_accuracy': 0.940399907357369, 'eval_runtime': 2.3312, 'eval_samples_per_second': 656.743, 'eval_steps_per_second': 82.361, 'epoch': 17.0, 'step': 3672}, {'loss': 0.0005, 'learning_rate': 2.5e-05, 'epoch': 18.0, 'step': 3888}, {'eval_loss': 0.44774672389030457, 'eval_precision': 0.4434673366834171, 'eval_recall': 0.40250855188141393, 'eval_f1': 0.42199641362821283, 'eval_accuracy': 0.9431405851926195, 'eval_runtime': 2.2437, 'eval_samples_per_second': 682.367, 'eval_steps_per_second': 85.574, 'epoch': 18.0, 'step': 3888}, {'loss': 0.0005, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0, 'step': 4104}, {'eval_loss': 0.4584161937236786, 'eval_precision': 0.4308571428571429, 'eval_recall': 0.4298745724059293, 'eval_f1': 0.43036529680365293, 'eval_accuracy': 0.9414807380529607, 'eval_runtime': 2.2621, 'eval_samples_per_second': 676.815, 'eval_steps_per_second': 84.878, 'epoch': 19.0, 'step': 4104}, {'loss': 0.0003, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0, 'step': 4320}, {'eval_loss': 0.4658433496952057, 'eval_precision': 0.4420289855072464, 'eval_recall': 0.41733181299885974, 'eval_f1': 0.429325513196481, 'eval_accuracy': 0.9430247819038061, 'eval_runtime': 2.2499, 'eval_samples_per_second': 680.487, 'eval_steps_per_second': 85.339, 'epoch': 20.0, 'step': 4320}, {'loss': 0.0001, 'learning_rate': 1.25e-05, 'epoch': 21.0, 'step': 4536}, {'eval_loss': 0.48517775535583496, 'eval_precision': 0.4308390022675737, 'eval_recall': 0.43329532497149376, 'eval_f1': 0.43206367254121664, 'eval_accuracy': 0.941828147919401, 'eval_runtime': 2.2457, 'eval_samples_per_second': 681.735, 'eval_steps_per_second': 85.495, 'epoch': 21.0, 'step': 4536}, {'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0, 'step': 4752}, {'eval_loss': 0.48329174518585205, 'eval_precision': 0.44155844155844154, 'eval_recall': 0.4264538198403649, 'eval_f1': 0.4338747099767982, 'eval_accuracy': 0.9432563884814329, 'eval_runtime': 2.2505, 'eval_samples_per_second': 680.29, 'eval_steps_per_second': 85.314, 'epoch': 22.0, 'step': 4752}, {'loss': 0.0002, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0, 'step': 4968}, {'eval_loss': 0.4822247624397278, 'eval_precision': 0.4413472706155633, 'eval_recall': 0.43329532497149376, 'eval_f1': 0.4372842347525892, 'eval_accuracy': 0.9429089786149927, 'eval_runtime': 2.2416, 'eval_samples_per_second': 682.985, 'eval_steps_per_second': 85.652, 'epoch': 23.0, 'step': 4968}, {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 5184}, {'eval_loss': 0.48350074887275696, 'eval_precision': 0.4375, 'eval_recall': 0.43101482326111745, 'eval_f1': 0.43423319931074095, 'eval_accuracy': 0.9428317764224504, 'eval_runtime': 2.2413, 'eval_samples_per_second': 683.075, 'eval_steps_per_second': 85.663, 'epoch': 24.0, 'step': 5184}, {'train_runtime': 755.5995, 'train_samples_per_second': 274.241, 'train_steps_per_second': 6.861, 'total_flos': 6810645841644840.0, 'train_loss': 0.020612411285077945, 'epoch': 24.0, 'step': 5184}]

Evaluation, ltg/norbert2
***** predict metrics *****
  predict_accuracy           =     0.9434
  predict_f1                 =     0.3647
  predict_loss               =      0.177
  predict_precision          =     0.4046
  predict_recall             =      0.332
  predict_runtime            = 0:00:01.88
  predict_samples_per_second =    675.528
  predict_steps_per_second   =     84.441
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_17.json completed. F1: 0.3647234678624813
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_39.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at NbAiLab/nb-bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_39.json
01170939_tsa-bin_NB-BERT_base Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 5794.35 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 6694.07 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6701.12 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6787.72 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6889.25 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7033.69 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6239.91 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6550.82 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6636.19 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7257.80 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 4845.24 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6969.70 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6747.01 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
01170939_tsa-bin_NB-BERT_base Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2184, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0}
{'eval_loss': 0.15520046651363373, 'eval_precision': 0.4218289085545723, 'eval_recall': 0.48916761687571264, 'eval_f1': 0.4530095036958817, 'eval_accuracy': 0.9457268586427855, 'eval_runtime': 2.3891, 'eval_samples_per_second': 640.827, 'eval_steps_per_second': 80.365, 'epoch': 1.0}
{'loss': 0.1307, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0}
{'eval_loss': 0.1585230678319931, 'eval_precision': 0.4463276836158192, 'eval_recall': 0.540478905359179, 'eval_f1': 0.4889118102114492, 'eval_accuracy': 0.9451478421987184, 'eval_runtime': 2.7936, 'eval_samples_per_second': 548.036, 'eval_steps_per_second': 68.728, 'epoch': 2.0}
{'loss': 0.0758, 'learning_rate': 8.75e-05, 'epoch': 3.0}
{'eval_loss': 0.16640682518482208, 'eval_precision': 0.525, 'eval_recall': 0.4549600912200684, 'eval_f1': 0.48747709224190594, 'eval_accuracy': 0.9509766077356597, 'eval_runtime': 2.4287, 'eval_samples_per_second': 630.386, 'eval_steps_per_second': 79.056, 'epoch': 3.0}
{'loss': 0.0445, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0}
{'eval_loss': 0.21569842100143433, 'eval_precision': 0.46483516483516485, 'eval_recall': 0.4823261117445838, 'eval_f1': 0.47341913822048126, 'eval_accuracy': 0.9456496564502432, 'eval_runtime': 2.3712, 'eval_samples_per_second': 645.661, 'eval_steps_per_second': 80.971, 'epoch': 4.0}
{'loss': 0.0281, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0}
{'eval_loss': 0.22960680723190308, 'eval_precision': 0.47362869198312235, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.49205479452054796, 'eval_accuracy': 0.9471550992048174, 'eval_runtime': 2.3738, 'eval_samples_per_second': 644.958, 'eval_steps_per_second': 80.883, 'epoch': 5.0}
{'loss': 0.0182, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.2590194344520569, 'eval_precision': 0.44660194174757284, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.4824331410592554, 'eval_accuracy': 0.9472323013973597, 'eval_runtime': 2.3808, 'eval_samples_per_second': 643.055, 'eval_steps_per_second': 80.644, 'epoch': 6.0}
{'loss': 0.0127, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0}
{'eval_loss': 0.2669265568256378, 'eval_precision': 0.45754245754245754, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.4877529286474973, 'eval_accuracy': 0.9468462904346483, 'eval_runtime': 2.3773, 'eval_samples_per_second': 644.017, 'eval_steps_per_second': 80.765, 'epoch': 7.0}
{'loss': 0.0098, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0}
{'eval_loss': 0.2855277955532074, 'eval_precision': 0.43884892086330934, 'eval_recall': 0.556442417331813, 'eval_f1': 0.4906988436400201, 'eval_accuracy': 0.9449934378136339, 'eval_runtime': 2.3802, 'eval_samples_per_second': 643.236, 'eval_steps_per_second': 80.667, 'epoch': 8.0}
{'loss': 0.0064, 'learning_rate': 6.25e-05, 'epoch': 9.0}
{'eval_loss': 0.31080374121665955, 'eval_precision': 0.4677754677754678, 'eval_recall': 0.5131128848346637, 'eval_f1': 0.4893964110929853, 'eval_accuracy': 0.947888520033969, 'eval_runtime': 2.3794, 'eval_samples_per_second': 643.431, 'eval_steps_per_second': 80.692, 'epoch': 9.0}
{'loss': 0.0047, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0}
{'eval_loss': 0.3172037601470947, 'eval_precision': 0.5017103762827823, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.5017103762827823, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 2.3744, 'eval_samples_per_second': 644.807, 'eval_steps_per_second': 80.864, 'epoch': 10.0}
{'loss': 0.0036, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0}
{'eval_loss': 0.3413010239601135, 'eval_precision': 0.4687168610816543, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.4857142857142857, 'eval_accuracy': 0.9470006948197329, 'eval_runtime': 2.371, 'eval_samples_per_second': 645.72, 'eval_steps_per_second': 80.979, 'epoch': 11.0}
{'loss': 0.0028, 'learning_rate': 5e-05, 'epoch': 12.0}
{'eval_loss': 0.35158100724220276, 'eval_precision': 0.49035187287173665, 'eval_recall': 0.4925883694412771, 'eval_f1': 0.49146757679180886, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 2.3763, 'eval_samples_per_second': 644.282, 'eval_steps_per_second': 80.798, 'epoch': 12.0}
{'loss': 0.002, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0}
{'eval_loss': 0.3669762909412384, 'eval_precision': 0.5084134615384616, 'eval_recall': 0.4823261117445838, 'eval_f1': 0.4950263311878292, 'eval_accuracy': 0.9491623562109164, 'eval_runtime': 2.3775, 'eval_samples_per_second': 643.962, 'eval_steps_per_second': 80.758, 'epoch': 13.0}
{'loss': 0.0016, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0}
{'eval_loss': 0.35878637433052063, 'eval_precision': 0.4936268829663963, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.4896551724137931, 'eval_accuracy': 0.9498957770400679, 'eval_runtime': 2.373, 'eval_samples_per_second': 645.185, 'eval_steps_per_second': 80.912, 'epoch': 14.0}
{'loss': 0.002, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0}
{'eval_loss': 0.35800623893737793, 'eval_precision': 0.4911699779249448, 'eval_recall': 0.507411630558723, 'eval_f1': 0.49915872125630956, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 2.4735, 'eval_samples_per_second': 618.971, 'eval_steps_per_second': 77.624, 'epoch': 15.0}
{'loss': 0.0018, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0}
{'eval_loss': 0.3573495149612427, 'eval_precision': 0.4911660777385159, 'eval_recall': 0.475484606613455, 'eval_f1': 0.48319814600231753, 'eval_accuracy': 0.9498571759437968, 'eval_runtime': 2.3736, 'eval_samples_per_second': 645.003, 'eval_steps_per_second': 80.889, 'epoch': 16.0}
{'loss': 0.0016, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0}
{'eval_loss': 0.361111581325531, 'eval_precision': 0.5053507728894173, 'eval_recall': 0.4846066134549601, 'eval_f1': 0.4947613504074505, 'eval_accuracy': 0.950204585810237, 'eval_runtime': 2.3744, 'eval_samples_per_second': 644.781, 'eval_steps_per_second': 80.861, 'epoch': 17.0}
{'loss': 0.0007, 'learning_rate': 2.5e-05, 'epoch': 18.0}
{'eval_loss': 0.37172698974609375, 'eval_precision': 0.5086505190311419, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.5057339449541284, 'eval_accuracy': 0.9501659847139658, 'eval_runtime': 2.3817, 'eval_samples_per_second': 642.826, 'eval_steps_per_second': 80.616, 'epoch': 18.0}
{'loss': 0.0006, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0}
{'eval_loss': 0.38088443875312805, 'eval_precision': 0.5032967032967033, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5125909345271404, 'eval_accuracy': 0.9496641704624411, 'eval_runtime': 2.3762, 'eval_samples_per_second': 644.311, 'eval_steps_per_second': 80.802, 'epoch': 19.0}
{'loss': 0.0005, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0}
{'eval_loss': 0.3846683204174042, 'eval_precision': 0.49567099567099565, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5086063298167683, 'eval_accuracy': 0.9489693507295607, 'eval_runtime': 2.372, 'eval_samples_per_second': 645.443, 'eval_steps_per_second': 80.944, 'epoch': 20.0}
{'loss': 0.0003, 'learning_rate': 1.25e-05, 'epoch': 21.0}
{'eval_loss': 0.3893578052520752, 'eval_precision': 0.5183908045977011, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.5163136805953062, 'eval_accuracy': 0.9497027715587123, 'eval_runtime': 2.3871, 'eval_samples_per_second': 641.364, 'eval_steps_per_second': 80.432, 'epoch': 21.0}
{'loss': 0.0004, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0}
{'eval_loss': 0.39388060569763184, 'eval_precision': 0.5093099671412924, 'eval_recall': 0.5302166476624858, 'eval_f1': 0.5195530726256984, 'eval_accuracy': 0.9500501814251525, 'eval_runtime': 2.3711, 'eval_samples_per_second': 645.704, 'eval_steps_per_second': 80.977, 'epoch': 22.0}
{'loss': 0.0002, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0}
{'eval_loss': 0.3956914246082306, 'eval_precision': 0.5106382978723404, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5152542372881356, 'eval_accuracy': 0.9502817880027793, 'eval_runtime': 2.3714, 'eval_samples_per_second': 645.602, 'eval_steps_per_second': 80.964, 'epoch': 23.0}
{'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.3949621915817261, 'eval_precision': 0.5055432372505543, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5126475548060707, 'eval_accuracy': 0.9499343781363391, 'eval_runtime': 2.3713, 'eval_samples_per_second': 645.629, 'eval_steps_per_second': 80.967, 'epoch': 24.0}
{'train_runtime': 844.5766, 'train_samples_per_second': 245.349, 'train_steps_per_second': 3.836, 'train_loss': 0.023646722684533876, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0236
  train_runtime            = 0:14:04.57
  train_samples            =       8634
  train_samples_per_second =    245.349
  train_steps_per_second   =      3.836
[{'loss': 0.2184, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.15520046651363373, 'eval_precision': 0.4218289085545723, 'eval_recall': 0.48916761687571264, 'eval_f1': 0.4530095036958817, 'eval_accuracy': 0.9457268586427855, 'eval_runtime': 2.3891, 'eval_samples_per_second': 640.827, 'eval_steps_per_second': 80.365, 'epoch': 1.0, 'step': 135}, {'loss': 0.1307, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.1585230678319931, 'eval_precision': 0.4463276836158192, 'eval_recall': 0.540478905359179, 'eval_f1': 0.4889118102114492, 'eval_accuracy': 0.9451478421987184, 'eval_runtime': 2.7936, 'eval_samples_per_second': 548.036, 'eval_steps_per_second': 68.728, 'epoch': 2.0, 'step': 270}, {'loss': 0.0758, 'learning_rate': 8.75e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.16640682518482208, 'eval_precision': 0.525, 'eval_recall': 0.4549600912200684, 'eval_f1': 0.48747709224190594, 'eval_accuracy': 0.9509766077356597, 'eval_runtime': 2.4287, 'eval_samples_per_second': 630.386, 'eval_steps_per_second': 79.056, 'epoch': 3.0, 'step': 405}, {'loss': 0.0445, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.21569842100143433, 'eval_precision': 0.46483516483516485, 'eval_recall': 0.4823261117445838, 'eval_f1': 0.47341913822048126, 'eval_accuracy': 0.9456496564502432, 'eval_runtime': 2.3712, 'eval_samples_per_second': 645.661, 'eval_steps_per_second': 80.971, 'epoch': 4.0, 'step': 540}, {'loss': 0.0281, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.22960680723190308, 'eval_precision': 0.47362869198312235, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.49205479452054796, 'eval_accuracy': 0.9471550992048174, 'eval_runtime': 2.3738, 'eval_samples_per_second': 644.958, 'eval_steps_per_second': 80.883, 'epoch': 5.0, 'step': 675}, {'loss': 0.0182, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.2590194344520569, 'eval_precision': 0.44660194174757284, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.4824331410592554, 'eval_accuracy': 0.9472323013973597, 'eval_runtime': 2.3808, 'eval_samples_per_second': 643.055, 'eval_steps_per_second': 80.644, 'epoch': 6.0, 'step': 810}, {'loss': 0.0127, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.2669265568256378, 'eval_precision': 0.45754245754245754, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.4877529286474973, 'eval_accuracy': 0.9468462904346483, 'eval_runtime': 2.3773, 'eval_samples_per_second': 644.017, 'eval_steps_per_second': 80.765, 'epoch': 7.0, 'step': 945}, {'loss': 0.0098, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.2855277955532074, 'eval_precision': 0.43884892086330934, 'eval_recall': 0.556442417331813, 'eval_f1': 0.4906988436400201, 'eval_accuracy': 0.9449934378136339, 'eval_runtime': 2.3802, 'eval_samples_per_second': 643.236, 'eval_steps_per_second': 80.667, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0064, 'learning_rate': 6.25e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.31080374121665955, 'eval_precision': 0.4677754677754678, 'eval_recall': 0.5131128848346637, 'eval_f1': 0.4893964110929853, 'eval_accuracy': 0.947888520033969, 'eval_runtime': 2.3794, 'eval_samples_per_second': 643.431, 'eval_steps_per_second': 80.692, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0047, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.3172037601470947, 'eval_precision': 0.5017103762827823, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.5017103762827823, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 2.3744, 'eval_samples_per_second': 644.807, 'eval_steps_per_second': 80.864, 'epoch': 10.0, 'step': 1350}, {'loss': 0.0036, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.3413010239601135, 'eval_precision': 0.4687168610816543, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.4857142857142857, 'eval_accuracy': 0.9470006948197329, 'eval_runtime': 2.371, 'eval_samples_per_second': 645.72, 'eval_steps_per_second': 80.979, 'epoch': 11.0, 'step': 1485}, {'loss': 0.0028, 'learning_rate': 5e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.35158100724220276, 'eval_precision': 0.49035187287173665, 'eval_recall': 0.4925883694412771, 'eval_f1': 0.49146757679180886, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 2.3763, 'eval_samples_per_second': 644.282, 'eval_steps_per_second': 80.798, 'epoch': 12.0, 'step': 1620}, {'loss': 0.002, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.3669762909412384, 'eval_precision': 0.5084134615384616, 'eval_recall': 0.4823261117445838, 'eval_f1': 0.4950263311878292, 'eval_accuracy': 0.9491623562109164, 'eval_runtime': 2.3775, 'eval_samples_per_second': 643.962, 'eval_steps_per_second': 80.758, 'epoch': 13.0, 'step': 1755}, {'loss': 0.0016, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.35878637433052063, 'eval_precision': 0.4936268829663963, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.4896551724137931, 'eval_accuracy': 0.9498957770400679, 'eval_runtime': 2.373, 'eval_samples_per_second': 645.185, 'eval_steps_per_second': 80.912, 'epoch': 14.0, 'step': 1890}, {'loss': 0.002, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.35800623893737793, 'eval_precision': 0.4911699779249448, 'eval_recall': 0.507411630558723, 'eval_f1': 0.49915872125630956, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 2.4735, 'eval_samples_per_second': 618.971, 'eval_steps_per_second': 77.624, 'epoch': 15.0, 'step': 2025}, {'loss': 0.0018, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.3573495149612427, 'eval_precision': 0.4911660777385159, 'eval_recall': 0.475484606613455, 'eval_f1': 0.48319814600231753, 'eval_accuracy': 0.9498571759437968, 'eval_runtime': 2.3736, 'eval_samples_per_second': 645.003, 'eval_steps_per_second': 80.889, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0016, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.361111581325531, 'eval_precision': 0.5053507728894173, 'eval_recall': 0.4846066134549601, 'eval_f1': 0.4947613504074505, 'eval_accuracy': 0.950204585810237, 'eval_runtime': 2.3744, 'eval_samples_per_second': 644.781, 'eval_steps_per_second': 80.861, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0007, 'learning_rate': 2.5e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.37172698974609375, 'eval_precision': 0.5086505190311419, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.5057339449541284, 'eval_accuracy': 0.9501659847139658, 'eval_runtime': 2.3817, 'eval_samples_per_second': 642.826, 'eval_steps_per_second': 80.616, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0006, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.38088443875312805, 'eval_precision': 0.5032967032967033, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5125909345271404, 'eval_accuracy': 0.9496641704624411, 'eval_runtime': 2.3762, 'eval_samples_per_second': 644.311, 'eval_steps_per_second': 80.802, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0005, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.3846683204174042, 'eval_precision': 0.49567099567099565, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5086063298167683, 'eval_accuracy': 0.9489693507295607, 'eval_runtime': 2.372, 'eval_samples_per_second': 645.443, 'eval_steps_per_second': 80.944, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0003, 'learning_rate': 1.25e-05, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.3893578052520752, 'eval_precision': 0.5183908045977011, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.5163136805953062, 'eval_accuracy': 0.9497027715587123, 'eval_runtime': 2.3871, 'eval_samples_per_second': 641.364, 'eval_steps_per_second': 80.432, 'epoch': 21.0, 'step': 2835}, {'loss': 0.0004, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.39388060569763184, 'eval_precision': 0.5093099671412924, 'eval_recall': 0.5302166476624858, 'eval_f1': 0.5195530726256984, 'eval_accuracy': 0.9500501814251525, 'eval_runtime': 2.3711, 'eval_samples_per_second': 645.704, 'eval_steps_per_second': 80.977, 'epoch': 22.0, 'step': 2970}, {'loss': 0.0002, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.3956914246082306, 'eval_precision': 0.5106382978723404, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5152542372881356, 'eval_accuracy': 0.9502817880027793, 'eval_runtime': 2.3714, 'eval_samples_per_second': 645.602, 'eval_steps_per_second': 80.964, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.3949621915817261, 'eval_precision': 0.5055432372505543, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5126475548060707, 'eval_accuracy': 0.9499343781363391, 'eval_runtime': 2.3713, 'eval_samples_per_second': 645.629, 'eval_steps_per_second': 80.967, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 844.5766, 'train_samples_per_second': 245.349, 'train_steps_per_second': 3.836, 'total_flos': 8936323010457180.0, 'train_loss': 0.023646722684533876, 'epoch': 24.0, 'step': 3240}]

Evaluation, NbAiLab/nb-bert-base
***** predict metrics *****
  predict_accuracy           =      0.947
  predict_f1                 =      0.435
  predict_loss               =     0.1649
  predict_precision          =     0.4148
  predict_recall             =     0.4571
  predict_runtime            = 0:00:01.98
  predict_samples_per_second =    642.143
  predict_steps_per_second   =     80.268
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_39.json completed. F1: 0.4349514563106796
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_22.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_22.json
01170939_tsa-bin_NorBERT_3_base Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6280.49 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 6842.97 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6734.76 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6796.14 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6862.01 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 6990.16 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 7148.55 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 7218.27 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6650.53 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7260.20 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6917.68 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6939.35 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6771.27 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
01170939_tsa-bin_NorBERT_3_base Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 1.6094, 'learning_rate': 4.791666666666667e-05, 'epoch': 1.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0556, 'eval_samples_per_second': 501.048, 'eval_steps_per_second': 62.836, 'epoch': 1.0}
{'loss': 1.6094, 'learning_rate': 4.5833333333333334e-05, 'epoch': 2.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0185, 'eval_samples_per_second': 507.202, 'eval_steps_per_second': 63.607, 'epoch': 2.0}
{'loss': 1.6094, 'learning_rate': 4.375e-05, 'epoch': 3.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0448, 'eval_samples_per_second': 502.826, 'eval_steps_per_second': 63.058, 'epoch': 3.0}
{'loss': 1.6094, 'learning_rate': 4.166666666666667e-05, 'epoch': 4.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0359, 'eval_samples_per_second': 504.304, 'eval_steps_per_second': 63.244, 'epoch': 4.0}
{'loss': 1.6094, 'learning_rate': 3.958333333333333e-05, 'epoch': 5.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0205, 'eval_samples_per_second': 506.877, 'eval_steps_per_second': 63.567, 'epoch': 5.0}
{'loss': 1.6094, 'learning_rate': 3.7500000000000003e-05, 'epoch': 6.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.001, 'eval_samples_per_second': 510.157, 'eval_steps_per_second': 63.978, 'epoch': 6.0}
{'loss': 1.6094, 'learning_rate': 3.541666666666667e-05, 'epoch': 7.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0144, 'eval_samples_per_second': 507.894, 'eval_steps_per_second': 63.694, 'epoch': 7.0}
{'loss': 1.6094, 'learning_rate': 3.3333333333333335e-05, 'epoch': 8.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0102, 'eval_samples_per_second': 508.603, 'eval_steps_per_second': 63.783, 'epoch': 8.0}
{'loss': 1.6094, 'learning_rate': 3.125e-05, 'epoch': 9.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9986, 'eval_samples_per_second': 510.58, 'eval_steps_per_second': 64.031, 'epoch': 9.0}
{'loss': 1.6094, 'learning_rate': 2.916666666666667e-05, 'epoch': 10.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0757, 'eval_samples_per_second': 497.78, 'eval_steps_per_second': 62.426, 'epoch': 10.0}
{'loss': 1.6094, 'learning_rate': 2.7083333333333332e-05, 'epoch': 11.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0051, 'eval_samples_per_second': 509.465, 'eval_steps_per_second': 63.891, 'epoch': 11.0}
{'loss': 1.6094, 'learning_rate': 2.5e-05, 'epoch': 12.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9935, 'eval_samples_per_second': 511.447, 'eval_steps_per_second': 64.14, 'epoch': 12.0}
{'loss': 1.6094, 'learning_rate': 2.2916666666666667e-05, 'epoch': 13.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9979, 'eval_samples_per_second': 510.689, 'eval_steps_per_second': 64.045, 'epoch': 13.0}
{'loss': 1.6094, 'learning_rate': 2.0833333333333336e-05, 'epoch': 14.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9874, 'eval_samples_per_second': 512.48, 'eval_steps_per_second': 64.269, 'epoch': 14.0}
{'loss': 1.6094, 'learning_rate': 1.8750000000000002e-05, 'epoch': 15.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9833, 'eval_samples_per_second': 513.198, 'eval_steps_per_second': 64.359, 'epoch': 15.0}
{'loss': 1.6094, 'learning_rate': 1.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.985, 'eval_samples_per_second': 512.898, 'eval_steps_per_second': 64.322, 'epoch': 16.0}
{'loss': 1.6094, 'learning_rate': 1.4583333333333335e-05, 'epoch': 17.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9797, 'eval_samples_per_second': 513.818, 'eval_steps_per_second': 64.437, 'epoch': 17.0}
{'loss': 1.6094, 'learning_rate': 1.25e-05, 'epoch': 18.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9857, 'eval_samples_per_second': 512.776, 'eval_steps_per_second': 64.306, 'epoch': 18.0}
{'loss': 1.6094, 'learning_rate': 1.0416666666666668e-05, 'epoch': 19.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9895, 'eval_samples_per_second': 512.12, 'eval_steps_per_second': 64.224, 'epoch': 19.0}
{'loss': 1.6094, 'learning_rate': 8.333333333333334e-06, 'epoch': 20.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9861, 'eval_samples_per_second': 512.7, 'eval_steps_per_second': 64.297, 'epoch': 20.0}
{'loss': 1.6094, 'learning_rate': 6.25e-06, 'epoch': 21.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0698, 'eval_samples_per_second': 498.729, 'eval_steps_per_second': 62.545, 'epoch': 21.0}
{'loss': 1.6094, 'learning_rate': 4.166666666666667e-06, 'epoch': 22.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9893, 'eval_samples_per_second': 512.161, 'eval_steps_per_second': 64.229, 'epoch': 22.0}
{'loss': 1.6094, 'learning_rate': 2.0833333333333334e-06, 'epoch': 23.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9879, 'eval_samples_per_second': 512.4, 'eval_steps_per_second': 64.259, 'epoch': 23.0}
{'loss': 1.6094, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9912, 'eval_samples_per_second': 511.827, 'eval_steps_per_second': 64.187, 'epoch': 24.0}
{'train_runtime': 849.9485, 'train_samples_per_second': 243.798, 'train_steps_per_second': 3.812, 'train_loss': 1.6094362612123843, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     1.6094
  train_runtime            = 0:14:09.94
  train_samples            =       8634
  train_samples_per_second =    243.798
  train_steps_per_second   =      3.812
[{'loss': 1.6094, 'learning_rate': 4.791666666666667e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0556, 'eval_samples_per_second': 501.048, 'eval_steps_per_second': 62.836, 'epoch': 1.0, 'step': 135}, {'loss': 1.6094, 'learning_rate': 4.5833333333333334e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0185, 'eval_samples_per_second': 507.202, 'eval_steps_per_second': 63.607, 'epoch': 2.0, 'step': 270}, {'loss': 1.6094, 'learning_rate': 4.375e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0448, 'eval_samples_per_second': 502.826, 'eval_steps_per_second': 63.058, 'epoch': 3.0, 'step': 405}, {'loss': 1.6094, 'learning_rate': 4.166666666666667e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0359, 'eval_samples_per_second': 504.304, 'eval_steps_per_second': 63.244, 'epoch': 4.0, 'step': 540}, {'loss': 1.6094, 'learning_rate': 3.958333333333333e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0205, 'eval_samples_per_second': 506.877, 'eval_steps_per_second': 63.567, 'epoch': 5.0, 'step': 675}, {'loss': 1.6094, 'learning_rate': 3.7500000000000003e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.001, 'eval_samples_per_second': 510.157, 'eval_steps_per_second': 63.978, 'epoch': 6.0, 'step': 810}, {'loss': 1.6094, 'learning_rate': 3.541666666666667e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0144, 'eval_samples_per_second': 507.894, 'eval_steps_per_second': 63.694, 'epoch': 7.0, 'step': 945}, {'loss': 1.6094, 'learning_rate': 3.3333333333333335e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0102, 'eval_samples_per_second': 508.603, 'eval_steps_per_second': 63.783, 'epoch': 8.0, 'step': 1080}, {'loss': 1.6094, 'learning_rate': 3.125e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9986, 'eval_samples_per_second': 510.58, 'eval_steps_per_second': 64.031, 'epoch': 9.0, 'step': 1215}, {'loss': 1.6094, 'learning_rate': 2.916666666666667e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0757, 'eval_samples_per_second': 497.78, 'eval_steps_per_second': 62.426, 'epoch': 10.0, 'step': 1350}, {'loss': 1.6094, 'learning_rate': 2.7083333333333332e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0051, 'eval_samples_per_second': 509.465, 'eval_steps_per_second': 63.891, 'epoch': 11.0, 'step': 1485}, {'loss': 1.6094, 'learning_rate': 2.5e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9935, 'eval_samples_per_second': 511.447, 'eval_steps_per_second': 64.14, 'epoch': 12.0, 'step': 1620}, {'loss': 1.6094, 'learning_rate': 2.2916666666666667e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9979, 'eval_samples_per_second': 510.689, 'eval_steps_per_second': 64.045, 'epoch': 13.0, 'step': 1755}, {'loss': 1.6094, 'learning_rate': 2.0833333333333336e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9874, 'eval_samples_per_second': 512.48, 'eval_steps_per_second': 64.269, 'epoch': 14.0, 'step': 1890}, {'loss': 1.6094, 'learning_rate': 1.8750000000000002e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9833, 'eval_samples_per_second': 513.198, 'eval_steps_per_second': 64.359, 'epoch': 15.0, 'step': 2025}, {'loss': 1.6094, 'learning_rate': 1.6666666666666667e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.985, 'eval_samples_per_second': 512.898, 'eval_steps_per_second': 64.322, 'epoch': 16.0, 'step': 2160}, {'loss': 1.6094, 'learning_rate': 1.4583333333333335e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9797, 'eval_samples_per_second': 513.818, 'eval_steps_per_second': 64.437, 'epoch': 17.0, 'step': 2295}, {'loss': 1.6094, 'learning_rate': 1.25e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9857, 'eval_samples_per_second': 512.776, 'eval_steps_per_second': 64.306, 'epoch': 18.0, 'step': 2430}, {'loss': 1.6094, 'learning_rate': 1.0416666666666668e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9895, 'eval_samples_per_second': 512.12, 'eval_steps_per_second': 64.224, 'epoch': 19.0, 'step': 2565}, {'loss': 1.6094, 'learning_rate': 8.333333333333334e-06, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9861, 'eval_samples_per_second': 512.7, 'eval_steps_per_second': 64.297, 'epoch': 20.0, 'step': 2700}, {'loss': 1.6094, 'learning_rate': 6.25e-06, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 3.0698, 'eval_samples_per_second': 498.729, 'eval_steps_per_second': 62.545, 'epoch': 21.0, 'step': 2835}, {'loss': 1.6094, 'learning_rate': 4.166666666666667e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9893, 'eval_samples_per_second': 512.161, 'eval_steps_per_second': 64.229, 'epoch': 22.0, 'step': 2970}, {'loss': 1.6094, 'learning_rate': 2.0833333333333334e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9879, 'eval_samples_per_second': 512.4, 'eval_steps_per_second': 64.259, 'epoch': 23.0, 'step': 3105}, {'loss': 1.6094, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 1.6094378232955933, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9341851308577164, 'eval_runtime': 2.9912, 'eval_samples_per_second': 511.827, 'eval_steps_per_second': 64.187, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 849.9485, 'train_samples_per_second': 243.798, 'train_steps_per_second': 3.812, 'total_flos': 7641716291195580.0, 'train_loss': 1.6094362612123843, 'epoch': 24.0, 'step': 3240}]

Evaluation, ltg/norbert3-base
***** predict metrics *****
  predict_accuracy           =     0.9327
  predict_f1                 =        0.0
  predict_loss               =     1.6094
  predict_precision          =        0.0
  predict_recall             =        0.0
  predict_runtime            = 0:00:02.50
  predict_samples_per_second =    508.363
  predict_steps_per_second   =     63.545
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_base_22.json completed. F1: 0.0
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_10.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at ltg/norbert2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_10.json
01170939_tsa-bin_NorBERT_2 Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 5818.28 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 6853.22 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6917.37 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 7072.81 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 7169.41 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7351.41 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6474.42 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6832.07 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6899.18 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7552.34 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 7147.26 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7315.66 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 7113.49 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Checkpoint destination directory /cluster/work/projects/ec30/egilron/tsa-hf/01170939_tsa-bin_NorBERT_2/checkpoint-216 already exists and is non-empty.Saving will proceed but saved results may be invalid.
01170939_tsa-bin_NorBERT_2 Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2127, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': 0.16031886637210846, 'eval_precision': 0.38760504201680673, 'eval_recall': 0.4207525655644242, 'eval_f1': 0.40349917987971573, 'eval_accuracy': 0.9442986180807534, 'eval_runtime': 2.2398, 'eval_samples_per_second': 683.556, 'eval_steps_per_second': 85.724, 'epoch': 1.0}
{'loss': 0.1091, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': 0.16732172667980194, 'eval_precision': 0.503725782414307, 'eval_recall': 0.38540478905359177, 'eval_f1': 0.4366925064599483, 'eval_accuracy': 0.9485061375743071, 'eval_runtime': 2.2273, 'eval_samples_per_second': 687.384, 'eval_steps_per_second': 86.204, 'epoch': 2.0}
{'loss': 0.0489, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': 0.22247019410133362, 'eval_precision': 0.3880037488284911, 'eval_recall': 0.47206385404789053, 'eval_f1': 0.4259259259259259, 'eval_accuracy': 0.9407473172238091, 'eval_runtime': 2.2242, 'eval_samples_per_second': 688.345, 'eval_steps_per_second': 86.324, 'epoch': 3.0}
{'loss': 0.0276, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.2594444751739502, 'eval_precision': 0.4249726177437021, 'eval_recall': 0.44241733181299886, 'eval_f1': 0.43351955307262563, 'eval_accuracy': 0.9438740060217711, 'eval_runtime': 2.2396, 'eval_samples_per_second': 683.61, 'eval_steps_per_second': 85.73, 'epoch': 4.0}
{'loss': 0.016, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.27949103713035583, 'eval_precision': 0.44042056074766356, 'eval_recall': 0.4298745724059293, 'eval_f1': 0.4350836699365263, 'eval_accuracy': 0.9441828147919401, 'eval_runtime': 2.4362, 'eval_samples_per_second': 628.437, 'eval_steps_per_second': 78.811, 'epoch': 5.0}
{'loss': 0.0122, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.3118223249912262, 'eval_precision': 0.4361820199778024, 'eval_recall': 0.44811858608893956, 'eval_f1': 0.44206974128233967, 'eval_accuracy': 0.9431791862888906, 'eval_runtime': 2.2261, 'eval_samples_per_second': 687.758, 'eval_steps_per_second': 86.251, 'epoch': 6.0}
{'loss': 0.008, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': 0.34031394124031067, 'eval_precision': 0.4565727699530516, 'eval_recall': 0.443557582668187, 'eval_f1': 0.4499710815500289, 'eval_accuracy': 0.9452636454875318, 'eval_runtime': 2.2318, 'eval_samples_per_second': 685.99, 'eval_steps_per_second': 86.029, 'epoch': 7.0}
{'loss': 0.005, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': 0.35503923892974854, 'eval_precision': 0.4236760124610592, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.4434782608695652, 'eval_accuracy': 0.9424843665560102, 'eval_runtime': 2.2426, 'eval_samples_per_second': 682.691, 'eval_steps_per_second': 85.615, 'epoch': 8.0}
{'loss': 0.005, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': 0.3479989469051361, 'eval_precision': 0.44539614561027835, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.45941468801766977, 'eval_accuracy': 0.9434879950590597, 'eval_runtime': 2.2341, 'eval_samples_per_second': 685.274, 'eval_steps_per_second': 85.939, 'epoch': 9.0}
{'loss': 0.0037, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.38174718618392944, 'eval_precision': 0.3980295566502463, 'eval_recall': 0.4606613454960091, 'eval_f1': 0.427061310782241, 'eval_accuracy': 0.9400910985871999, 'eval_runtime': 2.2299, 'eval_samples_per_second': 686.572, 'eval_steps_per_second': 86.102, 'epoch': 10.0}
{'loss': 0.003, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': 0.38685572147369385, 'eval_precision': 0.4088669950738916, 'eval_recall': 0.4732041049030787, 'eval_f1': 0.4386892177589852, 'eval_accuracy': 0.9390102678916081, 'eval_runtime': 2.31, 'eval_samples_per_second': 662.768, 'eval_steps_per_second': 83.117, 'epoch': 11.0}
{'loss': 0.0025, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': 0.38110774755477905, 'eval_precision': 0.3914313534566699, 'eval_recall': 0.4583808437856328, 'eval_f1': 0.4222689075630252, 'eval_accuracy': 0.9396664865282174, 'eval_runtime': 2.2326, 'eval_samples_per_second': 685.742, 'eval_steps_per_second': 85.998, 'epoch': 12.0}
{'loss': 0.0022, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': 0.3997921049594879, 'eval_precision': 0.4422657952069717, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4523676880222841, 'eval_accuracy': 0.9440284104068556, 'eval_runtime': 2.2331, 'eval_samples_per_second': 685.607, 'eval_steps_per_second': 85.981, 'epoch': 13.0}
{'loss': 0.0014, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': 0.42057082056999207, 'eval_precision': 0.43010752688172044, 'eval_recall': 0.45610034207525657, 'eval_f1': 0.4427227448810183, 'eval_accuracy': 0.9437968038292287, 'eval_runtime': 2.2346, 'eval_samples_per_second': 685.129, 'eval_steps_per_second': 85.921, 'epoch': 14.0}
{'loss': 0.0014, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': 0.4070323407649994, 'eval_precision': 0.4563679245283019, 'eval_recall': 0.4412770809578107, 'eval_f1': 0.448695652173913, 'eval_accuracy': 0.9449934378136339, 'eval_runtime': 2.2329, 'eval_samples_per_second': 685.661, 'eval_steps_per_second': 85.988, 'epoch': 15.0}
{'loss': 0.0012, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.408799409866333, 'eval_precision': 0.45979899497487436, 'eval_recall': 0.41733181299885974, 'eval_f1': 0.4375373580394501, 'eval_accuracy': 0.9459198641241411, 'eval_runtime': 2.2301, 'eval_samples_per_second': 686.512, 'eval_steps_per_second': 86.094, 'epoch': 16.0}
{'loss': 0.0007, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': 0.43134480714797974, 'eval_precision': 0.46618357487922707, 'eval_recall': 0.44013683010262256, 'eval_f1': 0.45278592375366566, 'eval_accuracy': 0.945302246583803, 'eval_runtime': 2.2194, 'eval_samples_per_second': 689.822, 'eval_steps_per_second': 86.509, 'epoch': 17.0}
{'loss': 0.0008, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': 0.4229564964771271, 'eval_precision': 0.4385201305767138, 'eval_recall': 0.45952109464082097, 'eval_f1': 0.4487750556792873, 'eval_accuracy': 0.9420983555932988, 'eval_runtime': 2.37, 'eval_samples_per_second': 645.981, 'eval_steps_per_second': 81.011, 'epoch': 18.0}
{'loss': 0.0005, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': 0.42844486236572266, 'eval_precision': 0.44583808437856326, 'eval_recall': 0.44583808437856326, 'eval_f1': 0.4458380843785633, 'eval_accuracy': 0.9442986180807534, 'eval_runtime': 2.2366, 'eval_samples_per_second': 684.518, 'eval_steps_per_second': 85.844, 'epoch': 19.0}
{'loss': 0.0003, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': 0.43738144636154175, 'eval_precision': 0.4563445867287544, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.45161290322580644, 'eval_accuracy': 0.9447232301397359, 'eval_runtime': 2.3071, 'eval_samples_per_second': 663.598, 'eval_steps_per_second': 83.221, 'epoch': 20.0}
{'loss': 0.0003, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': 0.44108977913856506, 'eval_precision': 0.43609022556390975, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4491150442477876, 'eval_accuracy': 0.942445765459739, 'eval_runtime': 2.2418, 'eval_samples_per_second': 682.938, 'eval_steps_per_second': 85.646, 'epoch': 21.0}
{'loss': 0.0002, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.4473300576210022, 'eval_precision': 0.4740740740740741, 'eval_recall': 0.4378563283922463, 'eval_f1': 0.45524599881446354, 'eval_accuracy': 0.9458426619315988, 'eval_runtime': 2.2306, 'eval_samples_per_second': 686.36, 'eval_steps_per_second': 86.075, 'epoch': 22.0}
{'loss': 0.0001, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': 0.4486005902290344, 'eval_precision': 0.4531791907514451, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.4500574052812859, 'eval_accuracy': 0.9444144213695669, 'eval_runtime': 2.2229, 'eval_samples_per_second': 688.729, 'eval_steps_per_second': 86.372, 'epoch': 23.0}
{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.44915273785591125, 'eval_precision': 0.46054181389870436, 'eval_recall': 0.44583808437856326, 'eval_f1': 0.45307068366164543, 'eval_accuracy': 0.9447232301397359, 'eval_runtime': 2.2278, 'eval_samples_per_second': 687.215, 'eval_steps_per_second': 86.182, 'epoch': 24.0}
{'train_runtime': 755.3733, 'train_samples_per_second': 274.323, 'train_steps_per_second': 6.863, 'train_loss': 0.01928156472593086, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0193
  train_runtime            = 0:12:35.37
  train_samples            =       8634
  train_samples_per_second =    274.323
  train_steps_per_second   =      6.863
[{'loss': 0.2127, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.16031886637210846, 'eval_precision': 0.38760504201680673, 'eval_recall': 0.4207525655644242, 'eval_f1': 0.40349917987971573, 'eval_accuracy': 0.9442986180807534, 'eval_runtime': 2.2398, 'eval_samples_per_second': 683.556, 'eval_steps_per_second': 85.724, 'epoch': 1.0, 'step': 216}, {'loss': 0.1091, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 432}, {'eval_loss': 0.16732172667980194, 'eval_precision': 0.503725782414307, 'eval_recall': 0.38540478905359177, 'eval_f1': 0.4366925064599483, 'eval_accuracy': 0.9485061375743071, 'eval_runtime': 2.2273, 'eval_samples_per_second': 687.384, 'eval_steps_per_second': 86.204, 'epoch': 2.0, 'step': 432}, {'loss': 0.0489, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 648}, {'eval_loss': 0.22247019410133362, 'eval_precision': 0.3880037488284911, 'eval_recall': 0.47206385404789053, 'eval_f1': 0.4259259259259259, 'eval_accuracy': 0.9407473172238091, 'eval_runtime': 2.2242, 'eval_samples_per_second': 688.345, 'eval_steps_per_second': 86.324, 'epoch': 3.0, 'step': 648}, {'loss': 0.0276, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 864}, {'eval_loss': 0.2594444751739502, 'eval_precision': 0.4249726177437021, 'eval_recall': 0.44241733181299886, 'eval_f1': 0.43351955307262563, 'eval_accuracy': 0.9438740060217711, 'eval_runtime': 2.2396, 'eval_samples_per_second': 683.61, 'eval_steps_per_second': 85.73, 'epoch': 4.0, 'step': 864}, {'loss': 0.016, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 1080}, {'eval_loss': 0.27949103713035583, 'eval_precision': 0.44042056074766356, 'eval_recall': 0.4298745724059293, 'eval_f1': 0.4350836699365263, 'eval_accuracy': 0.9441828147919401, 'eval_runtime': 2.4362, 'eval_samples_per_second': 628.437, 'eval_steps_per_second': 78.811, 'epoch': 5.0, 'step': 1080}, {'loss': 0.0122, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 1296}, {'eval_loss': 0.3118223249912262, 'eval_precision': 0.4361820199778024, 'eval_recall': 0.44811858608893956, 'eval_f1': 0.44206974128233967, 'eval_accuracy': 0.9431791862888906, 'eval_runtime': 2.2261, 'eval_samples_per_second': 687.758, 'eval_steps_per_second': 86.251, 'epoch': 6.0, 'step': 1296}, {'loss': 0.008, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 1512}, {'eval_loss': 0.34031394124031067, 'eval_precision': 0.4565727699530516, 'eval_recall': 0.443557582668187, 'eval_f1': 0.4499710815500289, 'eval_accuracy': 0.9452636454875318, 'eval_runtime': 2.2318, 'eval_samples_per_second': 685.99, 'eval_steps_per_second': 86.029, 'epoch': 7.0, 'step': 1512}, {'loss': 0.005, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1728}, {'eval_loss': 0.35503923892974854, 'eval_precision': 0.4236760124610592, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.4434782608695652, 'eval_accuracy': 0.9424843665560102, 'eval_runtime': 2.2426, 'eval_samples_per_second': 682.691, 'eval_steps_per_second': 85.615, 'epoch': 8.0, 'step': 1728}, {'loss': 0.005, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1944}, {'eval_loss': 0.3479989469051361, 'eval_precision': 0.44539614561027835, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.45941468801766977, 'eval_accuracy': 0.9434879950590597, 'eval_runtime': 2.2341, 'eval_samples_per_second': 685.274, 'eval_steps_per_second': 85.939, 'epoch': 9.0, 'step': 1944}, {'loss': 0.0037, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 2160}, {'eval_loss': 0.38174718618392944, 'eval_precision': 0.3980295566502463, 'eval_recall': 0.4606613454960091, 'eval_f1': 0.427061310782241, 'eval_accuracy': 0.9400910985871999, 'eval_runtime': 2.2299, 'eval_samples_per_second': 686.572, 'eval_steps_per_second': 86.102, 'epoch': 10.0, 'step': 2160}, {'loss': 0.003, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 2376}, {'eval_loss': 0.38685572147369385, 'eval_precision': 0.4088669950738916, 'eval_recall': 0.4732041049030787, 'eval_f1': 0.4386892177589852, 'eval_accuracy': 0.9390102678916081, 'eval_runtime': 2.31, 'eval_samples_per_second': 662.768, 'eval_steps_per_second': 83.117, 'epoch': 11.0, 'step': 2376}, {'loss': 0.0025, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 2592}, {'eval_loss': 0.38110774755477905, 'eval_precision': 0.3914313534566699, 'eval_recall': 0.4583808437856328, 'eval_f1': 0.4222689075630252, 'eval_accuracy': 0.9396664865282174, 'eval_runtime': 2.2326, 'eval_samples_per_second': 685.742, 'eval_steps_per_second': 85.998, 'epoch': 12.0, 'step': 2592}, {'loss': 0.0022, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 2808}, {'eval_loss': 0.3997921049594879, 'eval_precision': 0.4422657952069717, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4523676880222841, 'eval_accuracy': 0.9440284104068556, 'eval_runtime': 2.2331, 'eval_samples_per_second': 685.607, 'eval_steps_per_second': 85.981, 'epoch': 13.0, 'step': 2808}, {'loss': 0.0014, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 3024}, {'eval_loss': 0.42057082056999207, 'eval_precision': 0.43010752688172044, 'eval_recall': 0.45610034207525657, 'eval_f1': 0.4427227448810183, 'eval_accuracy': 0.9437968038292287, 'eval_runtime': 2.2346, 'eval_samples_per_second': 685.129, 'eval_steps_per_second': 85.921, 'epoch': 14.0, 'step': 3024}, {'loss': 0.0014, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 3240}, {'eval_loss': 0.4070323407649994, 'eval_precision': 0.4563679245283019, 'eval_recall': 0.4412770809578107, 'eval_f1': 0.448695652173913, 'eval_accuracy': 0.9449934378136339, 'eval_runtime': 2.2329, 'eval_samples_per_second': 685.661, 'eval_steps_per_second': 85.988, 'epoch': 15.0, 'step': 3240}, {'loss': 0.0012, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 3456}, {'eval_loss': 0.408799409866333, 'eval_precision': 0.45979899497487436, 'eval_recall': 0.41733181299885974, 'eval_f1': 0.4375373580394501, 'eval_accuracy': 0.9459198641241411, 'eval_runtime': 2.2301, 'eval_samples_per_second': 686.512, 'eval_steps_per_second': 86.094, 'epoch': 16.0, 'step': 3456}, {'loss': 0.0007, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 3672}, {'eval_loss': 0.43134480714797974, 'eval_precision': 0.46618357487922707, 'eval_recall': 0.44013683010262256, 'eval_f1': 0.45278592375366566, 'eval_accuracy': 0.945302246583803, 'eval_runtime': 2.2194, 'eval_samples_per_second': 689.822, 'eval_steps_per_second': 86.509, 'epoch': 17.0, 'step': 3672}, {'loss': 0.0008, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 3888}, {'eval_loss': 0.4229564964771271, 'eval_precision': 0.4385201305767138, 'eval_recall': 0.45952109464082097, 'eval_f1': 0.4487750556792873, 'eval_accuracy': 0.9420983555932988, 'eval_runtime': 2.37, 'eval_samples_per_second': 645.981, 'eval_steps_per_second': 81.011, 'epoch': 18.0, 'step': 3888}, {'loss': 0.0005, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 4104}, {'eval_loss': 0.42844486236572266, 'eval_precision': 0.44583808437856326, 'eval_recall': 0.44583808437856326, 'eval_f1': 0.4458380843785633, 'eval_accuracy': 0.9442986180807534, 'eval_runtime': 2.2366, 'eval_samples_per_second': 684.518, 'eval_steps_per_second': 85.844, 'epoch': 19.0, 'step': 4104}, {'loss': 0.0003, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 4320}, {'eval_loss': 0.43738144636154175, 'eval_precision': 0.4563445867287544, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.45161290322580644, 'eval_accuracy': 0.9447232301397359, 'eval_runtime': 2.3071, 'eval_samples_per_second': 663.598, 'eval_steps_per_second': 83.221, 'epoch': 20.0, 'step': 4320}, {'loss': 0.0003, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 4536}, {'eval_loss': 0.44108977913856506, 'eval_precision': 0.43609022556390975, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4491150442477876, 'eval_accuracy': 0.942445765459739, 'eval_runtime': 2.2418, 'eval_samples_per_second': 682.938, 'eval_steps_per_second': 85.646, 'epoch': 21.0, 'step': 4536}, {'loss': 0.0002, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 4752}, {'eval_loss': 0.4473300576210022, 'eval_precision': 0.4740740740740741, 'eval_recall': 0.4378563283922463, 'eval_f1': 0.45524599881446354, 'eval_accuracy': 0.9458426619315988, 'eval_runtime': 2.2306, 'eval_samples_per_second': 686.36, 'eval_steps_per_second': 86.075, 'epoch': 22.0, 'step': 4752}, {'loss': 0.0001, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 4968}, {'eval_loss': 0.4486005902290344, 'eval_precision': 0.4531791907514451, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.4500574052812859, 'eval_accuracy': 0.9444144213695669, 'eval_runtime': 2.2229, 'eval_samples_per_second': 688.729, 'eval_steps_per_second': 86.372, 'epoch': 23.0, 'step': 4968}, {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 5184}, {'eval_loss': 0.44915273785591125, 'eval_precision': 0.46054181389870436, 'eval_recall': 0.44583808437856326, 'eval_f1': 0.45307068366164543, 'eval_accuracy': 0.9447232301397359, 'eval_runtime': 2.2278, 'eval_samples_per_second': 687.215, 'eval_steps_per_second': 86.182, 'epoch': 24.0, 'step': 5184}, {'train_runtime': 755.3733, 'train_samples_per_second': 274.323, 'train_steps_per_second': 6.863, 'total_flos': 6810645841644840.0, 'train_loss': 0.01928156472593086, 'epoch': 24.0, 'step': 5184}]

Evaluation, ltg/norbert2
***** predict metrics *****
  predict_accuracy           =      0.944
  predict_f1                 =     0.3856
  predict_loss               =     0.1692
  predict_precision          =     0.3861
  predict_recall             =      0.385
  predict_runtime            = 0:00:01.86
  predict_samples_per_second =     681.28
  predict_steps_per_second   =      85.16
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_10.json completed. F1: 0.385558583106267
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_33.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at NbAiLab/nb-bert-large and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_33.json
01170939_tsa-bin_NB-BERT_large Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6234.32 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 6962.80 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6882.43 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6949.87 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 7006.99 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7163.04 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6301.51 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6646.80 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6778.93 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7465.63 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 7087.46 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7134.52 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6958.25 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
01170939_tsa-bin_NB-BERT_large Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2084, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': 0.13983657956123352, 'eval_precision': 0.4639175257731959, 'eval_recall': 0.5131128848346637, 'eval_f1': 0.4872766648619383, 'eval_accuracy': 0.9479657222265112, 'eval_runtime': 4.6743, 'eval_samples_per_second': 327.536, 'eval_steps_per_second': 41.076, 'epoch': 1.0}
{'loss': 0.1169, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': 0.1390741914510727, 'eval_precision': 0.47075208913649025, 'eval_recall': 0.5781071835803877, 'eval_f1': 0.518935516888434, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 4.6672, 'eval_samples_per_second': 328.037, 'eval_steps_per_second': 41.139, 'epoch': 2.0}
{'loss': 0.0646, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': 0.15558449923992157, 'eval_precision': 0.4940239043824701, 'eval_recall': 0.5655644241733181, 'eval_f1': 0.5273790536948432, 'eval_accuracy': 0.952211842816336, 'eval_runtime': 4.6661, 'eval_samples_per_second': 328.115, 'eval_steps_per_second': 41.148, 'epoch': 3.0}
{'loss': 0.0349, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.1871093511581421, 'eval_precision': 0.49742533470648814, 'eval_recall': 0.5507411630558723, 'eval_f1': 0.5227272727272727, 'eval_accuracy': 0.9511696132170153, 'eval_runtime': 4.6649, 'eval_samples_per_second': 328.199, 'eval_steps_per_second': 41.159, 'epoch': 4.0}
{'loss': 0.0197, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.2279435694217682, 'eval_precision': 0.515695067264574, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5200678349349915, 'eval_accuracy': 0.95336987570447, 'eval_runtime': 4.6608, 'eval_samples_per_second': 328.483, 'eval_steps_per_second': 41.194, 'epoch': 5.0}
{'loss': 0.011, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.26639094948768616, 'eval_precision': 0.5499383477188656, 'eval_recall': 0.508551881413911, 'eval_f1': 0.5284360189573459, 'eval_accuracy': 0.9557631436732803, 'eval_runtime': 4.6636, 'eval_samples_per_second': 328.286, 'eval_steps_per_second': 41.17, 'epoch': 6.0}
{'loss': 0.0075, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': 0.2532074451446533, 'eval_precision': 0.4566003616636528, 'eval_recall': 0.5758266818700114, 'eval_f1': 0.5093292990418558, 'eval_accuracy': 0.9485061375743071, 'eval_runtime': 4.6745, 'eval_samples_per_second': 327.525, 'eval_steps_per_second': 41.074, 'epoch': 7.0}
{'loss': 0.0056, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': 0.25323495268821716, 'eval_precision': 0.5042918454935622, 'eval_recall': 0.5359179019384265, 'eval_f1': 0.5196241017136539, 'eval_accuracy': 0.9534470778970123, 'eval_runtime': 4.6623, 'eval_samples_per_second': 328.38, 'eval_steps_per_second': 41.182, 'epoch': 8.0}
{'loss': 0.0046, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': 0.28256669640541077, 'eval_precision': 0.4935064935064935, 'eval_recall': 0.5632839224629419, 'eval_f1': 0.5260915867944622, 'eval_accuracy': 0.9531768702231144, 'eval_runtime': 4.6628, 'eval_samples_per_second': 328.34, 'eval_steps_per_second': 41.177, 'epoch': 9.0}
{'loss': 0.0039, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.29585784673690796, 'eval_precision': 0.5203619909502263, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5224304372515616, 'eval_accuracy': 0.9541804987261638, 'eval_runtime': 4.6648, 'eval_samples_per_second': 328.2, 'eval_steps_per_second': 41.159, 'epoch': 10.0}
{'loss': 0.003, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': 0.3026910424232483, 'eval_precision': 0.536928487690504, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5294797687861271, 'eval_accuracy': 0.9544121053037906, 'eval_runtime': 4.6582, 'eval_samples_per_second': 328.667, 'eval_steps_per_second': 41.218, 'epoch': 11.0}
{'loss': 0.0031, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': 0.32662954926490784, 'eval_precision': 0.528555431131019, 'eval_recall': 0.5381984036488028, 'eval_f1': 0.5333333333333333, 'eval_accuracy': 0.9544121053037906, 'eval_runtime': 4.6607, 'eval_samples_per_second': 328.495, 'eval_steps_per_second': 41.196, 'epoch': 12.0}
{'loss': 0.0015, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': 0.33693355321884155, 'eval_precision': 0.5390070921985816, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5293093441671503, 'eval_accuracy': 0.9552227283254845, 'eval_runtime': 4.666, 'eval_samples_per_second': 328.117, 'eval_steps_per_second': 41.149, 'epoch': 13.0}
{'loss': 0.0016, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': 0.32149526476860046, 'eval_precision': 0.5542021924482339, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5359246171967021, 'eval_accuracy': 0.9560333513471783, 'eval_runtime': 4.6563, 'eval_samples_per_second': 328.804, 'eval_steps_per_second': 41.235, 'epoch': 14.0}
{'loss': 0.0015, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': 0.3228573203086853, 'eval_precision': 0.5522388059701493, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.5282569898869721, 'eval_accuracy': 0.955956149154636, 'eval_runtime': 4.6521, 'eval_samples_per_second': 329.097, 'eval_steps_per_second': 41.271, 'epoch': 15.0}
{'loss': 0.0009, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.34076786041259766, 'eval_precision': 0.5589919816723941, 'eval_recall': 0.556442417331813, 'eval_f1': 0.5577142857142857, 'eval_accuracy': 0.9566123677912453, 'eval_runtime': 4.6555, 'eval_samples_per_second': 328.861, 'eval_steps_per_second': 41.242, 'epoch': 16.0}
{'loss': 0.0009, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': 0.3375677466392517, 'eval_precision': 0.5598548972188634, 'eval_recall': 0.5279361459521095, 'eval_f1': 0.5434272300469484, 'eval_accuracy': 0.9569597776576855, 'eval_runtime': 4.6562, 'eval_samples_per_second': 328.812, 'eval_steps_per_second': 41.236, 'epoch': 17.0}
{'loss': 0.0003, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': 0.3550891876220703, 'eval_precision': 0.5389755011135857, 'eval_recall': 0.5518814139110604, 'eval_f1': 0.5453521126760563, 'eval_accuracy': 0.955956149154636, 'eval_runtime': 4.6586, 'eval_samples_per_second': 328.64, 'eval_steps_per_second': 41.214, 'epoch': 18.0}
{'loss': 0.0002, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': 0.3614993989467621, 'eval_precision': 0.536, 'eval_recall': 0.5347776510832383, 'eval_f1': 0.5353881278538812, 'eval_accuracy': 0.955647340384467, 'eval_runtime': 4.6608, 'eval_samples_per_second': 328.486, 'eval_steps_per_second': 41.195, 'epoch': 19.0}
{'loss': 0.0003, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': 0.3614985942840576, 'eval_precision': 0.552439024390244, 'eval_recall': 0.5165336374002281, 'eval_f1': 0.5338833235120802, 'eval_accuracy': 0.9567667721763298, 'eval_runtime': 4.7342, 'eval_samples_per_second': 323.391, 'eval_steps_per_second': 40.556, 'epoch': 20.0}
{'loss': 0.0003, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': 0.36848533153533936, 'eval_precision': 0.5369955156950673, 'eval_recall': 0.5461801596351197, 'eval_f1': 0.5415488976823063, 'eval_accuracy': 0.9551455261329421, 'eval_runtime': 4.6603, 'eval_samples_per_second': 328.52, 'eval_steps_per_second': 41.199, 'epoch': 21.0}
{'loss': 0.0001, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.3748254179954529, 'eval_precision': 0.5535307517084282, 'eval_recall': 0.5541619156214367, 'eval_f1': 0.5538461538461539, 'eval_accuracy': 0.9563807612136185, 'eval_runtime': 4.6628, 'eval_samples_per_second': 328.347, 'eval_steps_per_second': 41.177, 'epoch': 22.0}
{'loss': 0.0002, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': 0.37512606382369995, 'eval_precision': 0.5581395348837209, 'eval_recall': 0.5473204104903079, 'eval_f1': 0.5526770293609672, 'eval_accuracy': 0.9564193623098896, 'eval_runtime': 4.6632, 'eval_samples_per_second': 328.318, 'eval_steps_per_second': 41.174, 'epoch': 23.0}
{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.37619295716285706, 'eval_precision': 0.5571095571095571, 'eval_recall': 0.5450399087799316, 'eval_f1': 0.5510086455331413, 'eval_accuracy': 0.956535165598703, 'eval_runtime': 4.6611, 'eval_samples_per_second': 328.465, 'eval_steps_per_second': 41.192, 'epoch': 24.0}
{'train_runtime': 2101.2017, 'train_samples_per_second': 98.618, 'train_steps_per_second': 1.542, 'train_loss': 0.02046515036885983, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0205
  train_runtime            = 0:35:01.20
  train_samples            =       8634
  train_samples_per_second =     98.618
  train_steps_per_second   =      1.542
[{'loss': 0.2084, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.13983657956123352, 'eval_precision': 0.4639175257731959, 'eval_recall': 0.5131128848346637, 'eval_f1': 0.4872766648619383, 'eval_accuracy': 0.9479657222265112, 'eval_runtime': 4.6743, 'eval_samples_per_second': 327.536, 'eval_steps_per_second': 41.076, 'epoch': 1.0, 'step': 135}, {'loss': 0.1169, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.1390741914510727, 'eval_precision': 0.47075208913649025, 'eval_recall': 0.5781071835803877, 'eval_f1': 0.518935516888434, 'eval_accuracy': 0.9500887825214236, 'eval_runtime': 4.6672, 'eval_samples_per_second': 328.037, 'eval_steps_per_second': 41.139, 'epoch': 2.0, 'step': 270}, {'loss': 0.0646, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.15558449923992157, 'eval_precision': 0.4940239043824701, 'eval_recall': 0.5655644241733181, 'eval_f1': 0.5273790536948432, 'eval_accuracy': 0.952211842816336, 'eval_runtime': 4.6661, 'eval_samples_per_second': 328.115, 'eval_steps_per_second': 41.148, 'epoch': 3.0, 'step': 405}, {'loss': 0.0349, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.1871093511581421, 'eval_precision': 0.49742533470648814, 'eval_recall': 0.5507411630558723, 'eval_f1': 0.5227272727272727, 'eval_accuracy': 0.9511696132170153, 'eval_runtime': 4.6649, 'eval_samples_per_second': 328.199, 'eval_steps_per_second': 41.159, 'epoch': 4.0, 'step': 540}, {'loss': 0.0197, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.2279435694217682, 'eval_precision': 0.515695067264574, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5200678349349915, 'eval_accuracy': 0.95336987570447, 'eval_runtime': 4.6608, 'eval_samples_per_second': 328.483, 'eval_steps_per_second': 41.194, 'epoch': 5.0, 'step': 675}, {'loss': 0.011, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.26639094948768616, 'eval_precision': 0.5499383477188656, 'eval_recall': 0.508551881413911, 'eval_f1': 0.5284360189573459, 'eval_accuracy': 0.9557631436732803, 'eval_runtime': 4.6636, 'eval_samples_per_second': 328.286, 'eval_steps_per_second': 41.17, 'epoch': 6.0, 'step': 810}, {'loss': 0.0075, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.2532074451446533, 'eval_precision': 0.4566003616636528, 'eval_recall': 0.5758266818700114, 'eval_f1': 0.5093292990418558, 'eval_accuracy': 0.9485061375743071, 'eval_runtime': 4.6745, 'eval_samples_per_second': 327.525, 'eval_steps_per_second': 41.074, 'epoch': 7.0, 'step': 945}, {'loss': 0.0056, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.25323495268821716, 'eval_precision': 0.5042918454935622, 'eval_recall': 0.5359179019384265, 'eval_f1': 0.5196241017136539, 'eval_accuracy': 0.9534470778970123, 'eval_runtime': 4.6623, 'eval_samples_per_second': 328.38, 'eval_steps_per_second': 41.182, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0046, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.28256669640541077, 'eval_precision': 0.4935064935064935, 'eval_recall': 0.5632839224629419, 'eval_f1': 0.5260915867944622, 'eval_accuracy': 0.9531768702231144, 'eval_runtime': 4.6628, 'eval_samples_per_second': 328.34, 'eval_steps_per_second': 41.177, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0039, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.29585784673690796, 'eval_precision': 0.5203619909502263, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5224304372515616, 'eval_accuracy': 0.9541804987261638, 'eval_runtime': 4.6648, 'eval_samples_per_second': 328.2, 'eval_steps_per_second': 41.159, 'epoch': 10.0, 'step': 1350}, {'loss': 0.003, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.3026910424232483, 'eval_precision': 0.536928487690504, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5294797687861271, 'eval_accuracy': 0.9544121053037906, 'eval_runtime': 4.6582, 'eval_samples_per_second': 328.667, 'eval_steps_per_second': 41.218, 'epoch': 11.0, 'step': 1485}, {'loss': 0.0031, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.32662954926490784, 'eval_precision': 0.528555431131019, 'eval_recall': 0.5381984036488028, 'eval_f1': 0.5333333333333333, 'eval_accuracy': 0.9544121053037906, 'eval_runtime': 4.6607, 'eval_samples_per_second': 328.495, 'eval_steps_per_second': 41.196, 'epoch': 12.0, 'step': 1620}, {'loss': 0.0015, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.33693355321884155, 'eval_precision': 0.5390070921985816, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5293093441671503, 'eval_accuracy': 0.9552227283254845, 'eval_runtime': 4.666, 'eval_samples_per_second': 328.117, 'eval_steps_per_second': 41.149, 'epoch': 13.0, 'step': 1755}, {'loss': 0.0016, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.32149526476860046, 'eval_precision': 0.5542021924482339, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5359246171967021, 'eval_accuracy': 0.9560333513471783, 'eval_runtime': 4.6563, 'eval_samples_per_second': 328.804, 'eval_steps_per_second': 41.235, 'epoch': 14.0, 'step': 1890}, {'loss': 0.0015, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.3228573203086853, 'eval_precision': 0.5522388059701493, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.5282569898869721, 'eval_accuracy': 0.955956149154636, 'eval_runtime': 4.6521, 'eval_samples_per_second': 329.097, 'eval_steps_per_second': 41.271, 'epoch': 15.0, 'step': 2025}, {'loss': 0.0009, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.34076786041259766, 'eval_precision': 0.5589919816723941, 'eval_recall': 0.556442417331813, 'eval_f1': 0.5577142857142857, 'eval_accuracy': 0.9566123677912453, 'eval_runtime': 4.6555, 'eval_samples_per_second': 328.861, 'eval_steps_per_second': 41.242, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0009, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.3375677466392517, 'eval_precision': 0.5598548972188634, 'eval_recall': 0.5279361459521095, 'eval_f1': 0.5434272300469484, 'eval_accuracy': 0.9569597776576855, 'eval_runtime': 4.6562, 'eval_samples_per_second': 328.812, 'eval_steps_per_second': 41.236, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0003, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.3550891876220703, 'eval_precision': 0.5389755011135857, 'eval_recall': 0.5518814139110604, 'eval_f1': 0.5453521126760563, 'eval_accuracy': 0.955956149154636, 'eval_runtime': 4.6586, 'eval_samples_per_second': 328.64, 'eval_steps_per_second': 41.214, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0002, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.3614993989467621, 'eval_precision': 0.536, 'eval_recall': 0.5347776510832383, 'eval_f1': 0.5353881278538812, 'eval_accuracy': 0.955647340384467, 'eval_runtime': 4.6608, 'eval_samples_per_second': 328.486, 'eval_steps_per_second': 41.195, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0003, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.3614985942840576, 'eval_precision': 0.552439024390244, 'eval_recall': 0.5165336374002281, 'eval_f1': 0.5338833235120802, 'eval_accuracy': 0.9567667721763298, 'eval_runtime': 4.7342, 'eval_samples_per_second': 323.391, 'eval_steps_per_second': 40.556, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0003, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.36848533153533936, 'eval_precision': 0.5369955156950673, 'eval_recall': 0.5461801596351197, 'eval_f1': 0.5415488976823063, 'eval_accuracy': 0.9551455261329421, 'eval_runtime': 4.6603, 'eval_samples_per_second': 328.52, 'eval_steps_per_second': 41.199, 'epoch': 21.0, 'step': 2835}, {'loss': 0.0001, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.3748254179954529, 'eval_precision': 0.5535307517084282, 'eval_recall': 0.5541619156214367, 'eval_f1': 0.5538461538461539, 'eval_accuracy': 0.9563807612136185, 'eval_runtime': 4.6628, 'eval_samples_per_second': 328.347, 'eval_steps_per_second': 41.177, 'epoch': 22.0, 'step': 2970}, {'loss': 0.0002, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.37512606382369995, 'eval_precision': 0.5581395348837209, 'eval_recall': 0.5473204104903079, 'eval_f1': 0.5526770293609672, 'eval_accuracy': 0.9564193623098896, 'eval_runtime': 4.6632, 'eval_samples_per_second': 328.318, 'eval_steps_per_second': 41.174, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.37619295716285706, 'eval_precision': 0.5571095571095571, 'eval_recall': 0.5450399087799316, 'eval_f1': 0.5510086455331413, 'eval_accuracy': 0.956535165598703, 'eval_runtime': 4.6611, 'eval_samples_per_second': 328.465, 'eval_steps_per_second': 41.192, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 2101.2017, 'train_samples_per_second': 98.618, 'train_steps_per_second': 1.542, 'total_flos': 2.5991352100330236e+16, 'train_loss': 0.02046515036885983, 'epoch': 24.0, 'step': 3240}]

Evaluation, NbAiLab/nb-bert-large
***** predict metrics *****
  predict_accuracy           =     0.9476
  predict_f1                 =      0.513
  predict_loss               =     0.1534
  predict_precision          =      0.471
  predict_recall             =     0.5633
  predict_runtime            = 0:00:03.92
  predict_samples_per_second =    324.223
  predict_steps_per_second   =     40.528
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_33.json completed. F1: 0.5130111524163569
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_28.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_28.json
01170939_tsa-bin_NorBERT_3_small Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6795.80 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 7135.52 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6844.22 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6866.21 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6913.20 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7031.19 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:00<00:00, 7187.98 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 7247.48 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6720.10 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7312.49 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6964.14 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6956.69 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6764.81 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
01170939_tsa-bin_NorBERT_3_small Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.5924, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': 0.2342902421951294, 'eval_precision': 0.6346153846153846, 'eval_recall': 0.037628278221208664, 'eval_f1': 0.07104413347685684, 'eval_accuracy': 0.9353431637458504, 'eval_runtime': 3.0325, 'eval_samples_per_second': 504.858, 'eval_steps_per_second': 63.313, 'epoch': 1.0}
{'loss': 0.225, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': 0.20251691341400146, 'eval_precision': 0.2003257328990228, 'eval_recall': 0.1402508551881414, 'eval_f1': 0.164989939637827, 'eval_accuracy': 0.9383154481587277, 'eval_runtime': 2.995, 'eval_samples_per_second': 511.191, 'eval_steps_per_second': 64.108, 'epoch': 2.0}
{'loss': 0.1728, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': 0.17587943375110626, 'eval_precision': 0.4568081991215227, 'eval_recall': 0.3557582668187001, 'eval_f1': 0.4, 'eval_accuracy': 0.9476955145526132, 'eval_runtime': 3.0024, 'eval_samples_per_second': 509.924, 'eval_steps_per_second': 63.949, 'epoch': 3.0}
{'loss': 0.1131, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.19103577733039856, 'eval_precision': 0.4387254901960784, 'eval_recall': 0.40820980615735464, 'eval_f1': 0.4229178972238629, 'eval_accuracy': 0.9446460279471937, 'eval_runtime': 2.9982, 'eval_samples_per_second': 510.635, 'eval_steps_per_second': 64.038, 'epoch': 4.0}
{'loss': 0.0857, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.19878631830215454, 'eval_precision': 0.4246885617214043, 'eval_recall': 0.427594070695553, 'eval_f1': 0.42613636363636365, 'eval_accuracy': 0.942445765459739, 'eval_runtime': 3.0157, 'eval_samples_per_second': 507.671, 'eval_steps_per_second': 63.666, 'epoch': 5.0}
{'loss': 0.0657, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.206822469830513, 'eval_precision': 0.4156378600823045, 'eval_recall': 0.4606613454960091, 'eval_f1': 0.43699296917252567, 'eval_accuracy': 0.9438740060217711, 'eval_runtime': 3.0065, 'eval_samples_per_second': 509.228, 'eval_steps_per_second': 63.861, 'epoch': 6.0}
{'loss': 0.0469, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': 0.22836977243423462, 'eval_precision': 0.4362549800796813, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.46570972886762363, 'eval_accuracy': 0.945611055353972, 'eval_runtime': 2.9981, 'eval_samples_per_second': 510.651, 'eval_steps_per_second': 64.04, 'epoch': 7.0}
{'loss': 0.0338, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': 0.24064534902572632, 'eval_precision': 0.4584269662921348, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.4617996604414261, 'eval_accuracy': 0.9470778970122752, 'eval_runtime': 3.0056, 'eval_samples_per_second': 509.386, 'eval_steps_per_second': 63.881, 'epoch': 8.0}
{'loss': 0.0241, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': 0.24513477087020874, 'eval_precision': 0.4610983981693364, 'eval_recall': 0.45952109464082097, 'eval_f1': 0.46030839520274125, 'eval_accuracy': 0.946769088242106, 'eval_runtime': 2.9917, 'eval_samples_per_second': 511.754, 'eval_steps_per_second': 64.178, 'epoch': 9.0}
{'loss': 0.0174, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.26189303398132324, 'eval_precision': 0.4225774225774226, 'eval_recall': 0.4823261117445838, 'eval_f1': 0.45047923322683703, 'eval_accuracy': 0.9434107928665174, 'eval_runtime': 3.0701, 'eval_samples_per_second': 498.686, 'eval_steps_per_second': 62.539, 'epoch': 10.0}
{'loss': 0.0134, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': 0.2616191506385803, 'eval_precision': 0.47264260768335276, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.467741935483871, 'eval_accuracy': 0.9483517331892226, 'eval_runtime': 3.01, 'eval_samples_per_second': 508.641, 'eval_steps_per_second': 63.788, 'epoch': 11.0}
{'loss': 0.0102, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': 0.2802176773548126, 'eval_precision': 0.4311663479923518, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.469058762350494, 'eval_accuracy': 0.9437196016366864, 'eval_runtime': 2.9974, 'eval_samples_per_second': 510.768, 'eval_steps_per_second': 64.054, 'epoch': 12.0}
{'loss': 0.0077, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': 0.2851819097995758, 'eval_precision': 0.46360582306830905, 'eval_recall': 0.47206385404789053, 'eval_f1': 0.4677966101694915, 'eval_accuracy': 0.9457654597390566, 'eval_runtime': 2.9909, 'eval_samples_per_second': 511.878, 'eval_steps_per_second': 64.194, 'epoch': 13.0}
{'loss': 0.0069, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': 0.29199984669685364, 'eval_precision': 0.4657534246575342, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.4654877353108956, 'eval_accuracy': 0.9471937003010885, 'eval_runtime': 3.0048, 'eval_samples_per_second': 509.517, 'eval_steps_per_second': 63.898, 'epoch': 14.0}
{'loss': 0.0056, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': 0.29942747950553894, 'eval_precision': 0.4658454647256439, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.47005649717514125, 'eval_accuracy': 0.9459584652204123, 'eval_runtime': 3.1123, 'eval_samples_per_second': 491.926, 'eval_steps_per_second': 61.692, 'epoch': 15.0}
{'loss': 0.0046, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.2985076308250427, 'eval_precision': 0.47107438016528924, 'eval_recall': 0.4549600912200684, 'eval_f1': 0.46287703016241294, 'eval_accuracy': 0.9473867057824442, 'eval_runtime': 2.9962, 'eval_samples_per_second': 510.983, 'eval_steps_per_second': 64.082, 'epoch': 16.0}
{'loss': 0.0034, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': 0.3126821219921112, 'eval_precision': 0.45966850828729283, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.46689113355780026, 'eval_accuracy': 0.9462672739905813, 'eval_runtime': 3.0336, 'eval_samples_per_second': 504.685, 'eval_steps_per_second': 63.292, 'epoch': 17.0}
{'loss': 0.0033, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': 0.3141863942146301, 'eval_precision': 0.459375, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.48013064779531844, 'eval_accuracy': 0.9461128696054968, 'eval_runtime': 2.9928, 'eval_samples_per_second': 511.566, 'eval_steps_per_second': 64.155, 'epoch': 18.0}
{'loss': 0.0026, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': 0.3142082095146179, 'eval_precision': 0.4730473047304731, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.4815229563269877, 'eval_accuracy': 0.9462286728943102, 'eval_runtime': 2.9968, 'eval_samples_per_second': 510.877, 'eval_steps_per_second': 64.068, 'epoch': 19.0}
{'loss': 0.0021, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': 0.3197009265422821, 'eval_precision': 0.45304437564499483, 'eval_recall': 0.500570125427594, 'eval_f1': 0.475622968580715, 'eval_accuracy': 0.9448390334285494, 'eval_runtime': 2.9939, 'eval_samples_per_second': 511.373, 'eval_steps_per_second': 64.13, 'epoch': 20.0}
{'loss': 0.0023, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': 0.3224096894264221, 'eval_precision': 0.47434435575826683, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.47434435575826683, 'eval_accuracy': 0.947309503589902, 'eval_runtime': 3.0045, 'eval_samples_per_second': 509.575, 'eval_steps_per_second': 63.905, 'epoch': 21.0}
{'loss': 0.002, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.32283446192741394, 'eval_precision': 0.48148148148148145, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.4778862722573234, 'eval_accuracy': 0.9476569134563422, 'eval_runtime': 3.0127, 'eval_samples_per_second': 508.183, 'eval_steps_per_second': 63.73, 'epoch': 22.0}
{'loss': 0.002, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': 0.3224409520626068, 'eval_precision': 0.4626865671641791, 'eval_recall': 0.49486887115165334, 'eval_f1': 0.478236914600551, 'eval_accuracy': 0.9459584652204123, 'eval_runtime': 3.0763, 'eval_samples_per_second': 497.681, 'eval_steps_per_second': 62.413, 'epoch': 23.0}
{'loss': 0.0017, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.3213992416858673, 'eval_precision': 0.48519362186788156, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.4854700854700855, 'eval_accuracy': 0.9471937003010885, 'eval_runtime': 2.9932, 'eval_samples_per_second': 511.499, 'eval_steps_per_second': 64.146, 'epoch': 24.0}
{'train_runtime': 413.9157, 'train_samples_per_second': 500.624, 'train_steps_per_second': 7.828, 'train_loss': 0.06018285291890303, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0602
  train_runtime            = 0:06:53.91
  train_samples            =       8634
  train_samples_per_second =    500.624
  train_steps_per_second   =      7.828
[{'loss': 0.5924, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.2342902421951294, 'eval_precision': 0.6346153846153846, 'eval_recall': 0.037628278221208664, 'eval_f1': 0.07104413347685684, 'eval_accuracy': 0.9353431637458504, 'eval_runtime': 3.0325, 'eval_samples_per_second': 504.858, 'eval_steps_per_second': 63.313, 'epoch': 1.0, 'step': 135}, {'loss': 0.225, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.20251691341400146, 'eval_precision': 0.2003257328990228, 'eval_recall': 0.1402508551881414, 'eval_f1': 0.164989939637827, 'eval_accuracy': 0.9383154481587277, 'eval_runtime': 2.995, 'eval_samples_per_second': 511.191, 'eval_steps_per_second': 64.108, 'epoch': 2.0, 'step': 270}, {'loss': 0.1728, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.17587943375110626, 'eval_precision': 0.4568081991215227, 'eval_recall': 0.3557582668187001, 'eval_f1': 0.4, 'eval_accuracy': 0.9476955145526132, 'eval_runtime': 3.0024, 'eval_samples_per_second': 509.924, 'eval_steps_per_second': 63.949, 'epoch': 3.0, 'step': 405}, {'loss': 0.1131, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.19103577733039856, 'eval_precision': 0.4387254901960784, 'eval_recall': 0.40820980615735464, 'eval_f1': 0.4229178972238629, 'eval_accuracy': 0.9446460279471937, 'eval_runtime': 2.9982, 'eval_samples_per_second': 510.635, 'eval_steps_per_second': 64.038, 'epoch': 4.0, 'step': 540}, {'loss': 0.0857, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.19878631830215454, 'eval_precision': 0.4246885617214043, 'eval_recall': 0.427594070695553, 'eval_f1': 0.42613636363636365, 'eval_accuracy': 0.942445765459739, 'eval_runtime': 3.0157, 'eval_samples_per_second': 507.671, 'eval_steps_per_second': 63.666, 'epoch': 5.0, 'step': 675}, {'loss': 0.0657, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.206822469830513, 'eval_precision': 0.4156378600823045, 'eval_recall': 0.4606613454960091, 'eval_f1': 0.43699296917252567, 'eval_accuracy': 0.9438740060217711, 'eval_runtime': 3.0065, 'eval_samples_per_second': 509.228, 'eval_steps_per_second': 63.861, 'epoch': 6.0, 'step': 810}, {'loss': 0.0469, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.22836977243423462, 'eval_precision': 0.4362549800796813, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.46570972886762363, 'eval_accuracy': 0.945611055353972, 'eval_runtime': 2.9981, 'eval_samples_per_second': 510.651, 'eval_steps_per_second': 64.04, 'epoch': 7.0, 'step': 945}, {'loss': 0.0338, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.24064534902572632, 'eval_precision': 0.4584269662921348, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.4617996604414261, 'eval_accuracy': 0.9470778970122752, 'eval_runtime': 3.0056, 'eval_samples_per_second': 509.386, 'eval_steps_per_second': 63.881, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0241, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.24513477087020874, 'eval_precision': 0.4610983981693364, 'eval_recall': 0.45952109464082097, 'eval_f1': 0.46030839520274125, 'eval_accuracy': 0.946769088242106, 'eval_runtime': 2.9917, 'eval_samples_per_second': 511.754, 'eval_steps_per_second': 64.178, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0174, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.26189303398132324, 'eval_precision': 0.4225774225774226, 'eval_recall': 0.4823261117445838, 'eval_f1': 0.45047923322683703, 'eval_accuracy': 0.9434107928665174, 'eval_runtime': 3.0701, 'eval_samples_per_second': 498.686, 'eval_steps_per_second': 62.539, 'epoch': 10.0, 'step': 1350}, {'loss': 0.0134, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.2616191506385803, 'eval_precision': 0.47264260768335276, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.467741935483871, 'eval_accuracy': 0.9483517331892226, 'eval_runtime': 3.01, 'eval_samples_per_second': 508.641, 'eval_steps_per_second': 63.788, 'epoch': 11.0, 'step': 1485}, {'loss': 0.0102, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.2802176773548126, 'eval_precision': 0.4311663479923518, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.469058762350494, 'eval_accuracy': 0.9437196016366864, 'eval_runtime': 2.9974, 'eval_samples_per_second': 510.768, 'eval_steps_per_second': 64.054, 'epoch': 12.0, 'step': 1620}, {'loss': 0.0077, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.2851819097995758, 'eval_precision': 0.46360582306830905, 'eval_recall': 0.47206385404789053, 'eval_f1': 0.4677966101694915, 'eval_accuracy': 0.9457654597390566, 'eval_runtime': 2.9909, 'eval_samples_per_second': 511.878, 'eval_steps_per_second': 64.194, 'epoch': 13.0, 'step': 1755}, {'loss': 0.0069, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.29199984669685364, 'eval_precision': 0.4657534246575342, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.4654877353108956, 'eval_accuracy': 0.9471937003010885, 'eval_runtime': 3.0048, 'eval_samples_per_second': 509.517, 'eval_steps_per_second': 63.898, 'epoch': 14.0, 'step': 1890}, {'loss': 0.0056, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.29942747950553894, 'eval_precision': 0.4658454647256439, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.47005649717514125, 'eval_accuracy': 0.9459584652204123, 'eval_runtime': 3.1123, 'eval_samples_per_second': 491.926, 'eval_steps_per_second': 61.692, 'epoch': 15.0, 'step': 2025}, {'loss': 0.0046, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.2985076308250427, 'eval_precision': 0.47107438016528924, 'eval_recall': 0.4549600912200684, 'eval_f1': 0.46287703016241294, 'eval_accuracy': 0.9473867057824442, 'eval_runtime': 2.9962, 'eval_samples_per_second': 510.983, 'eval_steps_per_second': 64.082, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0034, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.3126821219921112, 'eval_precision': 0.45966850828729283, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.46689113355780026, 'eval_accuracy': 0.9462672739905813, 'eval_runtime': 3.0336, 'eval_samples_per_second': 504.685, 'eval_steps_per_second': 63.292, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0033, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.3141863942146301, 'eval_precision': 0.459375, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.48013064779531844, 'eval_accuracy': 0.9461128696054968, 'eval_runtime': 2.9928, 'eval_samples_per_second': 511.566, 'eval_steps_per_second': 64.155, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0026, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.3142082095146179, 'eval_precision': 0.4730473047304731, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.4815229563269877, 'eval_accuracy': 0.9462286728943102, 'eval_runtime': 2.9968, 'eval_samples_per_second': 510.877, 'eval_steps_per_second': 64.068, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0021, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.3197009265422821, 'eval_precision': 0.45304437564499483, 'eval_recall': 0.500570125427594, 'eval_f1': 0.475622968580715, 'eval_accuracy': 0.9448390334285494, 'eval_runtime': 2.9939, 'eval_samples_per_second': 511.373, 'eval_steps_per_second': 64.13, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0023, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.3224096894264221, 'eval_precision': 0.47434435575826683, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.47434435575826683, 'eval_accuracy': 0.947309503589902, 'eval_runtime': 3.0045, 'eval_samples_per_second': 509.575, 'eval_steps_per_second': 63.905, 'epoch': 21.0, 'step': 2835}, {'loss': 0.002, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.32283446192741394, 'eval_precision': 0.48148148148148145, 'eval_recall': 0.47434435575826683, 'eval_f1': 0.4778862722573234, 'eval_accuracy': 0.9476569134563422, 'eval_runtime': 3.0127, 'eval_samples_per_second': 508.183, 'eval_steps_per_second': 63.73, 'epoch': 22.0, 'step': 2970}, {'loss': 0.002, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.3224409520626068, 'eval_precision': 0.4626865671641791, 'eval_recall': 0.49486887115165334, 'eval_f1': 0.478236914600551, 'eval_accuracy': 0.9459584652204123, 'eval_runtime': 3.0763, 'eval_samples_per_second': 497.681, 'eval_steps_per_second': 62.413, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0017, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.3213992416858673, 'eval_precision': 0.48519362186788156, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.4854700854700855, 'eval_accuracy': 0.9471937003010885, 'eval_runtime': 2.9932, 'eval_samples_per_second': 511.499, 'eval_steps_per_second': 64.146, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 413.9157, 'train_samples_per_second': 500.624, 'train_steps_per_second': 7.828, 'total_flos': 1912879488074940.0, 'train_loss': 0.06018285291890303, 'epoch': 24.0, 'step': 3240}]

Evaluation, ltg/norbert3-small
***** predict metrics *****
  predict_accuracy           =     0.9495
  predict_f1                 =     0.3877
  predict_loss               =     0.1819
  predict_precision          =     0.4799
  predict_recall             =     0.3252
  predict_runtime            = 0:00:02.49
  predict_samples_per_second =    510.163
  predict_steps_per_second   =      63.77
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_28.json completed. F1: 0.3876723438767234
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_32.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at NbAiLab/nb-bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_32.json
01170939_tsa-bin_NB-BERT_base Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 5669.72 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:01, 6632.17 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6685.35 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6821.88 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6897.12 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7038.89 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6244.29 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6556.22 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6634.19 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7309.24 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6973.52 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6990.86 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6812.03 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Checkpoint destination directory /cluster/work/projects/ec30/egilron/tsa-hf/01170939_tsa-bin_NB-BERT_base/checkpoint-135 already exists and is non-empty.Saving will proceed but saved results may be invalid.
01170939_tsa-bin_NB-BERT_base Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2119, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0}
{'eval_loss': 0.1498766541481018, 'eval_precision': 0.44763860369609854, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.47109670448406266, 'eval_accuracy': 0.9475025090712577, 'eval_runtime': 2.3783, 'eval_samples_per_second': 643.739, 'eval_steps_per_second': 80.73, 'epoch': 1.0}
{'loss': 0.1269, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0}
{'eval_loss': 0.15317454934120178, 'eval_precision': 0.473630831643002, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5013419216317767, 'eval_accuracy': 0.9488149463444762, 'eval_runtime': 2.3692, 'eval_samples_per_second': 646.199, 'eval_steps_per_second': 81.039, 'epoch': 2.0}
{'loss': 0.074, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0}
{'eval_loss': 0.16694708168506622, 'eval_precision': 0.513189448441247, 'eval_recall': 0.4880273660205245, 'eval_f1': 0.5002922267679719, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 2.3672, 'eval_samples_per_second': 646.767, 'eval_steps_per_second': 81.11, 'epoch': 3.0}
{'loss': 0.0441, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.20511691272258759, 'eval_precision': 0.510178117048346, 'eval_recall': 0.4572405929304447, 'eval_f1': 0.48226097414311486, 'eval_accuracy': 0.9503203890990504, 'eval_runtime': 2.3689, 'eval_samples_per_second': 646.298, 'eval_steps_per_second': 81.051, 'epoch': 4.0}
{'loss': 0.0253, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.2330634742975235, 'eval_precision': 0.46331658291457284, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.49252136752136755, 'eval_accuracy': 0.9458426619315988, 'eval_runtime': 2.3647, 'eval_samples_per_second': 647.451, 'eval_steps_per_second': 81.196, 'epoch': 5.0}
{'loss': 0.0155, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.25483524799346924, 'eval_precision': 0.4755244755244755, 'eval_recall': 0.5427594070695553, 'eval_f1': 0.5069222577209797, 'eval_accuracy': 0.9473867057824442, 'eval_runtime': 2.3607, 'eval_samples_per_second': 648.529, 'eval_steps_per_second': 81.331, 'epoch': 6.0}
{'loss': 0.011, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0}
{'eval_loss': 0.2857145369052887, 'eval_precision': 0.4707792207792208, 'eval_recall': 0.4960091220068415, 'eval_f1': 0.4830649639089395, 'eval_accuracy': 0.9470006948197329, 'eval_runtime': 2.366, 'eval_samples_per_second': 647.079, 'eval_steps_per_second': 81.149, 'epoch': 7.0}
{'loss': 0.0079, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0}
{'eval_loss': 0.29421260952949524, 'eval_precision': 0.488962472406181, 'eval_recall': 0.5051311288483467, 'eval_f1': 0.49691531127313515, 'eval_accuracy': 0.9477341156488844, 'eval_runtime': 2.3604, 'eval_samples_per_second': 648.629, 'eval_steps_per_second': 81.343, 'epoch': 8.0}
{'loss': 0.0065, 'learning_rate': 5e-05, 'epoch': 9.0}
{'eval_loss': 0.3046606183052063, 'eval_precision': 0.4352126607319486, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.4661016949152543, 'eval_accuracy': 0.9437196016366864, 'eval_runtime': 2.359, 'eval_samples_per_second': 649.011, 'eval_steps_per_second': 81.391, 'epoch': 9.0}
{'loss': 0.0056, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.33105936646461487, 'eval_precision': 0.4804733727810651, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4715447154471545, 'eval_accuracy': 0.9480043233227824, 'eval_runtime': 2.3589, 'eval_samples_per_second': 649.026, 'eval_steps_per_second': 81.393, 'epoch': 10.0}
{'loss': 0.0037, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}
{'eval_loss': 0.3420388996601105, 'eval_precision': 0.46835443037974683, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.48657534246575335, 'eval_accuracy': 0.9461128696054968, 'eval_runtime': 2.357, 'eval_samples_per_second': 649.566, 'eval_steps_per_second': 81.461, 'epoch': 11.0}
{'loss': 0.0029, 'learning_rate': 4e-05, 'epoch': 12.0}
{'eval_loss': 0.3609592020511627, 'eval_precision': 0.5, 'eval_recall': 0.467502850627138, 'eval_f1': 0.48320565704183854, 'eval_accuracy': 0.9470778970122752, 'eval_runtime': 2.3597, 'eval_samples_per_second': 648.806, 'eval_steps_per_second': 81.366, 'epoch': 12.0}
{'loss': 0.0032, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0}
{'eval_loss': 0.333679735660553, 'eval_precision': 0.48068669527896996, 'eval_recall': 0.5108323831242874, 'eval_f1': 0.4953012714206744, 'eval_accuracy': 0.9477341156488844, 'eval_runtime': 2.3625, 'eval_samples_per_second': 648.033, 'eval_steps_per_second': 81.269, 'epoch': 13.0}
{'loss': 0.0022, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0}
{'eval_loss': 0.3439895212650299, 'eval_precision': 0.4983534577387486, 'eval_recall': 0.5176738882554162, 'eval_f1': 0.5078299776286354, 'eval_accuracy': 0.9489307496332896, 'eval_runtime': 2.358, 'eval_samples_per_second': 649.286, 'eval_steps_per_second': 81.426, 'epoch': 14.0}
{'loss': 0.0016, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0}
{'eval_loss': 0.3528522849082947, 'eval_precision': 0.5040840140023337, 'eval_recall': 0.4925883694412771, 'eval_f1': 0.4982698961937716, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 2.3529, 'eval_samples_per_second': 650.69, 'eval_steps_per_second': 81.602, 'epoch': 15.0}
{'loss': 0.0013, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.36112719774246216, 'eval_precision': 0.5052386495925495, 'eval_recall': 0.49486887115165334, 'eval_f1': 0.5, 'eval_accuracy': 0.9480815255153247, 'eval_runtime': 2.3531, 'eval_samples_per_second': 650.643, 'eval_steps_per_second': 81.596, 'epoch': 16.0}
{'loss': 0.0008, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0}
{'eval_loss': 0.36982640624046326, 'eval_precision': 0.5021929824561403, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5120178870877586, 'eval_accuracy': 0.9485833397668494, 'eval_runtime': 2.3601, 'eval_samples_per_second': 648.691, 'eval_steps_per_second': 81.351, 'epoch': 17.0}
{'loss': 0.0006, 'learning_rate': 2e-05, 'epoch': 18.0}
{'eval_loss': 0.3805343508720398, 'eval_precision': 0.518957345971564, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.5090063916327716, 'eval_accuracy': 0.9492395584034586, 'eval_runtime': 2.3611, 'eval_samples_per_second': 648.423, 'eval_steps_per_second': 81.318, 'epoch': 18.0}
{'loss': 0.0007, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0}
{'eval_loss': 0.37945133447647095, 'eval_precision': 0.5206611570247934, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.5116009280742461, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 2.3573, 'eval_samples_per_second': 649.459, 'eval_steps_per_second': 81.448, 'epoch': 19.0}
{'loss': 0.0006, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0}
{'eval_loss': 0.38442370295524597, 'eval_precision': 0.526564344746163, 'eval_recall': 0.508551881413911, 'eval_f1': 0.5174013921113688, 'eval_accuracy': 0.9490465529221029, 'eval_runtime': 2.3547, 'eval_samples_per_second': 650.194, 'eval_steps_per_second': 81.54, 'epoch': 20.0}
{'loss': 0.0004, 'learning_rate': 1e-05, 'epoch': 21.0}
{'eval_loss': 0.3809370994567871, 'eval_precision': 0.519406392694064, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5191100969766116, 'eval_accuracy': 0.9496641704624411, 'eval_runtime': 2.3596, 'eval_samples_per_second': 648.825, 'eval_steps_per_second': 81.368, 'epoch': 21.0}
{'loss': 0.0003, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.3831571042537689, 'eval_precision': 0.5149769585253456, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.5123209169054441, 'eval_accuracy': 0.9495097660773566, 'eval_runtime': 2.3543, 'eval_samples_per_second': 650.299, 'eval_steps_per_second': 81.553, 'epoch': 22.0}
{'loss': 0.0003, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0}
{'eval_loss': 0.38663366436958313, 'eval_precision': 0.5199063231850117, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.512998266897747, 'eval_accuracy': 0.9495097660773566, 'eval_runtime': 2.355, 'eval_samples_per_second': 650.104, 'eval_steps_per_second': 81.528, 'epoch': 23.0}
{'loss': 0.0003, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.3877083361148834, 'eval_precision': 0.5144843568945539, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.5103448275862068, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 2.3631, 'eval_samples_per_second': 647.887, 'eval_steps_per_second': 81.25, 'epoch': 24.0}
{'train_runtime': 849.1552, 'train_samples_per_second': 244.026, 'train_steps_per_second': 3.816, 'train_loss': 0.022821316302374557, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0228
  train_runtime            = 0:14:09.15
  train_samples            =       8634
  train_samples_per_second =    244.026
  train_steps_per_second   =      3.816
[{'loss': 0.2119, 'learning_rate': 7.666666666666668e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.1498766541481018, 'eval_precision': 0.44763860369609854, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.47109670448406266, 'eval_accuracy': 0.9475025090712577, 'eval_runtime': 2.3783, 'eval_samples_per_second': 643.739, 'eval_steps_per_second': 80.73, 'epoch': 1.0, 'step': 135}, {'loss': 0.1269, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.15317454934120178, 'eval_precision': 0.473630831643002, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5013419216317767, 'eval_accuracy': 0.9488149463444762, 'eval_runtime': 2.3692, 'eval_samples_per_second': 646.199, 'eval_steps_per_second': 81.039, 'epoch': 2.0, 'step': 270}, {'loss': 0.074, 'learning_rate': 7.000000000000001e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.16694708168506622, 'eval_precision': 0.513189448441247, 'eval_recall': 0.4880273660205245, 'eval_f1': 0.5002922267679719, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 2.3672, 'eval_samples_per_second': 646.767, 'eval_steps_per_second': 81.11, 'epoch': 3.0, 'step': 405}, {'loss': 0.0441, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.20511691272258759, 'eval_precision': 0.510178117048346, 'eval_recall': 0.4572405929304447, 'eval_f1': 0.48226097414311486, 'eval_accuracy': 0.9503203890990504, 'eval_runtime': 2.3689, 'eval_samples_per_second': 646.298, 'eval_steps_per_second': 81.051, 'epoch': 4.0, 'step': 540}, {'loss': 0.0253, 'learning_rate': 6.333333333333333e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.2330634742975235, 'eval_precision': 0.46331658291457284, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.49252136752136755, 'eval_accuracy': 0.9458426619315988, 'eval_runtime': 2.3647, 'eval_samples_per_second': 647.451, 'eval_steps_per_second': 81.196, 'epoch': 5.0, 'step': 675}, {'loss': 0.0155, 'learning_rate': 6.000000000000001e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.25483524799346924, 'eval_precision': 0.4755244755244755, 'eval_recall': 0.5427594070695553, 'eval_f1': 0.5069222577209797, 'eval_accuracy': 0.9473867057824442, 'eval_runtime': 2.3607, 'eval_samples_per_second': 648.529, 'eval_steps_per_second': 81.331, 'epoch': 6.0, 'step': 810}, {'loss': 0.011, 'learning_rate': 5.666666666666668e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.2857145369052887, 'eval_precision': 0.4707792207792208, 'eval_recall': 0.4960091220068415, 'eval_f1': 0.4830649639089395, 'eval_accuracy': 0.9470006948197329, 'eval_runtime': 2.366, 'eval_samples_per_second': 647.079, 'eval_steps_per_second': 81.149, 'epoch': 7.0, 'step': 945}, {'loss': 0.0079, 'learning_rate': 5.333333333333333e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.29421260952949524, 'eval_precision': 0.488962472406181, 'eval_recall': 0.5051311288483467, 'eval_f1': 0.49691531127313515, 'eval_accuracy': 0.9477341156488844, 'eval_runtime': 2.3604, 'eval_samples_per_second': 648.629, 'eval_steps_per_second': 81.343, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0065, 'learning_rate': 5e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.3046606183052063, 'eval_precision': 0.4352126607319486, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.4661016949152543, 'eval_accuracy': 0.9437196016366864, 'eval_runtime': 2.359, 'eval_samples_per_second': 649.011, 'eval_steps_per_second': 81.391, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0056, 'learning_rate': 4.666666666666667e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.33105936646461487, 'eval_precision': 0.4804733727810651, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4715447154471545, 'eval_accuracy': 0.9480043233227824, 'eval_runtime': 2.3589, 'eval_samples_per_second': 649.026, 'eval_steps_per_second': 81.393, 'epoch': 10.0, 'step': 1350}, {'loss': 0.0037, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.3420388996601105, 'eval_precision': 0.46835443037974683, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.48657534246575335, 'eval_accuracy': 0.9461128696054968, 'eval_runtime': 2.357, 'eval_samples_per_second': 649.566, 'eval_steps_per_second': 81.461, 'epoch': 11.0, 'step': 1485}, {'loss': 0.0029, 'learning_rate': 4e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.3609592020511627, 'eval_precision': 0.5, 'eval_recall': 0.467502850627138, 'eval_f1': 0.48320565704183854, 'eval_accuracy': 0.9470778970122752, 'eval_runtime': 2.3597, 'eval_samples_per_second': 648.806, 'eval_steps_per_second': 81.366, 'epoch': 12.0, 'step': 1620}, {'loss': 0.0032, 'learning_rate': 3.6666666666666666e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.333679735660553, 'eval_precision': 0.48068669527896996, 'eval_recall': 0.5108323831242874, 'eval_f1': 0.4953012714206744, 'eval_accuracy': 0.9477341156488844, 'eval_runtime': 2.3625, 'eval_samples_per_second': 648.033, 'eval_steps_per_second': 81.269, 'epoch': 13.0, 'step': 1755}, {'loss': 0.0022, 'learning_rate': 3.3333333333333335e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.3439895212650299, 'eval_precision': 0.4983534577387486, 'eval_recall': 0.5176738882554162, 'eval_f1': 0.5078299776286354, 'eval_accuracy': 0.9489307496332896, 'eval_runtime': 2.358, 'eval_samples_per_second': 649.286, 'eval_steps_per_second': 81.426, 'epoch': 14.0, 'step': 1890}, {'loss': 0.0016, 'learning_rate': 3.0000000000000004e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.3528522849082947, 'eval_precision': 0.5040840140023337, 'eval_recall': 0.4925883694412771, 'eval_f1': 0.4982698961937716, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 2.3529, 'eval_samples_per_second': 650.69, 'eval_steps_per_second': 81.602, 'epoch': 15.0, 'step': 2025}, {'loss': 0.0013, 'learning_rate': 2.6666666666666667e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.36112719774246216, 'eval_precision': 0.5052386495925495, 'eval_recall': 0.49486887115165334, 'eval_f1': 0.5, 'eval_accuracy': 0.9480815255153247, 'eval_runtime': 2.3531, 'eval_samples_per_second': 650.643, 'eval_steps_per_second': 81.596, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0008, 'learning_rate': 2.3333333333333336e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.36982640624046326, 'eval_precision': 0.5021929824561403, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.5120178870877586, 'eval_accuracy': 0.9485833397668494, 'eval_runtime': 2.3601, 'eval_samples_per_second': 648.691, 'eval_steps_per_second': 81.351, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0006, 'learning_rate': 2e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.3805343508720398, 'eval_precision': 0.518957345971564, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.5090063916327716, 'eval_accuracy': 0.9492395584034586, 'eval_runtime': 2.3611, 'eval_samples_per_second': 648.423, 'eval_steps_per_second': 81.318, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0007, 'learning_rate': 1.6666666666666667e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.37945133447647095, 'eval_precision': 0.5206611570247934, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.5116009280742461, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 2.3573, 'eval_samples_per_second': 649.459, 'eval_steps_per_second': 81.448, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0006, 'learning_rate': 1.3333333333333333e-05, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.38442370295524597, 'eval_precision': 0.526564344746163, 'eval_recall': 0.508551881413911, 'eval_f1': 0.5174013921113688, 'eval_accuracy': 0.9490465529221029, 'eval_runtime': 2.3547, 'eval_samples_per_second': 650.194, 'eval_steps_per_second': 81.54, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0004, 'learning_rate': 1e-05, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.3809370994567871, 'eval_precision': 0.519406392694064, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5191100969766116, 'eval_accuracy': 0.9496641704624411, 'eval_runtime': 2.3596, 'eval_samples_per_second': 648.825, 'eval_steps_per_second': 81.368, 'epoch': 21.0, 'step': 2835}, {'loss': 0.0003, 'learning_rate': 6.666666666666667e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.3831571042537689, 'eval_precision': 0.5149769585253456, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.5123209169054441, 'eval_accuracy': 0.9495097660773566, 'eval_runtime': 2.3543, 'eval_samples_per_second': 650.299, 'eval_steps_per_second': 81.553, 'epoch': 22.0, 'step': 2970}, {'loss': 0.0003, 'learning_rate': 3.3333333333333333e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.38663366436958313, 'eval_precision': 0.5199063231850117, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.512998266897747, 'eval_accuracy': 0.9495097660773566, 'eval_runtime': 2.355, 'eval_samples_per_second': 650.104, 'eval_steps_per_second': 81.528, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0003, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.3877083361148834, 'eval_precision': 0.5144843568945539, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.5103448275862068, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 2.3631, 'eval_samples_per_second': 647.887, 'eval_steps_per_second': 81.25, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 849.1552, 'train_samples_per_second': 244.026, 'train_steps_per_second': 3.816, 'total_flos': 8936323010457180.0, 'train_loss': 0.022821316302374557, 'epoch': 24.0, 'step': 3240}]

Evaluation, NbAiLab/nb-bert-base
***** predict metrics *****
  predict_accuracy           =     0.9482
  predict_f1                 =     0.4439
  predict_loss               =     0.1594
  predict_precision          =     0.4289
  predict_recall             =     0.4599
  predict_runtime            = 0:00:01.96
  predict_samples_per_second =    647.629
  predict_steps_per_second   =     80.954
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_base_32.json completed. F1: 0.44386080105055814
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_21.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_21.json
01170939_tsa-bin_NorBERT_3_small Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6296.42 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 6962.91 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6743.93 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6821.45 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6895.46 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7018.17 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 7188.58 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 7254.17 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6678.55 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7254.50 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6894.38 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6977.63 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6780.43 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
01170939_tsa-bin_NorBERT_3_small Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2635, 'learning_rate': 4.791666666666667e-05, 'epoch': 1.0}
{'eval_loss': 0.15661142766475677, 'eval_precision': 0.43498273878020716, 'eval_recall': 0.43101482326111745, 'eval_f1': 0.4329896907216495, 'eval_accuracy': 0.9465760827607504, 'eval_runtime': 3.0617, 'eval_samples_per_second': 500.053, 'eval_steps_per_second': 62.711, 'epoch': 1.0}
{'loss': 0.1458, 'learning_rate': 4.5833333333333334e-05, 'epoch': 2.0}
{'eval_loss': 0.15406747162342072, 'eval_precision': 0.4414141414141414, 'eval_recall': 0.4982896237172178, 'eval_f1': 0.46813069094804505, 'eval_accuracy': 0.9460742685092257, 'eval_runtime': 3.0347, 'eval_samples_per_second': 504.5, 'eval_steps_per_second': 63.268, 'epoch': 2.0}
{'loss': 0.1002, 'learning_rate': 4.375e-05, 'epoch': 3.0}
{'eval_loss': 0.16564904153347015, 'eval_precision': 0.4963768115942029, 'eval_recall': 0.46864310148232613, 'eval_f1': 0.48211143695014663, 'eval_accuracy': 0.9493939627885432, 'eval_runtime': 3.0272, 'eval_samples_per_second': 505.755, 'eval_steps_per_second': 63.426, 'epoch': 3.0}
{'loss': 0.0664, 'learning_rate': 4.166666666666667e-05, 'epoch': 4.0}
{'eval_loss': 0.18780694901943207, 'eval_precision': 0.474090407938258, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.4820627802690583, 'eval_accuracy': 0.9468462904346483, 'eval_runtime': 3.0438, 'eval_samples_per_second': 502.996, 'eval_steps_per_second': 63.08, 'epoch': 4.0}
{'loss': 0.0448, 'learning_rate': 3.958333333333333e-05, 'epoch': 5.0}
{'eval_loss': 0.22787916660308838, 'eval_precision': 0.4443359375, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.4786954234613362, 'eval_accuracy': 0.9436810005404154, 'eval_runtime': 3.0292, 'eval_samples_per_second': 505.407, 'eval_steps_per_second': 63.382, 'epoch': 5.0}
{'loss': 0.0295, 'learning_rate': 3.7500000000000003e-05, 'epoch': 6.0}
{'eval_loss': 0.27116820216178894, 'eval_precision': 0.43357363542739447, 'eval_recall': 0.48004561003420754, 'eval_f1': 0.45562770562770566, 'eval_accuracy': 0.9458040608353278, 'eval_runtime': 3.025, 'eval_samples_per_second': 506.124, 'eval_steps_per_second': 63.472, 'epoch': 6.0}
{'loss': 0.0215, 'learning_rate': 3.541666666666667e-05, 'epoch': 7.0}
{'eval_loss': 0.28309378027915955, 'eval_precision': 0.430622009569378, 'eval_recall': 0.5131128848346637, 'eval_f1': 0.46826222684703434, 'eval_accuracy': 0.9443372191770246, 'eval_runtime': 3.0229, 'eval_samples_per_second': 506.461, 'eval_steps_per_second': 63.514, 'epoch': 7.0}
{'loss': 0.016, 'learning_rate': 3.3333333333333335e-05, 'epoch': 8.0}
{'eval_loss': 0.29894688725471497, 'eval_precision': 0.46595744680851064, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.4821133736929004, 'eval_accuracy': 0.9470778970122752, 'eval_runtime': 3.0326, 'eval_samples_per_second': 504.843, 'eval_steps_per_second': 63.311, 'epoch': 8.0}
{'loss': 0.0129, 'learning_rate': 3.125e-05, 'epoch': 9.0}
{'eval_loss': 0.30726492404937744, 'eval_precision': 0.46440677966101696, 'eval_recall': 0.46864310148232613, 'eval_f1': 0.46651532349602726, 'eval_accuracy': 0.9479271211302401, 'eval_runtime': 3.0212, 'eval_samples_per_second': 506.759, 'eval_steps_per_second': 63.552, 'epoch': 9.0}
{'loss': 0.0086, 'learning_rate': 2.916666666666667e-05, 'epoch': 10.0}
{'eval_loss': 0.3505348563194275, 'eval_precision': 0.4329501915708812, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.4705882352941176, 'eval_accuracy': 0.9441828147919401, 'eval_runtime': 3.099, 'eval_samples_per_second': 494.023, 'eval_steps_per_second': 61.955, 'epoch': 10.0}
{'loss': 0.0069, 'learning_rate': 2.7083333333333332e-05, 'epoch': 11.0}
{'eval_loss': 0.3656032979488373, 'eval_precision': 0.46993318485523383, 'eval_recall': 0.4811858608893957, 'eval_f1': 0.4754929577464789, 'eval_accuracy': 0.9472323013973597, 'eval_runtime': 3.0296, 'eval_samples_per_second': 505.355, 'eval_steps_per_second': 63.376, 'epoch': 11.0}
{'loss': 0.0055, 'learning_rate': 2.5e-05, 'epoch': 12.0}
{'eval_loss': 0.370883971452713, 'eval_precision': 0.4731182795698925, 'eval_recall': 0.45153933865450396, 'eval_f1': 0.46207701283547264, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 3.0194, 'eval_samples_per_second': 507.061, 'eval_steps_per_second': 63.59, 'epoch': 12.0}
{'loss': 0.0055, 'learning_rate': 2.2916666666666667e-05, 'epoch': 13.0}
{'eval_loss': 0.35839584469795227, 'eval_precision': 0.47478070175438597, 'eval_recall': 0.49372862029646525, 'eval_f1': 0.48406931246506435, 'eval_accuracy': 0.9493939627885432, 'eval_runtime': 3.0278, 'eval_samples_per_second': 505.655, 'eval_steps_per_second': 63.413, 'epoch': 13.0}
{'loss': 0.0045, 'learning_rate': 2.0833333333333336e-05, 'epoch': 14.0}
{'eval_loss': 0.36191073060035706, 'eval_precision': 0.47423764458464773, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.49343544857768046, 'eval_accuracy': 0.946190071798039, 'eval_runtime': 3.0364, 'eval_samples_per_second': 504.217, 'eval_steps_per_second': 63.233, 'epoch': 14.0}
{'loss': 0.0043, 'learning_rate': 1.8750000000000002e-05, 'epoch': 15.0}
{'eval_loss': 0.3745850622653961, 'eval_precision': 0.47530186608122943, 'eval_recall': 0.49372862029646525, 'eval_f1': 0.48434004474272935, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 3.0282, 'eval_samples_per_second': 505.576, 'eval_steps_per_second': 63.403, 'epoch': 15.0}
{'loss': 0.0037, 'learning_rate': 1.6666666666666667e-05, 'epoch': 16.0}
{'eval_loss': 0.38140735030174255, 'eval_precision': 0.4936562860438293, 'eval_recall': 0.4880273660205245, 'eval_f1': 0.4908256880733945, 'eval_accuracy': 0.9503975912915927, 'eval_runtime': 3.0229, 'eval_samples_per_second': 506.463, 'eval_steps_per_second': 63.515, 'epoch': 16.0}
{'loss': 0.0025, 'learning_rate': 1.4583333333333335e-05, 'epoch': 17.0}
{'eval_loss': 0.40191641449928284, 'eval_precision': 0.4657676348547718, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.48777838131450296, 'eval_accuracy': 0.9475025090712577, 'eval_runtime': 3.0272, 'eval_samples_per_second': 505.748, 'eval_steps_per_second': 63.425, 'epoch': 17.0}
{'loss': 0.0026, 'learning_rate': 1.25e-05, 'epoch': 18.0}
{'eval_loss': 0.4013923108577728, 'eval_precision': 0.4687168610816543, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.4857142857142857, 'eval_accuracy': 0.9486991430556628, 'eval_runtime': 3.2115, 'eval_samples_per_second': 476.728, 'eval_steps_per_second': 59.786, 'epoch': 18.0}
{'loss': 0.0025, 'learning_rate': 1.0416666666666668e-05, 'epoch': 19.0}
{'eval_loss': 0.4093936085700989, 'eval_precision': 0.4680628272251309, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.48799126637554574, 'eval_accuracy': 0.947888520033969, 'eval_runtime': 3.02, 'eval_samples_per_second': 506.951, 'eval_steps_per_second': 63.576, 'epoch': 19.0}
{'loss': 0.0025, 'learning_rate': 8.333333333333334e-06, 'epoch': 20.0}
{'eval_loss': 0.41393426060676575, 'eval_precision': 0.46455834242093785, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.47491638795986624, 'eval_accuracy': 0.9488535474407473, 'eval_runtime': 3.0404, 'eval_samples_per_second': 503.557, 'eval_steps_per_second': 63.15, 'epoch': 20.0}
{'loss': 0.0019, 'learning_rate': 6.25e-06, 'epoch': 21.0}
{'eval_loss': 0.41781502962112427, 'eval_precision': 0.46808510638297873, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.48431480462300497, 'eval_accuracy': 0.9479657222265112, 'eval_runtime': 3.033, 'eval_samples_per_second': 504.778, 'eval_steps_per_second': 63.303, 'epoch': 21.0}
{'loss': 0.0018, 'learning_rate': 4.166666666666667e-06, 'epoch': 22.0}
{'eval_loss': 0.41693446040153503, 'eval_precision': 0.49710312862108924, 'eval_recall': 0.48916761687571264, 'eval_f1': 0.4931034482758621, 'eval_accuracy': 0.9495483671736278, 'eval_runtime': 3.0265, 'eval_samples_per_second': 505.872, 'eval_steps_per_second': 63.441, 'epoch': 22.0}
{'loss': 0.002, 'learning_rate': 2.0833333333333334e-06, 'epoch': 23.0}
{'eval_loss': 0.41479796171188354, 'eval_precision': 0.49377123442808607, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.4954545454545454, 'eval_accuracy': 0.9491623562109164, 'eval_runtime': 3.3441, 'eval_samples_per_second': 457.815, 'eval_steps_per_second': 57.414, 'epoch': 23.0}
{'loss': 0.0014, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.4145759046077728, 'eval_precision': 0.4909706546275395, 'eval_recall': 0.4960091220068415, 'eval_f1': 0.49347702779353375, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 3.0234, 'eval_samples_per_second': 506.386, 'eval_steps_per_second': 63.505, 'epoch': 24.0}
{'train_runtime': 416.3985, 'train_samples_per_second': 497.639, 'train_steps_per_second': 7.781, 'train_loss': 0.03152722760942983, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0315
  train_runtime            = 0:06:56.39
  train_samples            =       8634
  train_samples_per_second =    497.639
  train_steps_per_second   =      7.781
[{'loss': 0.2635, 'learning_rate': 4.791666666666667e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.15661142766475677, 'eval_precision': 0.43498273878020716, 'eval_recall': 0.43101482326111745, 'eval_f1': 0.4329896907216495, 'eval_accuracy': 0.9465760827607504, 'eval_runtime': 3.0617, 'eval_samples_per_second': 500.053, 'eval_steps_per_second': 62.711, 'epoch': 1.0, 'step': 135}, {'loss': 0.1458, 'learning_rate': 4.5833333333333334e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.15406747162342072, 'eval_precision': 0.4414141414141414, 'eval_recall': 0.4982896237172178, 'eval_f1': 0.46813069094804505, 'eval_accuracy': 0.9460742685092257, 'eval_runtime': 3.0347, 'eval_samples_per_second': 504.5, 'eval_steps_per_second': 63.268, 'epoch': 2.0, 'step': 270}, {'loss': 0.1002, 'learning_rate': 4.375e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.16564904153347015, 'eval_precision': 0.4963768115942029, 'eval_recall': 0.46864310148232613, 'eval_f1': 0.48211143695014663, 'eval_accuracy': 0.9493939627885432, 'eval_runtime': 3.0272, 'eval_samples_per_second': 505.755, 'eval_steps_per_second': 63.426, 'epoch': 3.0, 'step': 405}, {'loss': 0.0664, 'learning_rate': 4.166666666666667e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.18780694901943207, 'eval_precision': 0.474090407938258, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.4820627802690583, 'eval_accuracy': 0.9468462904346483, 'eval_runtime': 3.0438, 'eval_samples_per_second': 502.996, 'eval_steps_per_second': 63.08, 'epoch': 4.0, 'step': 540}, {'loss': 0.0448, 'learning_rate': 3.958333333333333e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.22787916660308838, 'eval_precision': 0.4443359375, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.4786954234613362, 'eval_accuracy': 0.9436810005404154, 'eval_runtime': 3.0292, 'eval_samples_per_second': 505.407, 'eval_steps_per_second': 63.382, 'epoch': 5.0, 'step': 675}, {'loss': 0.0295, 'learning_rate': 3.7500000000000003e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.27116820216178894, 'eval_precision': 0.43357363542739447, 'eval_recall': 0.48004561003420754, 'eval_f1': 0.45562770562770566, 'eval_accuracy': 0.9458040608353278, 'eval_runtime': 3.025, 'eval_samples_per_second': 506.124, 'eval_steps_per_second': 63.472, 'epoch': 6.0, 'step': 810}, {'loss': 0.0215, 'learning_rate': 3.541666666666667e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.28309378027915955, 'eval_precision': 0.430622009569378, 'eval_recall': 0.5131128848346637, 'eval_f1': 0.46826222684703434, 'eval_accuracy': 0.9443372191770246, 'eval_runtime': 3.0229, 'eval_samples_per_second': 506.461, 'eval_steps_per_second': 63.514, 'epoch': 7.0, 'step': 945}, {'loss': 0.016, 'learning_rate': 3.3333333333333335e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.29894688725471497, 'eval_precision': 0.46595744680851064, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.4821133736929004, 'eval_accuracy': 0.9470778970122752, 'eval_runtime': 3.0326, 'eval_samples_per_second': 504.843, 'eval_steps_per_second': 63.311, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0129, 'learning_rate': 3.125e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.30726492404937744, 'eval_precision': 0.46440677966101696, 'eval_recall': 0.46864310148232613, 'eval_f1': 0.46651532349602726, 'eval_accuracy': 0.9479271211302401, 'eval_runtime': 3.0212, 'eval_samples_per_second': 506.759, 'eval_steps_per_second': 63.552, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0086, 'learning_rate': 2.916666666666667e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.3505348563194275, 'eval_precision': 0.4329501915708812, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.4705882352941176, 'eval_accuracy': 0.9441828147919401, 'eval_runtime': 3.099, 'eval_samples_per_second': 494.023, 'eval_steps_per_second': 61.955, 'epoch': 10.0, 'step': 1350}, {'loss': 0.0069, 'learning_rate': 2.7083333333333332e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.3656032979488373, 'eval_precision': 0.46993318485523383, 'eval_recall': 0.4811858608893957, 'eval_f1': 0.4754929577464789, 'eval_accuracy': 0.9472323013973597, 'eval_runtime': 3.0296, 'eval_samples_per_second': 505.355, 'eval_steps_per_second': 63.376, 'epoch': 11.0, 'step': 1485}, {'loss': 0.0055, 'learning_rate': 2.5e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.370883971452713, 'eval_precision': 0.4731182795698925, 'eval_recall': 0.45153933865450396, 'eval_f1': 0.46207701283547264, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 3.0194, 'eval_samples_per_second': 507.061, 'eval_steps_per_second': 63.59, 'epoch': 12.0, 'step': 1620}, {'loss': 0.0055, 'learning_rate': 2.2916666666666667e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.35839584469795227, 'eval_precision': 0.47478070175438597, 'eval_recall': 0.49372862029646525, 'eval_f1': 0.48406931246506435, 'eval_accuracy': 0.9493939627885432, 'eval_runtime': 3.0278, 'eval_samples_per_second': 505.655, 'eval_steps_per_second': 63.413, 'epoch': 13.0, 'step': 1755}, {'loss': 0.0045, 'learning_rate': 2.0833333333333336e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.36191073060035706, 'eval_precision': 0.47423764458464773, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.49343544857768046, 'eval_accuracy': 0.946190071798039, 'eval_runtime': 3.0364, 'eval_samples_per_second': 504.217, 'eval_steps_per_second': 63.233, 'epoch': 14.0, 'step': 1890}, {'loss': 0.0043, 'learning_rate': 1.8750000000000002e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.3745850622653961, 'eval_precision': 0.47530186608122943, 'eval_recall': 0.49372862029646525, 'eval_f1': 0.48434004474272935, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 3.0282, 'eval_samples_per_second': 505.576, 'eval_steps_per_second': 63.403, 'epoch': 15.0, 'step': 2025}, {'loss': 0.0037, 'learning_rate': 1.6666666666666667e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.38140735030174255, 'eval_precision': 0.4936562860438293, 'eval_recall': 0.4880273660205245, 'eval_f1': 0.4908256880733945, 'eval_accuracy': 0.9503975912915927, 'eval_runtime': 3.0229, 'eval_samples_per_second': 506.463, 'eval_steps_per_second': 63.515, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0025, 'learning_rate': 1.4583333333333335e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.40191641449928284, 'eval_precision': 0.4657676348547718, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.48777838131450296, 'eval_accuracy': 0.9475025090712577, 'eval_runtime': 3.0272, 'eval_samples_per_second': 505.748, 'eval_steps_per_second': 63.425, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0026, 'learning_rate': 1.25e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.4013923108577728, 'eval_precision': 0.4687168610816543, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.4857142857142857, 'eval_accuracy': 0.9486991430556628, 'eval_runtime': 3.2115, 'eval_samples_per_second': 476.728, 'eval_steps_per_second': 59.786, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0025, 'learning_rate': 1.0416666666666668e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.4093936085700989, 'eval_precision': 0.4680628272251309, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.48799126637554574, 'eval_accuracy': 0.947888520033969, 'eval_runtime': 3.02, 'eval_samples_per_second': 506.951, 'eval_steps_per_second': 63.576, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0025, 'learning_rate': 8.333333333333334e-06, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.41393426060676575, 'eval_precision': 0.46455834242093785, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.47491638795986624, 'eval_accuracy': 0.9488535474407473, 'eval_runtime': 3.0404, 'eval_samples_per_second': 503.557, 'eval_steps_per_second': 63.15, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0019, 'learning_rate': 6.25e-06, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.41781502962112427, 'eval_precision': 0.46808510638297873, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.48431480462300497, 'eval_accuracy': 0.9479657222265112, 'eval_runtime': 3.033, 'eval_samples_per_second': 504.778, 'eval_steps_per_second': 63.303, 'epoch': 21.0, 'step': 2835}, {'loss': 0.0018, 'learning_rate': 4.166666666666667e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.41693446040153503, 'eval_precision': 0.49710312862108924, 'eval_recall': 0.48916761687571264, 'eval_f1': 0.4931034482758621, 'eval_accuracy': 0.9495483671736278, 'eval_runtime': 3.0265, 'eval_samples_per_second': 505.872, 'eval_steps_per_second': 63.441, 'epoch': 22.0, 'step': 2970}, {'loss': 0.002, 'learning_rate': 2.0833333333333334e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.41479796171188354, 'eval_precision': 0.49377123442808607, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.4954545454545454, 'eval_accuracy': 0.9491623562109164, 'eval_runtime': 3.3441, 'eval_samples_per_second': 457.815, 'eval_steps_per_second': 57.414, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0014, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.4145759046077728, 'eval_precision': 0.4909706546275395, 'eval_recall': 0.4960091220068415, 'eval_f1': 0.49347702779353375, 'eval_accuracy': 0.9491237551146453, 'eval_runtime': 3.0234, 'eval_samples_per_second': 506.386, 'eval_steps_per_second': 63.505, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 416.3985, 'train_samples_per_second': 497.639, 'train_steps_per_second': 7.781, 'total_flos': 1912879488074940.0, 'train_loss': 0.03152722760942983, 'epoch': 24.0, 'step': 3240}]

Evaluation, ltg/norbert3-small
***** predict metrics *****
  predict_accuracy           =     0.9478
  predict_f1                 =     0.4634
  predict_loss               =      0.155
  predict_precision          =     0.4454
  predict_recall             =      0.483
  predict_runtime            = 0:00:02.51
  predict_samples_per_second =    505.164
  predict_steps_per_second   =     63.146
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_small_21.json completed. F1: 0.46344647519582244
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_19.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at NbAiLab/nb-bert-large and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_19.json
01170939_tsa-bin_NB-BERT_large Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6906.18 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 7287.17 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 7015.15 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 7022.70 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 7072.88 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7157.98 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6318.61 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6631.87 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6836.05 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7416.51 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 7034.54 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7092.28 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6899.57 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
01170939_tsa-bin_NB-BERT_large Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.1987, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0}
{'eval_loss': 0.1425895392894745, 'eval_precision': 0.6120689655172413, 'eval_recall': 0.4047890535917902, 'eval_f1': 0.48730267673301303, 'eval_accuracy': 0.9530224658380299, 'eval_runtime': 4.6815, 'eval_samples_per_second': 327.029, 'eval_steps_per_second': 41.012, 'epoch': 1.0}
{'loss': 0.1168, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0}
{'eval_loss': 0.15767648816108704, 'eval_precision': 0.575107296137339, 'eval_recall': 0.4583808437856328, 'eval_f1': 0.5101522842639594, 'eval_accuracy': 0.9544893074963329, 'eval_runtime': 4.6704, 'eval_samples_per_second': 327.806, 'eval_steps_per_second': 41.11, 'epoch': 2.0}
{'loss': 0.069, 'learning_rate': 8.75e-05, 'epoch': 3.0}
{'eval_loss': 0.1707809567451477, 'eval_precision': 0.4445479962721342, 'eval_recall': 0.5438996579247435, 'eval_f1': 0.4892307692307693, 'eval_accuracy': 0.9468462904346483, 'eval_runtime': 4.6682, 'eval_samples_per_second': 327.967, 'eval_steps_per_second': 41.13, 'epoch': 3.0}
{'loss': 0.0414, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0}
{'eval_loss': 0.2120116502046585, 'eval_precision': 0.464321608040201, 'eval_recall': 0.5267958950969214, 'eval_f1': 0.49358974358974356, 'eval_accuracy': 0.9475797112637999, 'eval_runtime': 4.6725, 'eval_samples_per_second': 327.662, 'eval_steps_per_second': 41.091, 'epoch': 4.0}
{'loss': 0.0233, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0}
{'eval_loss': 0.23466676473617554, 'eval_precision': 0.4555984555984556, 'eval_recall': 0.5381984036488028, 'eval_f1': 0.49346576058546787, 'eval_accuracy': 0.9458426619315988, 'eval_runtime': 4.6639, 'eval_samples_per_second': 328.267, 'eval_steps_per_second': 41.167, 'epoch': 5.0}
{'loss': 0.0175, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.2700945734977722, 'eval_precision': 0.5659630606860159, 'eval_recall': 0.48916761687571264, 'eval_f1': 0.5247706422018348, 'eval_accuracy': 0.9534084768007411, 'eval_runtime': 4.6672, 'eval_samples_per_second': 328.034, 'eval_steps_per_second': 41.138, 'epoch': 6.0}
{'loss': 0.0111, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0}
{'eval_loss': 0.29094284772872925, 'eval_precision': 0.5113513513513513, 'eval_recall': 0.5393386545039909, 'eval_f1': 0.5249722530521642, 'eval_accuracy': 0.9507450011580328, 'eval_runtime': 4.6708, 'eval_samples_per_second': 327.78, 'eval_steps_per_second': 41.106, 'epoch': 7.0}
{'loss': 0.008, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0}
{'eval_loss': 0.29843562841415405, 'eval_precision': 0.5431472081218274, 'eval_recall': 0.4880273660205245, 'eval_f1': 0.5141141141141141, 'eval_accuracy': 0.9521346406237937, 'eval_runtime': 4.6707, 'eval_samples_per_second': 327.791, 'eval_steps_per_second': 41.108, 'epoch': 8.0}
{'loss': 0.0069, 'learning_rate': 6.25e-05, 'epoch': 9.0}
{'eval_loss': 0.26365581154823303, 'eval_precision': 0.49019607843137253, 'eval_recall': 0.5416191562143672, 'eval_f1': 0.514626218851571, 'eval_accuracy': 0.94962556936617, 'eval_runtime': 4.6723, 'eval_samples_per_second': 327.678, 'eval_steps_per_second': 41.094, 'epoch': 9.0}
{'loss': 0.0051, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0}
{'eval_loss': 0.2842327952384949, 'eval_precision': 0.5005202913631633, 'eval_recall': 0.548460661345496, 'eval_f1': 0.5233949945593035, 'eval_accuracy': 0.9512468154095576, 'eval_runtime': 4.6742, 'eval_samples_per_second': 327.544, 'eval_steps_per_second': 41.077, 'epoch': 10.0}
{'loss': 0.0054, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0}
{'eval_loss': 0.3135131299495697, 'eval_precision': 0.5190582959641256, 'eval_recall': 0.5279361459521095, 'eval_f1': 0.5234595816845676, 'eval_accuracy': 0.9511696132170153, 'eval_runtime': 4.6684, 'eval_samples_per_second': 327.953, 'eval_steps_per_second': 41.128, 'epoch': 11.0}
{'loss': 0.0031, 'learning_rate': 5e-05, 'epoch': 12.0}
{'eval_loss': 0.3270082473754883, 'eval_precision': 0.5130434782608696, 'eval_recall': 0.5381984036488028, 'eval_f1': 0.5253199777406788, 'eval_accuracy': 0.9500501814251525, 'eval_runtime': 4.6754, 'eval_samples_per_second': 327.456, 'eval_steps_per_second': 41.066, 'epoch': 12.0}
{'loss': 0.0026, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0}
{'eval_loss': 0.347918838262558, 'eval_precision': 0.5450121654501217, 'eval_recall': 0.5108323831242874, 'eval_f1': 0.5273690406121249, 'eval_accuracy': 0.9524820504902339, 'eval_runtime': 4.8092, 'eval_samples_per_second': 318.35, 'eval_steps_per_second': 39.924, 'epoch': 13.0}
{'loss': 0.0017, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0}
{'eval_loss': 0.34851983189582825, 'eval_precision': 0.5158730158730159, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5173393973848778, 'eval_accuracy': 0.9509380066393885, 'eval_runtime': 4.6758, 'eval_samples_per_second': 327.428, 'eval_steps_per_second': 41.062, 'epoch': 14.0}
{'loss': 0.0018, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0}
{'eval_loss': 0.3407461643218994, 'eval_precision': 0.5624227441285538, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5397390272835113, 'eval_accuracy': 0.9535628811858257, 'eval_runtime': 4.6733, 'eval_samples_per_second': 327.607, 'eval_steps_per_second': 41.085, 'epoch': 15.0}
{'loss': 0.0013, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0}
{'eval_loss': 0.34031879901885986, 'eval_precision': 0.538083538083538, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.5180366646954464, 'eval_accuracy': 0.9509380066393885, 'eval_runtime': 4.6711, 'eval_samples_per_second': 327.762, 'eval_steps_per_second': 41.104, 'epoch': 16.0}
{'loss': 0.0012, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0}
{'eval_loss': 0.3405272960662842, 'eval_precision': 0.518640350877193, 'eval_recall': 0.5393386545039909, 'eval_f1': 0.528787031861375, 'eval_accuracy': 0.9517100285648112, 'eval_runtime': 4.6729, 'eval_samples_per_second': 327.631, 'eval_steps_per_second': 41.088, 'epoch': 17.0}
{'loss': 0.0005, 'learning_rate': 2.5e-05, 'epoch': 18.0}
{'eval_loss': 0.3752845227718353, 'eval_precision': 0.5615763546798029, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5399644760213145, 'eval_accuracy': 0.9530996680305721, 'eval_runtime': 4.6708, 'eval_samples_per_second': 327.781, 'eval_steps_per_second': 41.106, 'epoch': 18.0}
{'loss': 0.0007, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0}
{'eval_loss': 0.38265758752822876, 'eval_precision': 0.5465253239104829, 'eval_recall': 0.5290763968072976, 'eval_f1': 0.5376593279258401, 'eval_accuracy': 0.9530996680305721, 'eval_runtime': 4.6834, 'eval_samples_per_second': 326.898, 'eval_steps_per_second': 40.996, 'epoch': 19.0}
{'loss': 0.001, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0}
{'eval_loss': 0.3519165515899658, 'eval_precision': 0.5271493212669683, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.5292447473026689, 'eval_accuracy': 0.9526364548753185, 'eval_runtime': 4.68, 'eval_samples_per_second': 327.139, 'eval_steps_per_second': 41.026, 'epoch': 20.0}
{'loss': 0.0007, 'learning_rate': 1.25e-05, 'epoch': 21.0}
{'eval_loss': 0.3628290891647339, 'eval_precision': 0.5566502463054187, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.5352279455298994, 'eval_accuracy': 0.9540646954373504, 'eval_runtime': 4.8149, 'eval_samples_per_second': 317.97, 'eval_steps_per_second': 39.876, 'epoch': 21.0}
{'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0}
{'eval_loss': 0.3643459975719452, 'eval_precision': 0.548926014319809, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5364431486880467, 'eval_accuracy': 0.9541418976298927, 'eval_runtime': 4.6752, 'eval_samples_per_second': 327.471, 'eval_steps_per_second': 41.068, 'epoch': 22.0}
{'loss': 0.0003, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0}
{'eval_loss': 0.3645574748516083, 'eval_precision': 0.5385514018691588, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5320253894979804, 'eval_accuracy': 0.9534084768007411, 'eval_runtime': 4.6791, 'eval_samples_per_second': 327.202, 'eval_steps_per_second': 41.034, 'epoch': 23.0}
{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.368018239736557, 'eval_precision': 0.5425531914893617, 'eval_recall': 0.5233751425313569, 'eval_f1': 0.5327916424840393, 'eval_accuracy': 0.9537172855709102, 'eval_runtime': 4.6747, 'eval_samples_per_second': 327.505, 'eval_steps_per_second': 41.072, 'epoch': 24.0}
{'train_runtime': 2133.225, 'train_samples_per_second': 97.137, 'train_steps_per_second': 2.43, 'train_loss': 0.02160135250147662, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0216
  train_runtime            = 0:35:33.22
  train_samples            =       8634
  train_samples_per_second =     97.137
  train_steps_per_second   =       2.43
[{'loss': 0.1987, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.1425895392894745, 'eval_precision': 0.6120689655172413, 'eval_recall': 0.4047890535917902, 'eval_f1': 0.48730267673301303, 'eval_accuracy': 0.9530224658380299, 'eval_runtime': 4.6815, 'eval_samples_per_second': 327.029, 'eval_steps_per_second': 41.012, 'epoch': 1.0, 'step': 216}, {'loss': 0.1168, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0, 'step': 432}, {'eval_loss': 0.15767648816108704, 'eval_precision': 0.575107296137339, 'eval_recall': 0.4583808437856328, 'eval_f1': 0.5101522842639594, 'eval_accuracy': 0.9544893074963329, 'eval_runtime': 4.6704, 'eval_samples_per_second': 327.806, 'eval_steps_per_second': 41.11, 'epoch': 2.0, 'step': 432}, {'loss': 0.069, 'learning_rate': 8.75e-05, 'epoch': 3.0, 'step': 648}, {'eval_loss': 0.1707809567451477, 'eval_precision': 0.4445479962721342, 'eval_recall': 0.5438996579247435, 'eval_f1': 0.4892307692307693, 'eval_accuracy': 0.9468462904346483, 'eval_runtime': 4.6682, 'eval_samples_per_second': 327.967, 'eval_steps_per_second': 41.13, 'epoch': 3.0, 'step': 648}, {'loss': 0.0414, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0, 'step': 864}, {'eval_loss': 0.2120116502046585, 'eval_precision': 0.464321608040201, 'eval_recall': 0.5267958950969214, 'eval_f1': 0.49358974358974356, 'eval_accuracy': 0.9475797112637999, 'eval_runtime': 4.6725, 'eval_samples_per_second': 327.662, 'eval_steps_per_second': 41.091, 'epoch': 4.0, 'step': 864}, {'loss': 0.0233, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0, 'step': 1080}, {'eval_loss': 0.23466676473617554, 'eval_precision': 0.4555984555984556, 'eval_recall': 0.5381984036488028, 'eval_f1': 0.49346576058546787, 'eval_accuracy': 0.9458426619315988, 'eval_runtime': 4.6639, 'eval_samples_per_second': 328.267, 'eval_steps_per_second': 41.167, 'epoch': 5.0, 'step': 1080}, {'loss': 0.0175, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0, 'step': 1296}, {'eval_loss': 0.2700945734977722, 'eval_precision': 0.5659630606860159, 'eval_recall': 0.48916761687571264, 'eval_f1': 0.5247706422018348, 'eval_accuracy': 0.9534084768007411, 'eval_runtime': 4.6672, 'eval_samples_per_second': 328.034, 'eval_steps_per_second': 41.138, 'epoch': 6.0, 'step': 1296}, {'loss': 0.0111, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0, 'step': 1512}, {'eval_loss': 0.29094284772872925, 'eval_precision': 0.5113513513513513, 'eval_recall': 0.5393386545039909, 'eval_f1': 0.5249722530521642, 'eval_accuracy': 0.9507450011580328, 'eval_runtime': 4.6708, 'eval_samples_per_second': 327.78, 'eval_steps_per_second': 41.106, 'epoch': 7.0, 'step': 1512}, {'loss': 0.008, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0, 'step': 1728}, {'eval_loss': 0.29843562841415405, 'eval_precision': 0.5431472081218274, 'eval_recall': 0.4880273660205245, 'eval_f1': 0.5141141141141141, 'eval_accuracy': 0.9521346406237937, 'eval_runtime': 4.6707, 'eval_samples_per_second': 327.791, 'eval_steps_per_second': 41.108, 'epoch': 8.0, 'step': 1728}, {'loss': 0.0069, 'learning_rate': 6.25e-05, 'epoch': 9.0, 'step': 1944}, {'eval_loss': 0.26365581154823303, 'eval_precision': 0.49019607843137253, 'eval_recall': 0.5416191562143672, 'eval_f1': 0.514626218851571, 'eval_accuracy': 0.94962556936617, 'eval_runtime': 4.6723, 'eval_samples_per_second': 327.678, 'eval_steps_per_second': 41.094, 'epoch': 9.0, 'step': 1944}, {'loss': 0.0051, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0, 'step': 2160}, {'eval_loss': 0.2842327952384949, 'eval_precision': 0.5005202913631633, 'eval_recall': 0.548460661345496, 'eval_f1': 0.5233949945593035, 'eval_accuracy': 0.9512468154095576, 'eval_runtime': 4.6742, 'eval_samples_per_second': 327.544, 'eval_steps_per_second': 41.077, 'epoch': 10.0, 'step': 2160}, {'loss': 0.0054, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0, 'step': 2376}, {'eval_loss': 0.3135131299495697, 'eval_precision': 0.5190582959641256, 'eval_recall': 0.5279361459521095, 'eval_f1': 0.5234595816845676, 'eval_accuracy': 0.9511696132170153, 'eval_runtime': 4.6684, 'eval_samples_per_second': 327.953, 'eval_steps_per_second': 41.128, 'epoch': 11.0, 'step': 2376}, {'loss': 0.0031, 'learning_rate': 5e-05, 'epoch': 12.0, 'step': 2592}, {'eval_loss': 0.3270082473754883, 'eval_precision': 0.5130434782608696, 'eval_recall': 0.5381984036488028, 'eval_f1': 0.5253199777406788, 'eval_accuracy': 0.9500501814251525, 'eval_runtime': 4.6754, 'eval_samples_per_second': 327.456, 'eval_steps_per_second': 41.066, 'epoch': 12.0, 'step': 2592}, {'loss': 0.0026, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0, 'step': 2808}, {'eval_loss': 0.347918838262558, 'eval_precision': 0.5450121654501217, 'eval_recall': 0.5108323831242874, 'eval_f1': 0.5273690406121249, 'eval_accuracy': 0.9524820504902339, 'eval_runtime': 4.8092, 'eval_samples_per_second': 318.35, 'eval_steps_per_second': 39.924, 'epoch': 13.0, 'step': 2808}, {'loss': 0.0017, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0, 'step': 3024}, {'eval_loss': 0.34851983189582825, 'eval_precision': 0.5158730158730159, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5173393973848778, 'eval_accuracy': 0.9509380066393885, 'eval_runtime': 4.6758, 'eval_samples_per_second': 327.428, 'eval_steps_per_second': 41.062, 'epoch': 14.0, 'step': 3024}, {'loss': 0.0018, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0, 'step': 3240}, {'eval_loss': 0.3407461643218994, 'eval_precision': 0.5624227441285538, 'eval_recall': 0.5188141391106044, 'eval_f1': 0.5397390272835113, 'eval_accuracy': 0.9535628811858257, 'eval_runtime': 4.6733, 'eval_samples_per_second': 327.607, 'eval_steps_per_second': 41.085, 'epoch': 15.0, 'step': 3240}, {'loss': 0.0013, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0, 'step': 3456}, {'eval_loss': 0.34031879901885986, 'eval_precision': 0.538083538083538, 'eval_recall': 0.49942987457240595, 'eval_f1': 0.5180366646954464, 'eval_accuracy': 0.9509380066393885, 'eval_runtime': 4.6711, 'eval_samples_per_second': 327.762, 'eval_steps_per_second': 41.104, 'epoch': 16.0, 'step': 3456}, {'loss': 0.0012, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0, 'step': 3672}, {'eval_loss': 0.3405272960662842, 'eval_precision': 0.518640350877193, 'eval_recall': 0.5393386545039909, 'eval_f1': 0.528787031861375, 'eval_accuracy': 0.9517100285648112, 'eval_runtime': 4.6729, 'eval_samples_per_second': 327.631, 'eval_steps_per_second': 41.088, 'epoch': 17.0, 'step': 3672}, {'loss': 0.0005, 'learning_rate': 2.5e-05, 'epoch': 18.0, 'step': 3888}, {'eval_loss': 0.3752845227718353, 'eval_precision': 0.5615763546798029, 'eval_recall': 0.5199543899657925, 'eval_f1': 0.5399644760213145, 'eval_accuracy': 0.9530996680305721, 'eval_runtime': 4.6708, 'eval_samples_per_second': 327.781, 'eval_steps_per_second': 41.106, 'epoch': 18.0, 'step': 3888}, {'loss': 0.0007, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0, 'step': 4104}, {'eval_loss': 0.38265758752822876, 'eval_precision': 0.5465253239104829, 'eval_recall': 0.5290763968072976, 'eval_f1': 0.5376593279258401, 'eval_accuracy': 0.9530996680305721, 'eval_runtime': 4.6834, 'eval_samples_per_second': 326.898, 'eval_steps_per_second': 40.996, 'epoch': 19.0, 'step': 4104}, {'loss': 0.001, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0, 'step': 4320}, {'eval_loss': 0.3519165515899658, 'eval_precision': 0.5271493212669683, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.5292447473026689, 'eval_accuracy': 0.9526364548753185, 'eval_runtime': 4.68, 'eval_samples_per_second': 327.139, 'eval_steps_per_second': 41.026, 'epoch': 20.0, 'step': 4320}, {'loss': 0.0007, 'learning_rate': 1.25e-05, 'epoch': 21.0, 'step': 4536}, {'eval_loss': 0.3628290891647339, 'eval_precision': 0.5566502463054187, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.5352279455298994, 'eval_accuracy': 0.9540646954373504, 'eval_runtime': 4.8149, 'eval_samples_per_second': 317.97, 'eval_steps_per_second': 39.876, 'epoch': 21.0, 'step': 4536}, {'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0, 'step': 4752}, {'eval_loss': 0.3643459975719452, 'eval_precision': 0.548926014319809, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.5364431486880467, 'eval_accuracy': 0.9541418976298927, 'eval_runtime': 4.6752, 'eval_samples_per_second': 327.471, 'eval_steps_per_second': 41.068, 'epoch': 22.0, 'step': 4752}, {'loss': 0.0003, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0, 'step': 4968}, {'eval_loss': 0.3645574748516083, 'eval_precision': 0.5385514018691588, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5320253894979804, 'eval_accuracy': 0.9534084768007411, 'eval_runtime': 4.6791, 'eval_samples_per_second': 327.202, 'eval_steps_per_second': 41.034, 'epoch': 23.0, 'step': 4968}, {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 5184}, {'eval_loss': 0.368018239736557, 'eval_precision': 0.5425531914893617, 'eval_recall': 0.5233751425313569, 'eval_f1': 0.5327916424840393, 'eval_accuracy': 0.9537172855709102, 'eval_runtime': 4.6747, 'eval_samples_per_second': 327.505, 'eval_steps_per_second': 41.072, 'epoch': 24.0, 'step': 5184}, {'train_runtime': 2133.225, 'train_samples_per_second': 97.137, 'train_steps_per_second': 2.43, 'total_flos': 2.388271956564535e+16, 'train_loss': 0.02160135250147662, 'epoch': 24.0, 'step': 5184}]

Evaluation, NbAiLab/nb-bert-large
***** predict metrics *****
  predict_accuracy           =     0.9501
  predict_f1                 =     0.4031
  predict_loss               =     0.1576
  predict_precision          =     0.5374
  predict_recall             =     0.3224
  predict_runtime            = 0:00:03.92
  predict_samples_per_second =    324.213
  predict_steps_per_second   =     40.527
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NB-BERT_large_19.json completed. F1: 0.4030612244897959
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_38.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at ltg/norbert2 and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_38.json
01170939_tsa-bin_NorBERT_2 Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 7062.47 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 7492.92 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 7244.93 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 7287.24 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 7320.25 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7426.73 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 6525.19 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6891.31 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 7075.74 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7741.07 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 7329.39 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7332.60 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 7140.04 examples/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
01170939_tsa-bin_NorBERT_2 Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.2163, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0}
{'eval_loss': 0.1527482122182846, 'eval_precision': 0.43037974683544306, 'eval_recall': 0.4264538198403649, 'eval_f1': 0.42840778923253153, 'eval_accuracy': 0.9464216783756658, 'eval_runtime': 2.2465, 'eval_samples_per_second': 681.497, 'eval_steps_per_second': 85.465, 'epoch': 1.0}
{'loss': 0.1097, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0}
{'eval_loss': 0.17951349914073944, 'eval_precision': 0.3797909407665505, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.4306172839506173, 'eval_accuracy': 0.9380066393885587, 'eval_runtime': 2.241, 'eval_samples_per_second': 683.187, 'eval_steps_per_second': 85.677, 'epoch': 2.0}
{'loss': 0.0524, 'learning_rate': 8.75e-05, 'epoch': 3.0}
{'eval_loss': 0.19987909495830536, 'eval_precision': 0.46445497630331756, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.4555490993608367, 'eval_accuracy': 0.946151470701768, 'eval_runtime': 2.2354, 'eval_samples_per_second': 684.894, 'eval_steps_per_second': 85.891, 'epoch': 3.0}
{'loss': 0.0281, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0}
{'eval_loss': 0.24287518858909607, 'eval_precision': 0.430635838150289, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.46684073107049606, 'eval_accuracy': 0.9424071643634679, 'eval_runtime': 2.2358, 'eval_samples_per_second': 684.78, 'eval_steps_per_second': 85.877, 'epoch': 4.0}
{'loss': 0.0162, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0}
{'eval_loss': 0.2759858965873718, 'eval_precision': 0.4319526627218935, 'eval_recall': 0.4161915621436716, 'eval_f1': 0.4239256678281068, 'eval_accuracy': 0.9452250443912608, 'eval_runtime': 2.2412, 'eval_samples_per_second': 683.112, 'eval_steps_per_second': 85.668, 'epoch': 5.0}
{'loss': 0.0125, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.29703664779663086, 'eval_precision': 0.4096958174904943, 'eval_recall': 0.49144811858608894, 'eval_f1': 0.44686365992742355, 'eval_accuracy': 0.9382768470624566, 'eval_runtime': 2.2463, 'eval_samples_per_second': 681.57, 'eval_steps_per_second': 85.474, 'epoch': 6.0}
{'loss': 0.0071, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0}
{'eval_loss': 0.33497098088264465, 'eval_precision': 0.4664351851851852, 'eval_recall': 0.45952109464082097, 'eval_f1': 0.462952326249282, 'eval_accuracy': 0.9450320389099051, 'eval_runtime': 2.3164, 'eval_samples_per_second': 660.931, 'eval_steps_per_second': 82.886, 'epoch': 7.0}
{'loss': 0.0057, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0}
{'eval_loss': 0.35791829228401184, 'eval_precision': 0.42400881057268724, 'eval_recall': 0.43899657924743446, 'eval_f1': 0.4313725490196078, 'eval_accuracy': 0.9426387709410947, 'eval_runtime': 2.2452, 'eval_samples_per_second': 681.892, 'eval_steps_per_second': 85.515, 'epoch': 8.0}
{'loss': 0.0056, 'learning_rate': 6.25e-05, 'epoch': 9.0}
{'eval_loss': 0.3530077338218689, 'eval_precision': 0.40150801131008484, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.43962848297213625, 'eval_accuracy': 0.9385084536400834, 'eval_runtime': 2.2456, 'eval_samples_per_second': 681.781, 'eval_steps_per_second': 85.501, 'epoch': 9.0}
{'loss': 0.0031, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0}
{'eval_loss': 0.34314683079719543, 'eval_precision': 0.44885679903730447, 'eval_recall': 0.42531356898517675, 'eval_f1': 0.43676814988290397, 'eval_accuracy': 0.9450320389099051, 'eval_runtime': 2.239, 'eval_samples_per_second': 683.797, 'eval_steps_per_second': 85.754, 'epoch': 10.0}
{'loss': 0.0031, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0}
{'eval_loss': 0.3476279079914093, 'eval_precision': 0.4161616161616162, 'eval_recall': 0.4697833523375142, 'eval_f1': 0.4413497589716122, 'eval_accuracy': 0.9413263336678762, 'eval_runtime': 2.2432, 'eval_samples_per_second': 682.496, 'eval_steps_per_second': 85.591, 'epoch': 11.0}
{'loss': 0.0018, 'learning_rate': 5e-05, 'epoch': 12.0}
{'eval_loss': 0.39815443754196167, 'eval_precision': 0.43522727272727274, 'eval_recall': 0.43671607753705816, 'eval_f1': 0.4359704040978941, 'eval_accuracy': 0.9432177873851617, 'eval_runtime': 2.2434, 'eval_samples_per_second': 682.447, 'eval_steps_per_second': 85.584, 'epoch': 12.0}
{'loss': 0.0017, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0}
{'eval_loss': 0.3913600444793701, 'eval_precision': 0.4441860465116279, 'eval_recall': 0.43557582668187, 'eval_f1': 0.439838802533103, 'eval_accuracy': 0.9444530224658381, 'eval_runtime': 2.24, 'eval_samples_per_second': 683.49, 'eval_steps_per_second': 85.715, 'epoch': 13.0}
{'loss': 0.001, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0}
{'eval_loss': 0.4182136058807373, 'eval_precision': 0.43922369765066394, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.4633620689655172, 'eval_accuracy': 0.9417509457268587, 'eval_runtime': 2.2404, 'eval_samples_per_second': 683.375, 'eval_steps_per_second': 85.701, 'epoch': 14.0}
{'loss': 0.0008, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0}
{'eval_loss': 0.4051904082298279, 'eval_precision': 0.45045045045045046, 'eval_recall': 0.45610034207525657, 'eval_f1': 0.45325779036827196, 'eval_accuracy': 0.9439512082143133, 'eval_runtime': 2.2451, 'eval_samples_per_second': 681.935, 'eval_steps_per_second': 85.52, 'epoch': 15.0}
{'loss': 0.001, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0}
{'eval_loss': 0.4056544005870819, 'eval_precision': 0.4304568527918782, 'eval_recall': 0.48346636259977194, 'eval_f1': 0.4554242749731472, 'eval_accuracy': 0.9439898093105844, 'eval_runtime': 2.2444, 'eval_samples_per_second': 682.152, 'eval_steps_per_second': 85.547, 'epoch': 16.0}
{'loss': 0.0008, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0}
{'eval_loss': 0.4050329625606537, 'eval_precision': 0.44803229061553984, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.4753747323340471, 'eval_accuracy': 0.9436037983478731, 'eval_runtime': 2.2423, 'eval_samples_per_second': 682.796, 'eval_steps_per_second': 85.628, 'epoch': 17.0}
{'loss': 0.0004, 'learning_rate': 2.5e-05, 'epoch': 18.0}
{'eval_loss': 0.414998322725296, 'eval_precision': 0.47794117647058826, 'eval_recall': 0.44469783352337516, 'eval_f1': 0.4607206142941524, 'eval_accuracy': 0.9473481046861731, 'eval_runtime': 2.2473, 'eval_samples_per_second': 681.255, 'eval_steps_per_second': 85.435, 'epoch': 18.0}
{'loss': 0.0003, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0}
{'eval_loss': 0.42128026485443115, 'eval_precision': 0.4610917537746806, 'eval_recall': 0.4526795895096921, 'eval_f1': 0.4568469505178366, 'eval_accuracy': 0.9466918860495638, 'eval_runtime': 2.2436, 'eval_samples_per_second': 682.382, 'eval_steps_per_second': 85.576, 'epoch': 19.0}
{'loss': 0.0003, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0}
{'eval_loss': 0.42703232169151306, 'eval_precision': 0.46153846153846156, 'eval_recall': 0.47206385404789053, 'eval_f1': 0.46674182638105977, 'eval_accuracy': 0.9461128696054968, 'eval_runtime': 2.2407, 'eval_samples_per_second': 683.267, 'eval_steps_per_second': 85.687, 'epoch': 20.0}
{'loss': 0.0002, 'learning_rate': 1.25e-05, 'epoch': 21.0}
{'eval_loss': 0.43351900577545166, 'eval_precision': 0.45513513513513515, 'eval_recall': 0.48004561003420754, 'eval_f1': 0.4672586015538291, 'eval_accuracy': 0.945611055353972, 'eval_runtime': 2.2378, 'eval_samples_per_second': 684.145, 'eval_steps_per_second': 85.797, 'epoch': 21.0}
{'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0}
{'eval_loss': 0.4418164789676666, 'eval_precision': 0.47038327526132406, 'eval_recall': 0.4618015963511973, 'eval_f1': 0.4660529344073648, 'eval_accuracy': 0.9466146838570215, 'eval_runtime': 2.2466, 'eval_samples_per_second': 681.482, 'eval_steps_per_second': 85.463, 'epoch': 22.0}
{'loss': 0.0001, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0}
{'eval_loss': 0.4424847960472107, 'eval_precision': 0.4787234042553192, 'eval_recall': 0.4618015963511973, 'eval_f1': 0.4701102727800348, 'eval_accuracy': 0.947039295916004, 'eval_runtime': 2.2466, 'eval_samples_per_second': 681.469, 'eval_steps_per_second': 85.462, 'epoch': 23.0}
{'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.44190743565559387, 'eval_precision': 0.47374562427071176, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4682814302191465, 'eval_accuracy': 0.9468076893383772, 'eval_runtime': 2.434, 'eval_samples_per_second': 628.999, 'eval_steps_per_second': 78.882, 'epoch': 24.0}
{'train_runtime': 725.8451, 'train_samples_per_second': 285.482, 'train_steps_per_second': 4.464, 'train_loss': 0.01953077647651051, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0195
  train_runtime            = 0:12:05.84
  train_samples            =       8634
  train_samples_per_second =    285.482
  train_steps_per_second   =      4.464
[{'loss': 0.2163, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0, 'step': 135}, {'eval_loss': 0.1527482122182846, 'eval_precision': 0.43037974683544306, 'eval_recall': 0.4264538198403649, 'eval_f1': 0.42840778923253153, 'eval_accuracy': 0.9464216783756658, 'eval_runtime': 2.2465, 'eval_samples_per_second': 681.497, 'eval_steps_per_second': 85.465, 'epoch': 1.0, 'step': 135}, {'loss': 0.1097, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0, 'step': 270}, {'eval_loss': 0.17951349914073944, 'eval_precision': 0.3797909407665505, 'eval_recall': 0.49714937286202965, 'eval_f1': 0.4306172839506173, 'eval_accuracy': 0.9380066393885587, 'eval_runtime': 2.241, 'eval_samples_per_second': 683.187, 'eval_steps_per_second': 85.677, 'epoch': 2.0, 'step': 270}, {'loss': 0.0524, 'learning_rate': 8.75e-05, 'epoch': 3.0, 'step': 405}, {'eval_loss': 0.19987909495830536, 'eval_precision': 0.46445497630331756, 'eval_recall': 0.4469783352337514, 'eval_f1': 0.4555490993608367, 'eval_accuracy': 0.946151470701768, 'eval_runtime': 2.2354, 'eval_samples_per_second': 684.894, 'eval_steps_per_second': 85.891, 'epoch': 3.0, 'step': 405}, {'loss': 0.0281, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0, 'step': 540}, {'eval_loss': 0.24287518858909607, 'eval_precision': 0.430635838150289, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.46684073107049606, 'eval_accuracy': 0.9424071643634679, 'eval_runtime': 2.2358, 'eval_samples_per_second': 684.78, 'eval_steps_per_second': 85.877, 'epoch': 4.0, 'step': 540}, {'loss': 0.0162, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0, 'step': 675}, {'eval_loss': 0.2759858965873718, 'eval_precision': 0.4319526627218935, 'eval_recall': 0.4161915621436716, 'eval_f1': 0.4239256678281068, 'eval_accuracy': 0.9452250443912608, 'eval_runtime': 2.2412, 'eval_samples_per_second': 683.112, 'eval_steps_per_second': 85.668, 'epoch': 5.0, 'step': 675}, {'loss': 0.0125, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0, 'step': 810}, {'eval_loss': 0.29703664779663086, 'eval_precision': 0.4096958174904943, 'eval_recall': 0.49144811858608894, 'eval_f1': 0.44686365992742355, 'eval_accuracy': 0.9382768470624566, 'eval_runtime': 2.2463, 'eval_samples_per_second': 681.57, 'eval_steps_per_second': 85.474, 'epoch': 6.0, 'step': 810}, {'loss': 0.0071, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0, 'step': 945}, {'eval_loss': 0.33497098088264465, 'eval_precision': 0.4664351851851852, 'eval_recall': 0.45952109464082097, 'eval_f1': 0.462952326249282, 'eval_accuracy': 0.9450320389099051, 'eval_runtime': 2.3164, 'eval_samples_per_second': 660.931, 'eval_steps_per_second': 82.886, 'epoch': 7.0, 'step': 945}, {'loss': 0.0057, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0, 'step': 1080}, {'eval_loss': 0.35791829228401184, 'eval_precision': 0.42400881057268724, 'eval_recall': 0.43899657924743446, 'eval_f1': 0.4313725490196078, 'eval_accuracy': 0.9426387709410947, 'eval_runtime': 2.2452, 'eval_samples_per_second': 681.892, 'eval_steps_per_second': 85.515, 'epoch': 8.0, 'step': 1080}, {'loss': 0.0056, 'learning_rate': 6.25e-05, 'epoch': 9.0, 'step': 1215}, {'eval_loss': 0.3530077338218689, 'eval_precision': 0.40150801131008484, 'eval_recall': 0.48574686431014824, 'eval_f1': 0.43962848297213625, 'eval_accuracy': 0.9385084536400834, 'eval_runtime': 2.2456, 'eval_samples_per_second': 681.781, 'eval_steps_per_second': 85.501, 'epoch': 9.0, 'step': 1215}, {'loss': 0.0031, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0, 'step': 1350}, {'eval_loss': 0.34314683079719543, 'eval_precision': 0.44885679903730447, 'eval_recall': 0.42531356898517675, 'eval_f1': 0.43676814988290397, 'eval_accuracy': 0.9450320389099051, 'eval_runtime': 2.239, 'eval_samples_per_second': 683.797, 'eval_steps_per_second': 85.754, 'epoch': 10.0, 'step': 1350}, {'loss': 0.0031, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0, 'step': 1485}, {'eval_loss': 0.3476279079914093, 'eval_precision': 0.4161616161616162, 'eval_recall': 0.4697833523375142, 'eval_f1': 0.4413497589716122, 'eval_accuracy': 0.9413263336678762, 'eval_runtime': 2.2432, 'eval_samples_per_second': 682.496, 'eval_steps_per_second': 85.591, 'epoch': 11.0, 'step': 1485}, {'loss': 0.0018, 'learning_rate': 5e-05, 'epoch': 12.0, 'step': 1620}, {'eval_loss': 0.39815443754196167, 'eval_precision': 0.43522727272727274, 'eval_recall': 0.43671607753705816, 'eval_f1': 0.4359704040978941, 'eval_accuracy': 0.9432177873851617, 'eval_runtime': 2.2434, 'eval_samples_per_second': 682.447, 'eval_steps_per_second': 85.584, 'epoch': 12.0, 'step': 1620}, {'loss': 0.0017, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0, 'step': 1755}, {'eval_loss': 0.3913600444793701, 'eval_precision': 0.4441860465116279, 'eval_recall': 0.43557582668187, 'eval_f1': 0.439838802533103, 'eval_accuracy': 0.9444530224658381, 'eval_runtime': 2.24, 'eval_samples_per_second': 683.49, 'eval_steps_per_second': 85.715, 'epoch': 13.0, 'step': 1755}, {'loss': 0.001, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0, 'step': 1890}, {'eval_loss': 0.4182136058807373, 'eval_precision': 0.43922369765066394, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.4633620689655172, 'eval_accuracy': 0.9417509457268587, 'eval_runtime': 2.2404, 'eval_samples_per_second': 683.375, 'eval_steps_per_second': 85.701, 'epoch': 14.0, 'step': 1890}, {'loss': 0.0008, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0, 'step': 2025}, {'eval_loss': 0.4051904082298279, 'eval_precision': 0.45045045045045046, 'eval_recall': 0.45610034207525657, 'eval_f1': 0.45325779036827196, 'eval_accuracy': 0.9439512082143133, 'eval_runtime': 2.2451, 'eval_samples_per_second': 681.935, 'eval_steps_per_second': 85.52, 'epoch': 15.0, 'step': 2025}, {'loss': 0.001, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0, 'step': 2160}, {'eval_loss': 0.4056544005870819, 'eval_precision': 0.4304568527918782, 'eval_recall': 0.48346636259977194, 'eval_f1': 0.4554242749731472, 'eval_accuracy': 0.9439898093105844, 'eval_runtime': 2.2444, 'eval_samples_per_second': 682.152, 'eval_steps_per_second': 85.547, 'epoch': 16.0, 'step': 2160}, {'loss': 0.0008, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0, 'step': 2295}, {'eval_loss': 0.4050329625606537, 'eval_precision': 0.44803229061553984, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.4753747323340471, 'eval_accuracy': 0.9436037983478731, 'eval_runtime': 2.2423, 'eval_samples_per_second': 682.796, 'eval_steps_per_second': 85.628, 'epoch': 17.0, 'step': 2295}, {'loss': 0.0004, 'learning_rate': 2.5e-05, 'epoch': 18.0, 'step': 2430}, {'eval_loss': 0.414998322725296, 'eval_precision': 0.47794117647058826, 'eval_recall': 0.44469783352337516, 'eval_f1': 0.4607206142941524, 'eval_accuracy': 0.9473481046861731, 'eval_runtime': 2.2473, 'eval_samples_per_second': 681.255, 'eval_steps_per_second': 85.435, 'epoch': 18.0, 'step': 2430}, {'loss': 0.0003, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0, 'step': 2565}, {'eval_loss': 0.42128026485443115, 'eval_precision': 0.4610917537746806, 'eval_recall': 0.4526795895096921, 'eval_f1': 0.4568469505178366, 'eval_accuracy': 0.9466918860495638, 'eval_runtime': 2.2436, 'eval_samples_per_second': 682.382, 'eval_steps_per_second': 85.576, 'epoch': 19.0, 'step': 2565}, {'loss': 0.0003, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0, 'step': 2700}, {'eval_loss': 0.42703232169151306, 'eval_precision': 0.46153846153846156, 'eval_recall': 0.47206385404789053, 'eval_f1': 0.46674182638105977, 'eval_accuracy': 0.9461128696054968, 'eval_runtime': 2.2407, 'eval_samples_per_second': 683.267, 'eval_steps_per_second': 85.687, 'epoch': 20.0, 'step': 2700}, {'loss': 0.0002, 'learning_rate': 1.25e-05, 'epoch': 21.0, 'step': 2835}, {'eval_loss': 0.43351900577545166, 'eval_precision': 0.45513513513513515, 'eval_recall': 0.48004561003420754, 'eval_f1': 0.4672586015538291, 'eval_accuracy': 0.945611055353972, 'eval_runtime': 2.2378, 'eval_samples_per_second': 684.145, 'eval_steps_per_second': 85.797, 'epoch': 21.0, 'step': 2835}, {'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0, 'step': 2970}, {'eval_loss': 0.4418164789676666, 'eval_precision': 0.47038327526132406, 'eval_recall': 0.4618015963511973, 'eval_f1': 0.4660529344073648, 'eval_accuracy': 0.9466146838570215, 'eval_runtime': 2.2466, 'eval_samples_per_second': 681.482, 'eval_steps_per_second': 85.463, 'epoch': 22.0, 'step': 2970}, {'loss': 0.0001, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0, 'step': 3105}, {'eval_loss': 0.4424847960472107, 'eval_precision': 0.4787234042553192, 'eval_recall': 0.4618015963511973, 'eval_f1': 0.4701102727800348, 'eval_accuracy': 0.947039295916004, 'eval_runtime': 2.2466, 'eval_samples_per_second': 681.469, 'eval_steps_per_second': 85.462, 'epoch': 23.0, 'step': 3105}, {'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 3240}, {'eval_loss': 0.44190743565559387, 'eval_precision': 0.47374562427071176, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4682814302191465, 'eval_accuracy': 0.9468076893383772, 'eval_runtime': 2.434, 'eval_samples_per_second': 628.999, 'eval_steps_per_second': 78.882, 'epoch': 24.0, 'step': 3240}, {'train_runtime': 725.8451, 'train_samples_per_second': 285.482, 'train_steps_per_second': 4.464, 'total_flos': 7418622311681880.0, 'train_loss': 0.01953077647651051, 'epoch': 24.0, 'step': 3240}]

Evaluation, ltg/norbert2
***** predict metrics *****
  predict_accuracy           =     0.9468
  predict_f1                 =     0.4339
  predict_loss               =     0.1631
  predict_precision          =     0.4515
  predict_recall             =     0.4177
  predict_runtime            = 0:00:01.86
  predict_samples_per_second =    680.786
  predict_steps_per_second   =     85.098
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_2_38.json completed. F1: 0.43392226148409896
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_20.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_20.json
01170939_tsa-bin_NorBERT_3_large Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 6310.54 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:00, 6935.20 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6809.41 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6853.06 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6923.67 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 7021.21 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 7184.64 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 6285.78 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6676.64 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7312.65 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6924.78 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 7009.53 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6863.67 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/fp/homes01/u01/ec-egilron/venvs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Checkpoint destination directory /cluster/work/projects/ec30/egilron/tsa-hf/01170939_tsa-bin_NorBERT_3_large/checkpoint-216 already exists and is non-empty.Saving will proceed but saved results may be invalid.
01170939_tsa-bin_NorBERT_3_large Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']
{'loss': 0.324, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0}
{'eval_loss': 0.19408489763736725, 'eval_precision': 0.2717391304347826, 'eval_recall': 0.19954389965792474, 'eval_f1': 0.230111768573307, 'eval_accuracy': 0.9417123446305875, 'eval_runtime': 5.8402, 'eval_samples_per_second': 262.147, 'eval_steps_per_second': 32.875, 'epoch': 1.0}
{'loss': 0.1442, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0}
{'eval_loss': 0.1799601912498474, 'eval_precision': 0.5553745928338762, 'eval_recall': 0.3888255416191562, 'eval_f1': 0.45741113346747153, 'eval_accuracy': 0.9520960395275225, 'eval_runtime': 5.8123, 'eval_samples_per_second': 263.406, 'eval_steps_per_second': 33.033, 'epoch': 2.0}
{'loss': 0.0685, 'learning_rate': 8.75e-05, 'epoch': 3.0}
{'eval_loss': 0.1963420808315277, 'eval_precision': 0.4678988326848249, 'eval_recall': 0.548460661345496, 'eval_f1': 0.50498687664042, 'eval_accuracy': 0.946151470701768, 'eval_runtime': 5.8278, 'eval_samples_per_second': 262.705, 'eval_steps_per_second': 32.945, 'epoch': 3.0}
{'loss': 0.0361, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0}
{'eval_loss': 0.22366806864738464, 'eval_precision': 0.4793388429752066, 'eval_recall': 0.5290763968072976, 'eval_f1': 0.5029810298102981, 'eval_accuracy': 0.9470006948197329, 'eval_runtime': 5.813, 'eval_samples_per_second': 263.377, 'eval_steps_per_second': 33.03, 'epoch': 4.0}
{'loss': 0.0199, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0}
{'eval_loss': 0.2291504591703415, 'eval_precision': 0.45123152709359604, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.48414376321353064, 'eval_accuracy': 0.9426773720373659, 'eval_runtime': 5.8262, 'eval_samples_per_second': 262.777, 'eval_steps_per_second': 32.954, 'epoch': 5.0}
{'loss': 0.012, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0}
{'eval_loss': 0.27733665704727173, 'eval_precision': 0.5286458333333334, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4936170212765958, 'eval_accuracy': 0.950783602254304, 'eval_runtime': 5.8155, 'eval_samples_per_second': 263.263, 'eval_steps_per_second': 33.015, 'epoch': 6.0}
{'loss': 0.0078, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0}
{'eval_loss': 0.2563934326171875, 'eval_precision': 0.48494623655913977, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.49916989485334806, 'eval_accuracy': 0.9472709024936308, 'eval_runtime': 5.9202, 'eval_samples_per_second': 258.607, 'eval_steps_per_second': 32.431, 'epoch': 7.0}
{'loss': 0.0052, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0}
{'eval_loss': 0.2998112738132477, 'eval_precision': 0.49764150943396224, 'eval_recall': 0.4811858608893957, 'eval_f1': 0.48927536231884056, 'eval_accuracy': 0.9481201266115957, 'eval_runtime': 5.8465, 'eval_samples_per_second': 261.868, 'eval_steps_per_second': 32.84, 'epoch': 8.0}
{'loss': 0.0034, 'learning_rate': 6.25e-05, 'epoch': 9.0}
{'eval_loss': 0.33396273851394653, 'eval_precision': 0.4993909866017052, 'eval_recall': 0.467502850627138, 'eval_f1': 0.4829210836277974, 'eval_accuracy': 0.9498571759437968, 'eval_runtime': 5.8299, 'eval_samples_per_second': 262.612, 'eval_steps_per_second': 32.934, 'epoch': 9.0}
{'loss': 0.003, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0}
{'eval_loss': 0.31183484196662903, 'eval_precision': 0.5108958837772397, 'eval_recall': 0.4811858608893957, 'eval_f1': 0.49559600704638873, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 5.8378, 'eval_samples_per_second': 262.257, 'eval_steps_per_second': 32.889, 'epoch': 10.0}
{'loss': 0.0025, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0}
{'eval_loss': 0.3294103741645813, 'eval_precision': 0.4689092762487258, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.49515608180839615, 'eval_accuracy': 0.946190071798039, 'eval_runtime': 5.8298, 'eval_samples_per_second': 262.615, 'eval_steps_per_second': 32.934, 'epoch': 11.0}
{'loss': 0.0013, 'learning_rate': 5e-05, 'epoch': 12.0}
{'eval_loss': 0.33441221714019775, 'eval_precision': 0.47816349384098544, 'eval_recall': 0.4868871151653364, 'eval_f1': 0.4824858757062147, 'eval_accuracy': 0.9486605419593916, 'eval_runtime': 5.7935, 'eval_samples_per_second': 264.261, 'eval_steps_per_second': 33.141, 'epoch': 12.0}
{'loss': 0.0011, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0}
{'eval_loss': 0.3511277139186859, 'eval_precision': 0.49327354260089684, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.497456189937818, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 5.862, 'eval_samples_per_second': 261.173, 'eval_steps_per_second': 32.753, 'epoch': 13.0}
{'loss': 0.0006, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0}
{'eval_loss': 0.3680264353752136, 'eval_precision': 0.49008168028004667, 'eval_recall': 0.4789053591790194, 'eval_f1': 0.4844290657439447, 'eval_accuracy': 0.9494711649810854, 'eval_runtime': 5.8084, 'eval_samples_per_second': 263.582, 'eval_steps_per_second': 33.055, 'epoch': 14.0}
{'loss': 0.0007, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0}
{'eval_loss': 0.35769447684288025, 'eval_precision': 0.4994438264738598, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5056306306306305, 'eval_accuracy': 0.9490079518258319, 'eval_runtime': 5.802, 'eval_samples_per_second': 263.873, 'eval_steps_per_second': 33.092, 'epoch': 15.0}
{'loss': 0.0005, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0}
{'eval_loss': 0.36336806416511536, 'eval_precision': 0.5354330708661418, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.49786455155582676, 'eval_accuracy': 0.9524820504902339, 'eval_runtime': 5.7854, 'eval_samples_per_second': 264.63, 'eval_steps_per_second': 33.187, 'epoch': 16.0}
{'loss': 0.0003, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0}
{'eval_loss': 0.36959534883499146, 'eval_precision': 0.5112960760998811, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.5005820721769499, 'eval_accuracy': 0.9497799737512546, 'eval_runtime': 5.7847, 'eval_samples_per_second': 264.663, 'eval_steps_per_second': 33.191, 'epoch': 17.0}
{'loss': 0.0003, 'learning_rate': 2.5e-05, 'epoch': 18.0}
{'eval_loss': 0.38133373856544495, 'eval_precision': 0.49077090119435396, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.5027808676307008, 'eval_accuracy': 0.9493939627885432, 'eval_runtime': 5.7844, 'eval_samples_per_second': 264.675, 'eval_steps_per_second': 33.192, 'epoch': 18.0}
{'loss': 0.0002, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0}
{'eval_loss': 0.389864444732666, 'eval_precision': 0.48094747682801237, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5054112554112554, 'eval_accuracy': 0.9477727167451555, 'eval_runtime': 5.8475, 'eval_samples_per_second': 261.821, 'eval_steps_per_second': 32.834, 'epoch': 19.0}
{'loss': 0.0002, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0}
{'eval_loss': 0.3860420882701874, 'eval_precision': 0.5183867141162515, 'eval_recall': 0.4982896237172178, 'eval_f1': 0.5081395348837209, 'eval_accuracy': 0.9510152088319308, 'eval_runtime': 5.7687, 'eval_samples_per_second': 265.4, 'eval_steps_per_second': 33.283, 'epoch': 20.0}
{'loss': 0.0001, 'learning_rate': 1.25e-05, 'epoch': 21.0}
{'eval_loss': 0.3941630423069, 'eval_precision': 0.49888392857142855, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.5042301184433164, 'eval_accuracy': 0.9502431869065081, 'eval_runtime': 5.7819, 'eval_samples_per_second': 264.791, 'eval_steps_per_second': 33.207, 'epoch': 21.0}
{'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0}
{'eval_loss': 0.3983294665813446, 'eval_precision': 0.5188235294117647, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.5107122177185872, 'eval_accuracy': 0.9509766077356597, 'eval_runtime': 5.7716, 'eval_samples_per_second': 265.262, 'eval_steps_per_second': 33.266, 'epoch': 22.0}
{'loss': 0.0001, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0}
{'eval_loss': 0.3999650180339813, 'eval_precision': 0.5175644028103045, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.510687463893703, 'eval_accuracy': 0.951053809928202, 'eval_runtime': 5.7682, 'eval_samples_per_second': 265.421, 'eval_steps_per_second': 33.286, 'epoch': 23.0}
{'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0}
{'eval_loss': 0.40054064989089966, 'eval_precision': 0.5050618672665916, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5084937712344281, 'eval_accuracy': 0.9505133945804061, 'eval_runtime': 5.7588, 'eval_samples_per_second': 265.853, 'eval_steps_per_second': 33.34, 'epoch': 24.0}
{'train_runtime': 2452.2355, 'train_samples_per_second': 84.501, 'train_steps_per_second': 2.114, 'train_loss': 0.026344279612035112, 'epoch': 24.0}
***** train metrics *****
  epoch                    =       24.0
  train_loss               =     0.0263
  train_runtime            = 0:40:52.23
  train_samples            =       8634
  train_samples_per_second =     84.501
  train_steps_per_second   =      2.114
[{'loss': 0.324, 'learning_rate': 9.583333333333334e-05, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.19408489763736725, 'eval_precision': 0.2717391304347826, 'eval_recall': 0.19954389965792474, 'eval_f1': 0.230111768573307, 'eval_accuracy': 0.9417123446305875, 'eval_runtime': 5.8402, 'eval_samples_per_second': 262.147, 'eval_steps_per_second': 32.875, 'epoch': 1.0, 'step': 216}, {'loss': 0.1442, 'learning_rate': 9.166666666666667e-05, 'epoch': 2.0, 'step': 432}, {'eval_loss': 0.1799601912498474, 'eval_precision': 0.5553745928338762, 'eval_recall': 0.3888255416191562, 'eval_f1': 0.45741113346747153, 'eval_accuracy': 0.9520960395275225, 'eval_runtime': 5.8123, 'eval_samples_per_second': 263.406, 'eval_steps_per_second': 33.033, 'epoch': 2.0, 'step': 432}, {'loss': 0.0685, 'learning_rate': 8.75e-05, 'epoch': 3.0, 'step': 648}, {'eval_loss': 0.1963420808315277, 'eval_precision': 0.4678988326848249, 'eval_recall': 0.548460661345496, 'eval_f1': 0.50498687664042, 'eval_accuracy': 0.946151470701768, 'eval_runtime': 5.8278, 'eval_samples_per_second': 262.705, 'eval_steps_per_second': 32.945, 'epoch': 3.0, 'step': 648}, {'loss': 0.0361, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.0, 'step': 864}, {'eval_loss': 0.22366806864738464, 'eval_precision': 0.4793388429752066, 'eval_recall': 0.5290763968072976, 'eval_f1': 0.5029810298102981, 'eval_accuracy': 0.9470006948197329, 'eval_runtime': 5.813, 'eval_samples_per_second': 263.377, 'eval_steps_per_second': 33.03, 'epoch': 4.0, 'step': 864}, {'loss': 0.0199, 'learning_rate': 7.916666666666666e-05, 'epoch': 5.0, 'step': 1080}, {'eval_loss': 0.2291504591703415, 'eval_precision': 0.45123152709359604, 'eval_recall': 0.5222348916761688, 'eval_f1': 0.48414376321353064, 'eval_accuracy': 0.9426773720373659, 'eval_runtime': 5.8262, 'eval_samples_per_second': 262.777, 'eval_steps_per_second': 32.954, 'epoch': 5.0, 'step': 1080}, {'loss': 0.012, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.0, 'step': 1296}, {'eval_loss': 0.27733665704727173, 'eval_precision': 0.5286458333333334, 'eval_recall': 0.4629418472063854, 'eval_f1': 0.4936170212765958, 'eval_accuracy': 0.950783602254304, 'eval_runtime': 5.8155, 'eval_samples_per_second': 263.263, 'eval_steps_per_second': 33.015, 'epoch': 6.0, 'step': 1296}, {'loss': 0.0078, 'learning_rate': 7.083333333333334e-05, 'epoch': 7.0, 'step': 1512}, {'eval_loss': 0.2563934326171875, 'eval_precision': 0.48494623655913977, 'eval_recall': 0.5142531356898518, 'eval_f1': 0.49916989485334806, 'eval_accuracy': 0.9472709024936308, 'eval_runtime': 5.9202, 'eval_samples_per_second': 258.607, 'eval_steps_per_second': 32.431, 'epoch': 7.0, 'step': 1512}, {'loss': 0.0052, 'learning_rate': 6.666666666666667e-05, 'epoch': 8.0, 'step': 1728}, {'eval_loss': 0.2998112738132477, 'eval_precision': 0.49764150943396224, 'eval_recall': 0.4811858608893957, 'eval_f1': 0.48927536231884056, 'eval_accuracy': 0.9481201266115957, 'eval_runtime': 5.8465, 'eval_samples_per_second': 261.868, 'eval_steps_per_second': 32.84, 'epoch': 8.0, 'step': 1728}, {'loss': 0.0034, 'learning_rate': 6.25e-05, 'epoch': 9.0, 'step': 1944}, {'eval_loss': 0.33396273851394653, 'eval_precision': 0.4993909866017052, 'eval_recall': 0.467502850627138, 'eval_f1': 0.4829210836277974, 'eval_accuracy': 0.9498571759437968, 'eval_runtime': 5.8299, 'eval_samples_per_second': 262.612, 'eval_steps_per_second': 32.934, 'epoch': 9.0, 'step': 1944}, {'loss': 0.003, 'learning_rate': 5.833333333333334e-05, 'epoch': 10.0, 'step': 2160}, {'eval_loss': 0.31183484196662903, 'eval_precision': 0.5108958837772397, 'eval_recall': 0.4811858608893957, 'eval_f1': 0.49559600704638873, 'eval_accuracy': 0.9492781594997298, 'eval_runtime': 5.8378, 'eval_samples_per_second': 262.257, 'eval_steps_per_second': 32.889, 'epoch': 10.0, 'step': 2160}, {'loss': 0.0025, 'learning_rate': 5.4166666666666664e-05, 'epoch': 11.0, 'step': 2376}, {'eval_loss': 0.3294103741645813, 'eval_precision': 0.4689092762487258, 'eval_recall': 0.5245153933865451, 'eval_f1': 0.49515608180839615, 'eval_accuracy': 0.946190071798039, 'eval_runtime': 5.8298, 'eval_samples_per_second': 262.615, 'eval_steps_per_second': 32.934, 'epoch': 11.0, 'step': 2376}, {'loss': 0.0013, 'learning_rate': 5e-05, 'epoch': 12.0, 'step': 2592}, {'eval_loss': 0.33441221714019775, 'eval_precision': 0.47816349384098544, 'eval_recall': 0.4868871151653364, 'eval_f1': 0.4824858757062147, 'eval_accuracy': 0.9486605419593916, 'eval_runtime': 5.7935, 'eval_samples_per_second': 264.261, 'eval_steps_per_second': 33.141, 'epoch': 12.0, 'step': 2592}, {'loss': 0.0011, 'learning_rate': 4.5833333333333334e-05, 'epoch': 13.0, 'step': 2808}, {'eval_loss': 0.3511277139186859, 'eval_precision': 0.49327354260089684, 'eval_recall': 0.5017103762827823, 'eval_f1': 0.497456189937818, 'eval_accuracy': 0.9493167605960009, 'eval_runtime': 5.862, 'eval_samples_per_second': 261.173, 'eval_steps_per_second': 32.753, 'epoch': 13.0, 'step': 2808}, {'loss': 0.0006, 'learning_rate': 4.166666666666667e-05, 'epoch': 14.0, 'step': 3024}, {'eval_loss': 0.3680264353752136, 'eval_precision': 0.49008168028004667, 'eval_recall': 0.4789053591790194, 'eval_f1': 0.4844290657439447, 'eval_accuracy': 0.9494711649810854, 'eval_runtime': 5.8084, 'eval_samples_per_second': 263.582, 'eval_steps_per_second': 33.055, 'epoch': 14.0, 'step': 3024}, {'loss': 0.0007, 'learning_rate': 3.7500000000000003e-05, 'epoch': 15.0, 'step': 3240}, {'eval_loss': 0.35769447684288025, 'eval_precision': 0.4994438264738598, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5056306306306305, 'eval_accuracy': 0.9490079518258319, 'eval_runtime': 5.802, 'eval_samples_per_second': 263.873, 'eval_steps_per_second': 33.092, 'epoch': 15.0, 'step': 3240}, {'loss': 0.0005, 'learning_rate': 3.3333333333333335e-05, 'epoch': 16.0, 'step': 3456}, {'eval_loss': 0.36336806416511536, 'eval_precision': 0.5354330708661418, 'eval_recall': 0.4652223489167617, 'eval_f1': 0.49786455155582676, 'eval_accuracy': 0.9524820504902339, 'eval_runtime': 5.7854, 'eval_samples_per_second': 264.63, 'eval_steps_per_second': 33.187, 'epoch': 16.0, 'step': 3456}, {'loss': 0.0003, 'learning_rate': 2.916666666666667e-05, 'epoch': 17.0, 'step': 3672}, {'eval_loss': 0.36959534883499146, 'eval_precision': 0.5112960760998811, 'eval_recall': 0.4903078677309008, 'eval_f1': 0.5005820721769499, 'eval_accuracy': 0.9497799737512546, 'eval_runtime': 5.7847, 'eval_samples_per_second': 264.663, 'eval_steps_per_second': 33.191, 'epoch': 17.0, 'step': 3672}, {'loss': 0.0003, 'learning_rate': 2.5e-05, 'epoch': 18.0, 'step': 3888}, {'eval_loss': 0.38133373856544495, 'eval_precision': 0.49077090119435396, 'eval_recall': 0.5153933865450399, 'eval_f1': 0.5027808676307008, 'eval_accuracy': 0.9493939627885432, 'eval_runtime': 5.7844, 'eval_samples_per_second': 264.675, 'eval_steps_per_second': 33.192, 'epoch': 18.0, 'step': 3888}, {'loss': 0.0002, 'learning_rate': 2.0833333333333336e-05, 'epoch': 19.0, 'step': 4104}, {'eval_loss': 0.389864444732666, 'eval_precision': 0.48094747682801237, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5054112554112554, 'eval_accuracy': 0.9477727167451555, 'eval_runtime': 5.8475, 'eval_samples_per_second': 261.821, 'eval_steps_per_second': 32.834, 'epoch': 19.0, 'step': 4104}, {'loss': 0.0002, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0, 'step': 4320}, {'eval_loss': 0.3860420882701874, 'eval_precision': 0.5183867141162515, 'eval_recall': 0.4982896237172178, 'eval_f1': 0.5081395348837209, 'eval_accuracy': 0.9510152088319308, 'eval_runtime': 5.7687, 'eval_samples_per_second': 265.4, 'eval_steps_per_second': 33.283, 'epoch': 20.0, 'step': 4320}, {'loss': 0.0001, 'learning_rate': 1.25e-05, 'epoch': 21.0, 'step': 4536}, {'eval_loss': 0.3941630423069, 'eval_precision': 0.49888392857142855, 'eval_recall': 0.5096921322690992, 'eval_f1': 0.5042301184433164, 'eval_accuracy': 0.9502431869065081, 'eval_runtime': 5.7819, 'eval_samples_per_second': 264.791, 'eval_steps_per_second': 33.207, 'epoch': 21.0, 'step': 4536}, {'loss': 0.0002, 'learning_rate': 8.333333333333334e-06, 'epoch': 22.0, 'step': 4752}, {'eval_loss': 0.3983294665813446, 'eval_precision': 0.5188235294117647, 'eval_recall': 0.5028506271379704, 'eval_f1': 0.5107122177185872, 'eval_accuracy': 0.9509766077356597, 'eval_runtime': 5.7716, 'eval_samples_per_second': 265.262, 'eval_steps_per_second': 33.266, 'epoch': 22.0, 'step': 4752}, {'loss': 0.0001, 'learning_rate': 4.166666666666667e-06, 'epoch': 23.0, 'step': 4968}, {'eval_loss': 0.3999650180339813, 'eval_precision': 0.5175644028103045, 'eval_recall': 0.5039908779931584, 'eval_f1': 0.510687463893703, 'eval_accuracy': 0.951053809928202, 'eval_runtime': 5.7682, 'eval_samples_per_second': 265.421, 'eval_steps_per_second': 33.286, 'epoch': 23.0, 'step': 4968}, {'loss': 0.0001, 'learning_rate': 0.0, 'epoch': 24.0, 'step': 5184}, {'eval_loss': 0.40054064989089966, 'eval_precision': 0.5050618672665916, 'eval_recall': 0.5119726339794755, 'eval_f1': 0.5084937712344281, 'eval_accuracy': 0.9505133945804061, 'eval_runtime': 5.7588, 'eval_samples_per_second': 265.853, 'eval_steps_per_second': 33.34, 'epoch': 24.0, 'step': 5184}, {'train_runtime': 2452.2355, 'train_samples_per_second': 84.501, 'train_steps_per_second': 2.114, 'total_flos': 2.4800280552929028e+16, 'train_loss': 0.026344279612035112, 'epoch': 24.0, 'step': 5184}]

Evaluation, ltg/norbert3-large
***** predict metrics *****
  predict_accuracy           =     0.9528
  predict_f1                 =     0.4641
  predict_loss               =     0.1861
  predict_precision          =     0.5808
  predict_recall             =     0.3864
  predict_runtime            = 0:00:04.82
  predict_samples_per_second =    263.607
  predict_steps_per_second   =     32.951
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01170939_tsa-bin_NorBERT_3_large_20.json completed. F1: 0.46405228758169936

Task and CPU usage stats:
JobID           JobName  AllocCPUS   NTasks     MinCPU MinCPUTask     AveCPU    Elapsed ExitCode 
------------ ---------- ---------- -------- ---------- ---------- ---------- ---------- -------- 
410062       tsa_norbe+          1                                             05:05:54      0:0 
410062.batch      batch          1        1   05:00:13          0   05:00:13   05:05:54      0:0 
410062.exte+     extern          1        1   00:00:00          0   00:00:00   05:05:54      0:0 

Memory usage stats:
JobID            MaxRSS MaxRSSTask     AveRSS MaxPages   MaxPagesTask   AvePages 
------------ ---------- ---------- ---------- -------- -------------- ---------- 
410062                                                                           
410062.batch   3789728K          0   3789728K        1              0          1 
410062.exte+          0          0          0        0              0          0 

Disk usage stats:
JobID         MaxDiskRead MaxDiskReadTask    AveDiskRead MaxDiskWrite MaxDiskWriteTask   AveDiskWrite 
------------ ------------ --------------- -------------- ------------ ---------------- -------------- 
410062                                                                                                
410062.batch     8373.68M               0       8373.68M   784292.30M                0     784292.30M 
410062.exte+        0.01M               0          0.01M        0.00M                0          0.00M 

GPU usage stats:
Error: Unable to retrieve job statistics. Return: Setting not configured.

Job 410062 completed at Thu Jan 18 16:14:00 CET 2024
