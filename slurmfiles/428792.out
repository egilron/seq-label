Starting job 428792 on gpu-7 at Mon Feb 12 15:41:43 CET 2024

/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/
/fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01191518_tsa-bin_NorBERT_3_base_16c.json
Python: 3.10.4 (main, Aug 30 2023, 20:05:23) [GCC 11.3.0]
Numpy: 1.22.3
PyTorch: 1.12.1
Transformers: 4.36.2



***Loading config file: /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01191518_tsa-bin_NorBERT_3_base_16c.json
01191518_tsa-bin_NorBERT_3_base Our label2id: {'O': 0, 'B-targ-Negative': 1, 'I-targ-Negative': 2, 'B-targ-Positive': 3, 'I-targ-Positive': 4}
Running tokenizer on train dataset:   0%|          | 0/8634 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Running tokenizer on train dataset:  12%|█▏        | 1000/8634 [00:00<00:01, 5332.17 examples/s]Running tokenizer on train dataset:  23%|██▎       | 2000/8634 [00:00<00:01, 6305.24 examples/s]Running tokenizer on train dataset:  35%|███▍      | 3000/8634 [00:00<00:00, 6400.74 examples/s]Running tokenizer on train dataset:  46%|████▋     | 4000/8634 [00:00<00:00, 6583.97 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 5000/8634 [00:00<00:00, 6696.57 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 6000/8634 [00:00<00:00, 6866.87 examples/s]Running tokenizer on train dataset:  81%|████████  | 7000/8634 [00:01<00:00, 7050.16 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 8000/8634 [00:01<00:00, 5974.53 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 5886.74 examples/s]Running tokenizer on train dataset: 100%|██████████| 8634/8634 [00:01<00:00, 6223.71 examples/s]
Running tokenizer on validation dataset:   0%|          | 0/1531 [00:00<?, ? examples/s]Running tokenizer on validation dataset:  65%|██████▌   | 1000/1531 [00:00<00:00, 7143.81 examples/s]Running tokenizer on validation dataset: 100%|██████████| 1531/1531 [00:00<00:00, 6812.23 examples/s]
Running tokenizer on test dataset:   0%|          | 0/1272 [00:00<?, ? examples/s]Running tokenizer on test dataset:  79%|███████▊  | 1000/1272 [00:00<00:00, 6848.68 examples/s]Running tokenizer on test dataset: 100%|██████████| 1272/1272 [00:00<00:00, 6330.09 examples/s]
You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Checkpoint destination directory /cluster/work/projects/ec30/egilron/tsa-hf/01191518_tsa-bin_NorBERT_3_base_tests2/checkpoint-540 already exists and is non-empty.Saving will proceed but saved results may be invalid.
Tokenization completed

Model: ltg/norbert3-base Trust Remote code? True
01191518_tsa-bin_NorBERT_3_base 
Ready to train. Train dataset labels are now: ['idx', 'tokens', 'tsa_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'] 

{'loss': 0.3595, 'learning_rate': 1.9e-05, 'epoch': 1.0}
{'eval_loss': 0.1984805464744568, 'eval_precision': 0.24297520661157024, 'eval_recall': 0.1676168757126568, 'eval_f1': 0.19838056680161942, 'eval_accuracy': 0.9404385084536401, 'eval_runtime': 2.9967, 'eval_samples_per_second': 510.896, 'eval_steps_per_second': 64.071, 'epoch': 1.0}
{'loss': 0.172, 'learning_rate': 1.8e-05, 'epoch': 2.0}
{'eval_loss': 0.16483400762081146, 'eval_precision': 0.47875816993464054, 'eval_recall': 0.33409350057012543, 'eval_f1': 0.3935527199462727, 'eval_accuracy': 0.9499343781363391, 'eval_runtime': 2.9284, 'eval_samples_per_second': 522.818, 'eval_steps_per_second': 65.566, 'epoch': 2.0}
{'loss': 0.1111, 'learning_rate': 1.7e-05, 'epoch': 3.0}
{'eval_loss': 0.17174987494945526, 'eval_precision': 0.4275510204081633, 'eval_recall': 0.47776510832383123, 'eval_f1': 0.4512654819601508, 'eval_accuracy': 0.9462672739905813, 'eval_runtime': 2.9662, 'eval_samples_per_second': 516.15, 'eval_steps_per_second': 64.729, 'epoch': 3.0}
{'loss': 0.0674, 'learning_rate': 1.6000000000000003e-05, 'epoch': 4.0}
{'eval_loss': 0.19391348958015442, 'eval_precision': 0.5045500505561172, 'eval_recall': 0.5689851767388826, 'eval_f1': 0.534833869239014, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 3.0717, 'eval_samples_per_second': 498.417, 'eval_steps_per_second': 62.506, 'epoch': 4.0}
{'loss': 0.0399, 'learning_rate': 1.5000000000000002e-05, 'epoch': 5.0}
{'eval_loss': 0.21263504028320312, 'eval_precision': 0.49281767955801103, 'eval_recall': 0.508551881413911, 'eval_f1': 0.5005611672278338, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 2.998, 'eval_samples_per_second': 510.681, 'eval_steps_per_second': 64.044, 'epoch': 5.0}
{'loss': 0.0249, 'learning_rate': 1.4e-05, 'epoch': 6.0}
{'eval_loss': 0.24309775233268738, 'eval_precision': 0.5343980343980343, 'eval_recall': 0.4960091220068415, 'eval_f1': 0.5144884683619161, 'eval_accuracy': 0.9515556241797267, 'eval_runtime': 3.0487, 'eval_samples_per_second': 502.185, 'eval_steps_per_second': 62.978, 'epoch': 6.0}
{'loss': 0.0147, 'learning_rate': 1.3000000000000001e-05, 'epoch': 7.0}
{'eval_loss': 0.2652530372142792, 'eval_precision': 0.48393782383419687, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.507057546145494, 'eval_accuracy': 0.9506291978692195, 'eval_runtime': 3.2307, 'eval_samples_per_second': 473.894, 'eval_steps_per_second': 59.43, 'epoch': 7.0}
{'loss': 0.0091, 'learning_rate': 1.2e-05, 'epoch': 8.0}
{'eval_loss': 0.2809131145477295, 'eval_precision': 0.5026910656620022, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5171650055370985, 'eval_accuracy': 0.9511310121207442, 'eval_runtime': 2.9302, 'eval_samples_per_second': 522.49, 'eval_steps_per_second': 65.525, 'epoch': 8.0}
{'loss': 0.0068, 'learning_rate': 1.1000000000000001e-05, 'epoch': 9.0}
{'eval_loss': 0.30010610818862915, 'eval_precision': 0.5394896719319563, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.5223529411764705, 'eval_accuracy': 0.9528294603566742, 'eval_runtime': 2.9493, 'eval_samples_per_second': 519.112, 'eval_steps_per_second': 65.101, 'epoch': 9.0}
{'loss': 0.0045, 'learning_rate': 1e-05, 'epoch': 10.0}
{'eval_loss': 0.32053372263908386, 'eval_precision': 0.518640350877193, 'eval_recall': 0.5393386545039909, 'eval_f1': 0.528787031861375, 'eval_accuracy': 0.9514398208909133, 'eval_runtime': 2.9316, 'eval_samples_per_second': 522.24, 'eval_steps_per_second': 65.493, 'epoch': 10.0}
{'loss': 0.0033, 'learning_rate': 9e-06, 'epoch': 11.0}
{'eval_loss': 0.32531243562698364, 'eval_precision': 0.5281146637265711, 'eval_recall': 0.5461801596351197, 'eval_f1': 0.5369955156950671, 'eval_accuracy': 0.9517100285648112, 'eval_runtime': 2.9592, 'eval_samples_per_second': 517.37, 'eval_steps_per_second': 64.883, 'epoch': 11.0}
{'loss': 0.0022, 'learning_rate': 8.000000000000001e-06, 'epoch': 12.0}
{'eval_loss': 0.34835949540138245, 'eval_precision': 0.5053879310344828, 'eval_recall': 0.5347776510832383, 'eval_f1': 0.5196675900277008, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 2.9385, 'eval_samples_per_second': 521.008, 'eval_steps_per_second': 65.339, 'epoch': 12.0}
{'loss': 0.0019, 'learning_rate': 7e-06, 'epoch': 13.0}
{'eval_loss': 0.34721463918685913, 'eval_precision': 0.5496277915632755, 'eval_recall': 0.5051311288483467, 'eval_f1': 0.5264408793820559, 'eval_accuracy': 0.95336987570447, 'eval_runtime': 2.946, 'eval_samples_per_second': 519.687, 'eval_steps_per_second': 65.173, 'epoch': 13.0}
{'loss': 0.0014, 'learning_rate': 6e-06, 'epoch': 14.0}
{'eval_loss': 0.353302925825119, 'eval_precision': 0.544047619047619, 'eval_recall': 0.5210946408209807, 'eval_f1': 0.5323238206173557, 'eval_accuracy': 0.9533312746081989, 'eval_runtime': 2.9554, 'eval_samples_per_second': 518.04, 'eval_steps_per_second': 64.966, 'epoch': 14.0}
{'loss': 0.0013, 'learning_rate': 5e-06, 'epoch': 15.0}
{'eval_loss': 0.36596646904945374, 'eval_precision': 0.5317185697808535, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5286697247706423, 'eval_accuracy': 0.9522504439126072, 'eval_runtime': 3.0192, 'eval_samples_per_second': 507.083, 'eval_steps_per_second': 63.592, 'epoch': 15.0}
{'loss': 0.0011, 'learning_rate': 4.000000000000001e-06, 'epoch': 16.0}
{'eval_loss': 0.3721886873245239, 'eval_precision': 0.5508274231678487, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.5409170052234475, 'eval_accuracy': 0.9527136570678607, 'eval_runtime': 2.9494, 'eval_samples_per_second': 519.083, 'eval_steps_per_second': 65.097, 'epoch': 16.0}
{'loss': 0.0007, 'learning_rate': 3e-06, 'epoch': 17.0}
{'eval_loss': 0.3836904466152191, 'eval_precision': 0.5251091703056768, 'eval_recall': 0.548460661345496, 'eval_f1': 0.5365309537088678, 'eval_accuracy': 0.9512468154095576, 'eval_runtime': 3.0187, 'eval_samples_per_second': 507.174, 'eval_steps_per_second': 63.604, 'epoch': 17.0}
{'loss': 0.0009, 'learning_rate': 2.0000000000000003e-06, 'epoch': 18.0}
{'eval_loss': 0.3791346848011017, 'eval_precision': 0.5373134328358209, 'eval_recall': 0.5336374002280502, 'eval_f1': 0.5354691075514875, 'eval_accuracy': 0.9518258318536247, 'eval_runtime': 2.9795, 'eval_samples_per_second': 513.839, 'eval_steps_per_second': 64.44, 'epoch': 18.0}
{'loss': 0.0005, 'learning_rate': 1.0000000000000002e-06, 'epoch': 19.0}
{'eval_loss': 0.3807985484600067, 'eval_precision': 0.5423529411764706, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5338737695425594, 'eval_accuracy': 0.9523276461051494, 'eval_runtime': 2.9947, 'eval_samples_per_second': 511.24, 'eval_steps_per_second': 64.114, 'epoch': 19.0}
{'loss': 0.0006, 'learning_rate': 0.0, 'epoch': 20.0}
{'eval_loss': 0.3812880218029022, 'eval_precision': 0.5318906605922551, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5321937321937322, 'eval_accuracy': 0.9518258318536247, 'eval_runtime': 2.9407, 'eval_samples_per_second': 520.627, 'eval_steps_per_second': 65.291, 'epoch': 20.0}
{'train_runtime': 824.4064, 'train_samples_per_second': 209.46, 'train_steps_per_second': 13.1, 'train_loss': 0.04119411334119461, 'epoch': 20.0}
***** train metrics *****
  epoch                    =       20.0
  train_loss               =     0.0412
  train_runtime            = 0:13:44.40
  train_samples            =       8634
  train_samples_per_second =     209.46
  train_steps_per_second   =       13.1
[{'loss': 0.3595, 'learning_rate': 1.9e-05, 'epoch': 1.0, 'step': 540}, {'eval_loss': 0.1984805464744568, 'eval_precision': 0.24297520661157024, 'eval_recall': 0.1676168757126568, 'eval_f1': 0.19838056680161942, 'eval_accuracy': 0.9404385084536401, 'eval_runtime': 2.9967, 'eval_samples_per_second': 510.896, 'eval_steps_per_second': 64.071, 'epoch': 1.0, 'step': 540}, {'loss': 0.172, 'learning_rate': 1.8e-05, 'epoch': 2.0, 'step': 1080}, {'eval_loss': 0.16483400762081146, 'eval_precision': 0.47875816993464054, 'eval_recall': 0.33409350057012543, 'eval_f1': 0.3935527199462727, 'eval_accuracy': 0.9499343781363391, 'eval_runtime': 2.9284, 'eval_samples_per_second': 522.818, 'eval_steps_per_second': 65.566, 'epoch': 2.0, 'step': 1080}, {'loss': 0.1111, 'learning_rate': 1.7e-05, 'epoch': 3.0, 'step': 1620}, {'eval_loss': 0.17174987494945526, 'eval_precision': 0.4275510204081633, 'eval_recall': 0.47776510832383123, 'eval_f1': 0.4512654819601508, 'eval_accuracy': 0.9462672739905813, 'eval_runtime': 2.9662, 'eval_samples_per_second': 516.15, 'eval_steps_per_second': 64.729, 'epoch': 3.0, 'step': 1620}, {'loss': 0.0674, 'learning_rate': 1.6000000000000003e-05, 'epoch': 4.0, 'step': 2160}, {'eval_loss': 0.19391348958015442, 'eval_precision': 0.5045500505561172, 'eval_recall': 0.5689851767388826, 'eval_f1': 0.534833869239014, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 3.0717, 'eval_samples_per_second': 498.417, 'eval_steps_per_second': 62.506, 'epoch': 4.0, 'step': 2160}, {'loss': 0.0399, 'learning_rate': 1.5000000000000002e-05, 'epoch': 5.0, 'step': 2700}, {'eval_loss': 0.21263504028320312, 'eval_precision': 0.49281767955801103, 'eval_recall': 0.508551881413911, 'eval_f1': 0.5005611672278338, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 2.998, 'eval_samples_per_second': 510.681, 'eval_steps_per_second': 64.044, 'epoch': 5.0, 'step': 2700}, {'loss': 0.0249, 'learning_rate': 1.4e-05, 'epoch': 6.0, 'step': 3240}, {'eval_loss': 0.24309775233268738, 'eval_precision': 0.5343980343980343, 'eval_recall': 0.4960091220068415, 'eval_f1': 0.5144884683619161, 'eval_accuracy': 0.9515556241797267, 'eval_runtime': 3.0487, 'eval_samples_per_second': 502.185, 'eval_steps_per_second': 62.978, 'epoch': 6.0, 'step': 3240}, {'loss': 0.0147, 'learning_rate': 1.3000000000000001e-05, 'epoch': 7.0, 'step': 3780}, {'eval_loss': 0.2652530372142792, 'eval_precision': 0.48393782383419687, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.507057546145494, 'eval_accuracy': 0.9506291978692195, 'eval_runtime': 3.2307, 'eval_samples_per_second': 473.894, 'eval_steps_per_second': 59.43, 'epoch': 7.0, 'step': 3780}, {'loss': 0.0091, 'learning_rate': 1.2e-05, 'epoch': 8.0, 'step': 4320}, {'eval_loss': 0.2809131145477295, 'eval_precision': 0.5026910656620022, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5171650055370985, 'eval_accuracy': 0.9511310121207442, 'eval_runtime': 2.9302, 'eval_samples_per_second': 522.49, 'eval_steps_per_second': 65.525, 'epoch': 8.0, 'step': 4320}, {'loss': 0.0068, 'learning_rate': 1.1000000000000001e-05, 'epoch': 9.0, 'step': 4860}, {'eval_loss': 0.30010610818862915, 'eval_precision': 0.5394896719319563, 'eval_recall': 0.5062713797035348, 'eval_f1': 0.5223529411764705, 'eval_accuracy': 0.9528294603566742, 'eval_runtime': 2.9493, 'eval_samples_per_second': 519.112, 'eval_steps_per_second': 65.101, 'epoch': 9.0, 'step': 4860}, {'loss': 0.0045, 'learning_rate': 1e-05, 'epoch': 10.0, 'step': 5400}, {'eval_loss': 0.32053372263908386, 'eval_precision': 0.518640350877193, 'eval_recall': 0.5393386545039909, 'eval_f1': 0.528787031861375, 'eval_accuracy': 0.9514398208909133, 'eval_runtime': 2.9316, 'eval_samples_per_second': 522.24, 'eval_steps_per_second': 65.493, 'epoch': 10.0, 'step': 5400}, {'loss': 0.0033, 'learning_rate': 9e-06, 'epoch': 11.0, 'step': 5940}, {'eval_loss': 0.32531243562698364, 'eval_precision': 0.5281146637265711, 'eval_recall': 0.5461801596351197, 'eval_f1': 0.5369955156950671, 'eval_accuracy': 0.9517100285648112, 'eval_runtime': 2.9592, 'eval_samples_per_second': 517.37, 'eval_steps_per_second': 64.883, 'epoch': 11.0, 'step': 5940}, {'loss': 0.0022, 'learning_rate': 8.000000000000001e-06, 'epoch': 12.0, 'step': 6480}, {'eval_loss': 0.34835949540138245, 'eval_precision': 0.5053879310344828, 'eval_recall': 0.5347776510832383, 'eval_f1': 0.5196675900277008, 'eval_accuracy': 0.9499729792326103, 'eval_runtime': 2.9385, 'eval_samples_per_second': 521.008, 'eval_steps_per_second': 65.339, 'epoch': 12.0, 'step': 6480}, {'loss': 0.0019, 'learning_rate': 7e-06, 'epoch': 13.0, 'step': 7020}, {'eval_loss': 0.34721463918685913, 'eval_precision': 0.5496277915632755, 'eval_recall': 0.5051311288483467, 'eval_f1': 0.5264408793820559, 'eval_accuracy': 0.95336987570447, 'eval_runtime': 2.946, 'eval_samples_per_second': 519.687, 'eval_steps_per_second': 65.173, 'epoch': 13.0, 'step': 7020}, {'loss': 0.0014, 'learning_rate': 6e-06, 'epoch': 14.0, 'step': 7560}, {'eval_loss': 0.353302925825119, 'eval_precision': 0.544047619047619, 'eval_recall': 0.5210946408209807, 'eval_f1': 0.5323238206173557, 'eval_accuracy': 0.9533312746081989, 'eval_runtime': 2.9554, 'eval_samples_per_second': 518.04, 'eval_steps_per_second': 64.966, 'epoch': 14.0, 'step': 7560}, {'loss': 0.0013, 'learning_rate': 5e-06, 'epoch': 15.0, 'step': 8100}, {'eval_loss': 0.36596646904945374, 'eval_precision': 0.5317185697808535, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5286697247706423, 'eval_accuracy': 0.9522504439126072, 'eval_runtime': 3.0192, 'eval_samples_per_second': 507.083, 'eval_steps_per_second': 63.592, 'epoch': 15.0, 'step': 8100}, {'loss': 0.0011, 'learning_rate': 4.000000000000001e-06, 'epoch': 16.0, 'step': 8640}, {'eval_loss': 0.3721886873245239, 'eval_precision': 0.5508274231678487, 'eval_recall': 0.5313568985176739, 'eval_f1': 0.5409170052234475, 'eval_accuracy': 0.9527136570678607, 'eval_runtime': 2.9494, 'eval_samples_per_second': 519.083, 'eval_steps_per_second': 65.097, 'epoch': 16.0, 'step': 8640}, {'loss': 0.0007, 'learning_rate': 3e-06, 'epoch': 17.0, 'step': 9180}, {'eval_loss': 0.3836904466152191, 'eval_precision': 0.5251091703056768, 'eval_recall': 0.548460661345496, 'eval_f1': 0.5365309537088678, 'eval_accuracy': 0.9512468154095576, 'eval_runtime': 3.0187, 'eval_samples_per_second': 507.174, 'eval_steps_per_second': 63.604, 'epoch': 17.0, 'step': 9180}, {'loss': 0.0009, 'learning_rate': 2.0000000000000003e-06, 'epoch': 18.0, 'step': 9720}, {'eval_loss': 0.3791346848011017, 'eval_precision': 0.5373134328358209, 'eval_recall': 0.5336374002280502, 'eval_f1': 0.5354691075514875, 'eval_accuracy': 0.9518258318536247, 'eval_runtime': 2.9795, 'eval_samples_per_second': 513.839, 'eval_steps_per_second': 64.44, 'epoch': 18.0, 'step': 9720}, {'loss': 0.0005, 'learning_rate': 1.0000000000000002e-06, 'epoch': 19.0, 'step': 10260}, {'eval_loss': 0.3807985484600067, 'eval_precision': 0.5423529411764706, 'eval_recall': 0.5256556442417332, 'eval_f1': 0.5338737695425594, 'eval_accuracy': 0.9523276461051494, 'eval_runtime': 2.9947, 'eval_samples_per_second': 511.24, 'eval_steps_per_second': 64.114, 'epoch': 19.0, 'step': 10260}, {'loss': 0.0006, 'learning_rate': 0.0, 'epoch': 20.0, 'step': 10800}, {'eval_loss': 0.3812880218029022, 'eval_precision': 0.5318906605922551, 'eval_recall': 0.5324971493728621, 'eval_f1': 0.5321937321937322, 'eval_accuracy': 0.9518258318536247, 'eval_runtime': 2.9407, 'eval_samples_per_second': 520.627, 'eval_steps_per_second': 65.291, 'epoch': 20.0, 'step': 10800}, {'train_runtime': 824.4064, 'train_samples_per_second': 209.46, 'train_steps_per_second': 13.1, 'total_flos': 4838226106286592.0, 'train_loss': 0.04119411334119461, 'epoch': 20.0, 'step': 10800}]

Evaluation, ltg/norbert3-base
***** predict metrics *****
  predict_accuracy           =     0.9523
  predict_f1                 =      0.384
  predict_loss               =     0.1719
  predict_precision          =     0.4968
  predict_recall             =     0.3129
  predict_runtime            = 0:00:02.53
  predict_samples_per_second =    501.312
  predict_steps_per_second   =     62.664
Train and save best epoch to /fp/homes01/u01/ec-egilron/sqlabel-github/configs/fox/01191518_tsa-bin_NorBERT_3_base_16c.json completed. F1: 0.3839732888146912

Task and CPU usage stats:
JobID           JobName  AllocCPUS   NTasks     MinCPU MinCPUTask     AveCPU    Elapsed ExitCode 
------------ ---------- ---------- -------- ---------- ---------- ---------- ---------- -------- 
428792       tsa_norbe+          1                                             00:14:40      0:0 
428792.batch      batch          1        1   00:13:43          0   00:13:43   00:14:40      0:0 
428792.exte+     extern          1        1   00:00:00          0   00:00:00   00:14:40      0:0 

Memory usage stats:
JobID            MaxRSS MaxRSSTask     AveRSS MaxPages   MaxPagesTask   AvePages 
------------ ---------- ---------- ---------- -------- -------------- ---------- 
428792                                                                           
428792.batch   2426980K          0   2426980K        0              0          0 
428792.exte+          0          0          0        0              0          0 

Disk usage stats:
JobID         MaxDiskRead MaxDiskReadTask    AveDiskRead MaxDiskWrite MaxDiskWriteTask   AveDiskWrite 
------------ ------------ --------------- -------------- ------------ ---------------- -------------- 
428792                                                                                                
428792.batch      787.55M               0        787.55M    27467.15M                0      27467.15M 
428792.exte+        0.01M               0          0.01M        0.00M                0          0.00M 

GPU usage stats:
Error: Unable to retrieve job statistics. Return: Setting not configured.

Job 428792 completed at Mon Feb 12 15:56:23 CET 2024
